{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imoirt the dataset\n",
    "train = pd.read_csv('/Users/xlade/Desktop/Amdari/Network Intrussion/train_data.csv')\n",
    "test = pd.read_csv('/Users/xlade/Desktop/Amdari/Network Intrussion/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow_ID</th>\n",
       "      <th>Src_IP</th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_IP</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.3.130-200.175.2.130-38693-4444-6</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>38693</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>10/01/2020 05:02</td>\n",
       "      <td>268599</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.3.130-200.175.2.130-3632-33747-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>33747</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>3632</td>\n",
       "      <td>6</td>\n",
       "      <td>10/01/2020 05:02</td>\n",
       "      <td>22194</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>U2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.3.130-200.175.2.130-8180-37217-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>37217</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>10/01/2020 01:39</td>\n",
       "      <td>8782</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.3.130-200.175.2.130-8180-35921-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>35921</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>10/01/2020 01:39</td>\n",
       "      <td>4047</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.3.130-200.175.2.130-8180-43053-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>43053</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>10/01/2020 01:39</td>\n",
       "      <td>3819</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Flow_ID         Src_IP  Src_Port  \\\n",
       "0  192.168.3.130-200.175.2.130-38693-4444-6  192.168.3.130     38693   \n",
       "1  192.168.3.130-200.175.2.130-3632-33747-6  200.175.2.130     33747   \n",
       "2  192.168.3.130-200.175.2.130-8180-37217-6  200.175.2.130     37217   \n",
       "3  192.168.3.130-200.175.2.130-8180-35921-6  200.175.2.130     35921   \n",
       "4  192.168.3.130-200.175.2.130-8180-43053-6  200.175.2.130     43053   \n",
       "\n",
       "          Dst_IP  Dst_Port  Protocol         Timestamp  Flow_Duration  \\\n",
       "0  200.175.2.130      4444         6  10/01/2020 05:02         268599   \n",
       "1  192.168.3.130      3632         6  10/01/2020 05:02          22194   \n",
       "2  192.168.3.130      8180         6  10/01/2020 01:39           8782   \n",
       "3  192.168.3.130      8180         6  10/01/2020 01:39           4047   \n",
       "4  192.168.3.130      8180         6  10/01/2020 01:39           3819   \n",
       "\n",
       "   Tot_Fwd_Pkts  Tot_Bwd_Pkts  ...  Fwd_Seg_Size_Min  Active_Mean  Active_Std  \\\n",
       "0             2             3  ...                 0          0.0         0.0   \n",
       "1             5             5  ...                 0          0.0         0.0   \n",
       "2             4             4  ...                 0          0.0         0.0   \n",
       "3             2             2  ...                 0          0.0         0.0   \n",
       "4             2             2  ...                 0          0.0         0.0   \n",
       "\n",
       "   Active_Max  Active_Min  Idle_Mean  Idle_Std  Idle_Max  Idle_Min  Label  \n",
       "0           0           0        0.0       0.0         0         0    U2R  \n",
       "1           0           0        0.0       0.0         0         0    U2R  \n",
       "2           0           0        0.0       0.0         0         0    BFA  \n",
       "3           0           0        0.0       0.0         0         0    BFA  \n",
       "4           0           0        0.0       0.0         0         0    BFA  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143574, 84)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61592, 84)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow_ID      0\n",
       "Src_IP       0\n",
       "Src_Port     0\n",
       "Dst_IP       0\n",
       "Dst_Port     0\n",
       "            ..\n",
       "Idle_Mean    0\n",
       "Idle_Std     0\n",
       "Idle_Max     0\n",
       "Idle_Min     0\n",
       "Label        0\n",
       "Length: 84, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find the missing values > 0\n",
    "train.isnull().sum()[train.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find the missing values > 0\n",
    "test.isnull().sum()[test.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow_ID      102960\n",
       "Src_IP        52363\n",
       "Src_Port      24229\n",
       "Dst_IP         1014\n",
       "Dst_Port      23957\n",
       "              ...  \n",
       "Idle_Mean      4053\n",
       "Idle_Std       5471\n",
       "Idle_Max       2908\n",
       "Idle_Min       5080\n",
       "Label             6\n",
       "Length: 84, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Feature cadinality. Unique values cotained in each feature\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fwd_PSH_Flags        1\n",
       "Fwd_URG_Flags        1\n",
       "Bwd_URG_Flags        1\n",
       "URG_Flag_Cnt         1\n",
       "CWE_Flag_Count       1\n",
       "ECE_Flag_Cnt         1\n",
       "Fwd_Byts/b_Avg       1\n",
       "Fwd_Pkts/b_Avg       1\n",
       "Fwd_Blk_Rate_Avg     1\n",
       "Bwd_Byts/b_Avg       1\n",
       "Bwd_Pkts/b_Avg       1\n",
       "Bwd_Blk_Rate_Avg     1\n",
       "Init_Fwd_Win_Byts    1\n",
       "Fwd_Seg_Size_Min     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_unique_equal_one = test.nunique()[test.nunique() == 1 ]\n",
    "test_unique_equal_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>143574.000000</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143574.000000</td>\n",
       "      <td>143574.0</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "      <td>1.435740e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17499.654046</td>\n",
       "      <td>10778.129327</td>\n",
       "      <td>5.666806</td>\n",
       "      <td>1.014942e+07</td>\n",
       "      <td>4.630636</td>\n",
       "      <td>8.529790</td>\n",
       "      <td>1.137087e+03</td>\n",
       "      <td>1.461854e+04</td>\n",
       "      <td>147.555734</td>\n",
       "      <td>7.437558</td>\n",
       "      <td>...</td>\n",
       "      <td>1.497848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.209253e+04</td>\n",
       "      <td>5.082656e+04</td>\n",
       "      <td>1.454295e+05</td>\n",
       "      <td>3.611374e+04</td>\n",
       "      <td>6.978304e+06</td>\n",
       "      <td>2.118306e+05</td>\n",
       "      <td>7.173034e+06</td>\n",
       "      <td>6.791966e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22467.153441</td>\n",
       "      <td>18305.497287</td>\n",
       "      <td>5.727448</td>\n",
       "      <td>2.618417e+07</td>\n",
       "      <td>69.004375</td>\n",
       "      <td>153.640664</td>\n",
       "      <td>6.791834e+04</td>\n",
       "      <td>5.026526e+05</td>\n",
       "      <td>856.733699</td>\n",
       "      <td>40.343082</td>\n",
       "      <td>...</td>\n",
       "      <td>25.624422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.175082e+05</td>\n",
       "      <td>6.682283e+05</td>\n",
       "      <td>1.462056e+06</td>\n",
       "      <td>6.128490e+05</td>\n",
       "      <td>1.890190e+07</td>\n",
       "      <td>2.055652e+06</td>\n",
       "      <td>1.920783e+07</td>\n",
       "      <td>1.876914e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.530000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.952000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40657.750000</td>\n",
       "      <td>9659.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.730550e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.370000e+02</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65518.000000</td>\n",
       "      <td>60998.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>16928.000000</td>\n",
       "      <td>34094.000000</td>\n",
       "      <td>1.500000e+07</td>\n",
       "      <td>1.070000e+08</td>\n",
       "      <td>64239.000000</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5280.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040000e+08</td>\n",
       "      <td>6.830000e+07</td>\n",
       "      <td>1.040000e+08</td>\n",
       "      <td>1.040000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>7.300000e+07</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.200000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Src_Port       Dst_Port       Protocol  Flow_Duration  \\\n",
       "count  143574.000000  143574.000000  143574.000000   1.435740e+05   \n",
       "mean    17499.654046   10778.129327       5.666806   1.014942e+07   \n",
       "std     22467.153441   18305.497287       5.727448   2.618417e+07   \n",
       "min         0.000000       0.000000       0.000000  -1.530000e+02   \n",
       "25%         0.000000       0.000000       0.000000   2.000000e+01   \n",
       "50%        80.000000      53.000000       6.000000   2.952000e+03   \n",
       "75%     40657.750000    9659.750000       6.000000   2.730550e+04   \n",
       "max     65518.000000   60998.000000      17.000000   1.200000e+08   \n",
       "\n",
       "        Tot_Fwd_Pkts   Tot_Bwd_Pkts  TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  \\\n",
       "count  143574.000000  143574.000000     1.435740e+05     1.435740e+05   \n",
       "mean        4.630636       8.529790     1.137087e+03     1.461854e+04   \n",
       "std        69.004375     153.640664     6.791834e+04     5.026526e+05   \n",
       "min         0.000000       1.000000     0.000000e+00     0.000000e+00   \n",
       "25%         0.000000       2.000000     0.000000e+00     0.000000e+00   \n",
       "50%         0.000000       2.000000     0.000000e+00     0.000000e+00   \n",
       "75%         3.000000       4.000000     3.100000e+01     1.370000e+02   \n",
       "max     16928.000000   34094.000000     1.500000e+07     1.070000e+08   \n",
       "\n",
       "       Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  ...  Fwd_Act_Data_Pkts  \\\n",
       "count    143574.000000    143574.000000  ...      143574.000000   \n",
       "mean        147.555734         7.437558  ...           1.497848   \n",
       "std         856.733699        40.343082  ...          25.624422   \n",
       "min           0.000000         0.000000  ...           0.000000   \n",
       "25%           0.000000         0.000000  ...           0.000000   \n",
       "50%           0.000000         0.000000  ...           0.000000   \n",
       "75%          30.000000         0.000000  ...           1.000000   \n",
       "max       64239.000000      3900.000000  ...        5280.000000   \n",
       "\n",
       "       Fwd_Seg_Size_Min   Active_Mean    Active_Std    Active_Max  \\\n",
       "count          143574.0  1.435740e+05  1.435740e+05  1.435740e+05   \n",
       "mean                0.0  7.209253e+04  5.082656e+04  1.454295e+05   \n",
       "std                 0.0  8.175082e+05  6.682283e+05  1.462056e+06   \n",
       "min                 0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%                 0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%                 0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%                 0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max                 0.0  1.040000e+08  6.830000e+07  1.040000e+08   \n",
       "\n",
       "         Active_Min     Idle_Mean      Idle_Std      Idle_Max      Idle_Min  \n",
       "count  1.435740e+05  1.435740e+05  1.435740e+05  1.435740e+05  1.435740e+05  \n",
       "mean   3.611374e+04  6.978304e+06  2.118306e+05  7.173034e+06  6.791966e+06  \n",
       "std    6.128490e+05  1.890190e+07  2.055652e+06  1.920783e+07  1.876914e+07  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "max    1.040000e+08  1.200000e+08  7.300000e+07  1.200000e+08  1.200000e+08  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data desciption\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143574 entries, 0 to 143573\n",
      "Data columns (total 84 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Flow_ID            143574 non-null  object \n",
      " 1   Src_IP             143574 non-null  object \n",
      " 2   Src_Port           143574 non-null  int64  \n",
      " 3   Dst_IP             143574 non-null  object \n",
      " 4   Dst_Port           143574 non-null  int64  \n",
      " 5   Protocol           143574 non-null  int64  \n",
      " 6   Timestamp          143574 non-null  object \n",
      " 7   Flow_Duration      143574 non-null  int64  \n",
      " 8   Tot_Fwd_Pkts       143574 non-null  int64  \n",
      " 9   Tot_Bwd_Pkts       143574 non-null  int64  \n",
      " 10  TotLen_Fwd_Pkts    143574 non-null  int64  \n",
      " 11  TotLen_Bwd_Pkts    143574 non-null  int64  \n",
      " 12  Fwd_Pkt_Len_Max    143574 non-null  int64  \n",
      " 13  Fwd_Pkt_Len_Min    143574 non-null  int64  \n",
      " 14  Fwd_Pkt_Len_Mean   143574 non-null  float64\n",
      " 15  Fwd_Pkt_Len_Std    143574 non-null  float64\n",
      " 16  Bwd_Pkt_Len_Max    143574 non-null  int64  \n",
      " 17  Bwd_Pkt_Len_Min    143574 non-null  int64  \n",
      " 18  Bwd_Pkt_Len_Mean   143574 non-null  float64\n",
      " 19  Bwd_Pkt_Len_Std    143574 non-null  float64\n",
      " 20  Flow_Byts/s        143574 non-null  float64\n",
      " 21  Flow_Pkts/s        143574 non-null  float64\n",
      " 22  Flow_IAT_Mean      143574 non-null  float64\n",
      " 23  Flow_IAT_Std       143574 non-null  float64\n",
      " 24  Flow_IAT_Max       143574 non-null  int64  \n",
      " 25  Flow_IAT_Min       143574 non-null  int64  \n",
      " 26  Fwd_IAT_Tot        143574 non-null  int64  \n",
      " 27  Fwd_IAT_Mean       143574 non-null  float64\n",
      " 28  Fwd_IAT_Std        143574 non-null  float64\n",
      " 29  Fwd_IAT_Max        143574 non-null  int64  \n",
      " 30  Fwd_IAT_Min        143574 non-null  int64  \n",
      " 31  Bwd_IAT_Tot        143574 non-null  int64  \n",
      " 32  Bwd_IAT_Mean       143574 non-null  float64\n",
      " 33  Bwd_IAT_Std        143574 non-null  float64\n",
      " 34  Bwd_IAT_Max        143574 non-null  int64  \n",
      " 35  Bwd_IAT_Min        143574 non-null  int64  \n",
      " 36  Fwd_PSH_Flags      143574 non-null  int64  \n",
      " 37  Bwd_PSH_Flags      143574 non-null  int64  \n",
      " 38  Fwd_URG_Flags      143574 non-null  int64  \n",
      " 39  Bwd_URG_Flags      143574 non-null  int64  \n",
      " 40  Fwd_Header_Len     143574 non-null  int64  \n",
      " 41  Bwd_Header_Len     143574 non-null  int64  \n",
      " 42  Fwd_Pkts/s         143574 non-null  float64\n",
      " 43  Bwd_Pkts/s         143574 non-null  float64\n",
      " 44  Pkt_Len_Min        143574 non-null  int64  \n",
      " 45  Pkt_Len_Max        143574 non-null  int64  \n",
      " 46  Pkt_Len_Mean       143574 non-null  float64\n",
      " 47  Pkt_Len_Std        143574 non-null  float64\n",
      " 48  Pkt_Len_Var        143574 non-null  float64\n",
      " 49  FIN_Flag_Cnt       143574 non-null  int64  \n",
      " 50  SYN_Flag_Cnt       143574 non-null  int64  \n",
      " 51  RST_Flag_Cnt       143574 non-null  int64  \n",
      " 52  PSH_Flag_Cnt       143574 non-null  int64  \n",
      " 53  ACK_Flag_Cnt       143574 non-null  int64  \n",
      " 54  URG_Flag_Cnt       143574 non-null  int64  \n",
      " 55  CWE_Flag_Count     143574 non-null  int64  \n",
      " 56  ECE_Flag_Cnt       143574 non-null  int64  \n",
      " 57  Down/Up_Ratio      143574 non-null  int64  \n",
      " 58  Pkt_Size_Avg       143574 non-null  float64\n",
      " 59  Fwd_Seg_Size_Avg   143574 non-null  float64\n",
      " 60  Bwd_Seg_Size_Avg   143574 non-null  float64\n",
      " 61  Fwd_Byts/b_Avg     143574 non-null  int64  \n",
      " 62  Fwd_Pkts/b_Avg     143574 non-null  int64  \n",
      " 63  Fwd_Blk_Rate_Avg   143574 non-null  int64  \n",
      " 64  Bwd_Byts/b_Avg     143574 non-null  int64  \n",
      " 65  Bwd_Pkts/b_Avg     143574 non-null  int64  \n",
      " 66  Bwd_Blk_Rate_Avg   143574 non-null  int64  \n",
      " 67  Subflow_Fwd_Pkts   143574 non-null  int64  \n",
      " 68  Subflow_Fwd_Byts   143574 non-null  int64  \n",
      " 69  Subflow_Bwd_Pkts   143574 non-null  int64  \n",
      " 70  Subflow_Bwd_Byts   143574 non-null  int64  \n",
      " 71  Init_Fwd_Win_Byts  143574 non-null  int64  \n",
      " 72  Init_Bwd_Win_Byts  143574 non-null  int64  \n",
      " 73  Fwd_Act_Data_Pkts  143574 non-null  int64  \n",
      " 74  Fwd_Seg_Size_Min   143574 non-null  int64  \n",
      " 75  Active_Mean        143574 non-null  float64\n",
      " 76  Active_Std         143574 non-null  float64\n",
      " 77  Active_Max         143574 non-null  int64  \n",
      " 78  Active_Min         143574 non-null  int64  \n",
      " 79  Idle_Mean          143574 non-null  float64\n",
      " 80  Idle_Std           143574 non-null  float64\n",
      " 81  Idle_Max           143574 non-null  int64  \n",
      " 82  Idle_Min           143574 non-null  int64  \n",
      " 83  Label              143574 non-null  object \n",
      "dtypes: float64(24), int64(55), object(5)\n",
      "memory usage: 92.0+ MB\n"
     ]
    }
   ],
   "source": [
    "## Data description\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out the non numerical features (except the labels)\n",
    "train_labels = train[\"Label\"]\n",
    "test_labels = test[\"Label\"]\n",
    "\n",
    "train = train.select_dtypes(exclude = [\"object\"])\n",
    "test = test.select_dtypes(exclude = [\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38693</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>268599</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33747</td>\n",
       "      <td>3632</td>\n",
       "      <td>6</td>\n",
       "      <td>22194</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37217</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>8782</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35921</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>4047</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43053</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>3819</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Src_Port  Dst_Port  Protocol  Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  \\\n",
       "0     38693      4444         6         268599             2             3   \n",
       "1     33747      3632         6          22194             5             5   \n",
       "2     37217      8180         6           8782             4             4   \n",
       "3     35921      8180         6           4047             2             2   \n",
       "4     43053      8180         6           3819             2             2   \n",
       "\n",
       "   TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  ...  \\\n",
       "0                0               23                0                0  ...   \n",
       "1               53               30               30                0  ...   \n",
       "2               30               30               30                0  ...   \n",
       "3                0                0                0                0  ...   \n",
       "4                0                0                0                0  ...   \n",
       "\n",
       "   Fwd_Act_Data_Pkts  Fwd_Seg_Size_Min  Active_Mean  Active_Std  Active_Max  \\\n",
       "0                  0                 0          0.0         0.0           0   \n",
       "1                  2                 0          0.0         0.0           0   \n",
       "2                  1                 0          0.0         0.0           0   \n",
       "3                  0                 0          0.0         0.0           0   \n",
       "4                  0                 0          0.0         0.0           0   \n",
       "\n",
       "   Active_Min  Idle_Mean  Idle_Std  Idle_Max  Idle_Min  \n",
       "0           0        0.0       0.0         0         0  \n",
       "1           0        0.0       0.0         0         0  \n",
       "2           0        0.0       0.0         0         0  \n",
       "3           0        0.0       0.0         0         0  \n",
       "4           0        0.0       0.0         0         0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outlier detection \n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "## Novelty = True, allows us to detect outliers in both dataset we trained on and otherwise\n",
    "outlier_detector = LocalOutlierFactor(novelty = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LocalOutlierFactor(novelty=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LocalOutlierFactor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\">?<span>Documentation for LocalOutlierFactor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LocalOutlierFactor(novelty=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LocalOutlierFactor(novelty=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit outlier detector on the train data\n",
    "\n",
    "outlier_detector.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xlade/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/xlade/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_outliers = outlier_detector.predict(train)\n",
    "test_outliers = outlier_detector.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in train split: 4136\n"
     ]
    }
   ],
   "source": [
    "## Numbers of outliers in train data\n",
    "print(\"Number of outliers in train split:\", sum(train_outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in test split: 2006\n"
     ]
    }
   ],
   "source": [
    "## Numbers of outliers in test data\n",
    "print(\"Number of outliers in test split:\", sum(test_outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "143569    False\n",
       "143570    False\n",
       "143571    False\n",
       "143572    False\n",
       "143573    False\n",
       "Length: 143574, dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Duplicated values\n",
    "\n",
    "train.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of duplicated values in train : 50357\n",
      "numbers of duplicated values in test : 21190\n"
     ]
    }
   ],
   "source": [
    "## print numbners of duplicated values in train and test dataset\n",
    "\n",
    "print(\"numbers of duplicated values in train :\", sum(train.duplicated() == True))\n",
    "print(\"numbers of duplicated values in test :\", sum(test.duplicated() == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elimanate duplicated values\n",
    "\n",
    "train = train.loc[~train.duplicated(), :]\n",
    "test = test.loc[~test.duplicated(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inplications\n",
    "\n",
    "    #Implied by findings above, we say the following:\n",
    "\n",
    "    - Missing values and outliers: There are no missing valaues in the trainset. As regards outliers, there are quite a few. \n",
    "    - Data imbalance: the datasetis strongly imbalanced with respect to the instance labels. This impliued that regular classification metrics like accuracy would not be good enough for evaluating final model\n",
    "    - Scaling: Depending on the final algorithm used, there might be a need for feature scaling with a good number of variables in the data. This would discourage from assigning undue degrees of importance (i.e: weights) to a variable simplydue to average magnitude. \n",
    "    - Correlation: There is a low multicinearity within the dataset. Some features exhibit strong correlation with one another. Some of the features may need to be eliminated or combined somehow to maintain feature independence.\n",
    "    - Data Dimensionality. There are around - 84 differenct features in the dataset. Although the number of observations (0.14 million) will offset the curse of dimensionality, the need to reduce the dimensionality may still arise. \n",
    "    - Large Number of Records: The lsrge number of records (- o.14 million) is a characteristics of the amount of data generated from day to day operations of the compyter networs. As such, optimized algorithm would be required for effective computation. \n",
    "    - Irrelevant columns: Some columns are irrelevant since they have a variance of zero. These columns need to be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93217, 79)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data size\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fwd_PSH_Flags        1\n",
       "Fwd_URG_Flags        1\n",
       "Bwd_URG_Flags        1\n",
       "URG_Flag_Cnt         1\n",
       "CWE_Flag_Count       1\n",
       "ECE_Flag_Cnt         1\n",
       "Fwd_Byts/b_Avg       1\n",
       "Fwd_Pkts/b_Avg       1\n",
       "Fwd_Blk_Rate_Avg     1\n",
       "Bwd_Byts/b_Avg       1\n",
       "Bwd_Pkts/b_Avg       1\n",
       "Bwd_Blk_Rate_Avg     1\n",
       "Init_Fwd_Win_Byts    1\n",
       "Fwd_Seg_Size_Min     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Features with a cadinality of 1 (invariant features)\n",
    "train.nunique()[train.nunique() == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fwd_PSH_Flags',\n",
       " 'Fwd_URG_Flags',\n",
       " 'Bwd_URG_Flags',\n",
       " 'URG_Flag_Cnt',\n",
       " 'CWE_Flag_Count',\n",
       " 'ECE_Flag_Cnt',\n",
       " 'Fwd_Byts/b_Avg',\n",
       " 'Fwd_Pkts/b_Avg',\n",
       " 'Fwd_Blk_Rate_Avg',\n",
       " 'Bwd_Byts/b_Avg',\n",
       " 'Bwd_Pkts/b_Avg',\n",
       " 'Bwd_Blk_Rate_Avg',\n",
       " 'Init_Fwd_Win_Byts',\n",
       " 'Fwd_Seg_Size_Min']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invariant_features = train.nunique()[train.nunique() == 1].index.tolist()\n",
    "invariant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            U2R\n",
       "1            U2R\n",
       "2            BFA\n",
       "3            BFA\n",
       "4            BFA\n",
       "           ...  \n",
       "143569    Normal\n",
       "143570    Normal\n",
       "143571    Normal\n",
       "143572    Normal\n",
       "143573    Normal\n",
       "Name: Label, Length: 143574, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##check for label distribution\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "DDoS      51588\n",
       "Normal    47862\n",
       "Probe     43113\n",
       "DoS         799\n",
       "BFA         201\n",
       "U2R          11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,  y = train_labels.value_counts().index, train_labels.value_counts(). values\n",
    "\n",
    "plt.bar(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature correlation (pearson allows us to observe linear correlation)\n",
    "correlation_matrix = train.corr(method = \"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## correlation heatmap\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(correlation_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Src_Port</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.903043</td>\n",
       "      <td>0.408463</td>\n",
       "      <td>-0.145166</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.037758</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>-0.019634</td>\n",
       "      <td>0.068701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071633</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.093275</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>-0.352647</td>\n",
       "      <td>0.092808</td>\n",
       "      <td>-0.338097</td>\n",
       "      <td>-0.363945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dst_Port</th>\n",
       "      <td>-0.903043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.329418</td>\n",
       "      <td>0.134572</td>\n",
       "      <td>-0.045298</td>\n",
       "      <td>-0.032592</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>-0.028542</td>\n",
       "      <td>0.074871</td>\n",
       "      <td>-0.035731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.083619</td>\n",
       "      <td>-0.072533</td>\n",
       "      <td>-0.094501</td>\n",
       "      <td>-0.055584</td>\n",
       "      <td>0.344679</td>\n",
       "      <td>-0.097464</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.356215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protocol</th>\n",
       "      <td>0.408463</td>\n",
       "      <td>-0.329418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.280577</td>\n",
       "      <td>-0.041504</td>\n",
       "      <td>-0.027529</td>\n",
       "      <td>-0.011296</td>\n",
       "      <td>-0.019679</td>\n",
       "      <td>-0.097959</td>\n",
       "      <td>0.348420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.057003</td>\n",
       "      <td>-0.050935</td>\n",
       "      <td>-0.066101</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>-0.254699</td>\n",
       "      <td>-0.064129</td>\n",
       "      <td>-0.257548</td>\n",
       "      <td>-0.249559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_Duration</th>\n",
       "      <td>-0.145166</td>\n",
       "      <td>0.134572</td>\n",
       "      <td>-0.280577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123216</td>\n",
       "      <td>0.094294</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.085370</td>\n",
       "      <td>-0.106421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204677</td>\n",
       "      <td>0.246933</td>\n",
       "      <td>0.288224</td>\n",
       "      <td>0.082243</td>\n",
       "      <td>0.806488</td>\n",
       "      <td>0.302594</td>\n",
       "      <td>0.826469</td>\n",
       "      <td>0.779474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <td>0.050648</td>\n",
       "      <td>-0.045298</td>\n",
       "      <td>-0.041504</td>\n",
       "      <td>0.123216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947951</td>\n",
       "      <td>0.358868</td>\n",
       "      <td>0.870280</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>-0.015727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>0.187264</td>\n",
       "      <td>0.212998</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.064981</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Active_Min</th>\n",
       "      <td>0.036443</td>\n",
       "      <td>-0.055584</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.082243</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.027866</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>0.053457</td>\n",
       "      <td>-0.013555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805611</td>\n",
       "      <td>0.087307</td>\n",
       "      <td>0.488649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028753</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.023404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idle_Mean</th>\n",
       "      <td>-0.352647</td>\n",
       "      <td>0.344679</td>\n",
       "      <td>-0.254699</td>\n",
       "      <td>0.806488</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>-0.023331</td>\n",
       "      <td>-0.104198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.028753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107636</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.995917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idle_Std</th>\n",
       "      <td>0.092808</td>\n",
       "      <td>-0.097464</td>\n",
       "      <td>-0.064129</td>\n",
       "      <td>0.302594</td>\n",
       "      <td>0.064981</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>0.102494</td>\n",
       "      <td>-0.023429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>0.208193</td>\n",
       "      <td>0.207031</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.107636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202446</td>\n",
       "      <td>0.019905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idle_Max</th>\n",
       "      <td>-0.338097</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>-0.257548</td>\n",
       "      <td>0.826469</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.011173</td>\n",
       "      <td>-0.105019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.053699</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.202446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idle_Min</th>\n",
       "      <td>-0.363945</td>\n",
       "      <td>0.356215</td>\n",
       "      <td>-0.249559</td>\n",
       "      <td>0.779474</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>-0.033994</td>\n",
       "      <td>-0.102479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.995917</td>\n",
       "      <td>0.019905</td>\n",
       "      <td>0.982397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Src_Port  Dst_Port  Protocol  Flow_Duration  Tot_Fwd_Pkts  \\\n",
       "Src_Port       1.000000 -0.903043  0.408463      -0.145166      0.050648   \n",
       "Dst_Port      -0.903043  1.000000 -0.329418       0.134572     -0.045298   \n",
       "Protocol       0.408463 -0.329418  1.000000      -0.280577     -0.041504   \n",
       "Flow_Duration -0.145166  0.134572 -0.280577       1.000000      0.123216   \n",
       "Tot_Fwd_Pkts   0.050648 -0.045298 -0.041504       0.123216      1.000000   \n",
       "...                 ...       ...       ...            ...           ...   \n",
       "Active_Min     0.036443 -0.055584 -0.036679       0.082243      0.060601   \n",
       "Idle_Mean     -0.352647  0.344679 -0.254699       0.806488      0.008015   \n",
       "Idle_Std       0.092808 -0.097464 -0.064129       0.302594      0.064981   \n",
       "Idle_Max      -0.338097  0.329630 -0.257548       0.826469      0.015746   \n",
       "Idle_Min      -0.363945  0.356215 -0.249559       0.779474      0.001311   \n",
       "\n",
       "               Tot_Bwd_Pkts  TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  \\\n",
       "Src_Port           0.037758         0.012336         0.033849   \n",
       "Dst_Port          -0.032592        -0.008437        -0.028542   \n",
       "Protocol          -0.027529        -0.011296        -0.019679   \n",
       "Flow_Duration      0.094294         0.030307         0.068715   \n",
       "Tot_Fwd_Pkts       0.947951         0.358868         0.870280   \n",
       "...                     ...              ...              ...   \n",
       "Active_Min         0.035655         0.027866         0.013415   \n",
       "Idle_Mean          0.005343        -0.003421        -0.003929   \n",
       "Idle_Std           0.040385         0.012496         0.022177   \n",
       "Idle_Max           0.010173        -0.001766        -0.001340   \n",
       "Idle_Min           0.001121        -0.004774        -0.006558   \n",
       "\n",
       "               Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  ...  Fwd_Act_Data_Pkts  \\\n",
       "Src_Port             -0.019634         0.068701  ...           0.040198   \n",
       "Dst_Port              0.074871        -0.035731  ...          -0.033554   \n",
       "Protocol             -0.097959         0.348420  ...          -0.022101   \n",
       "Flow_Duration         0.085370        -0.106421  ...           0.099596   \n",
       "Tot_Fwd_Pkts          0.110151        -0.015727  ...           0.407826   \n",
       "...                        ...              ...  ...                ...   \n",
       "Active_Min            0.053457        -0.013555  ...           0.093326   \n",
       "Idle_Mean            -0.023331        -0.104198  ...           0.013074   \n",
       "Idle_Std              0.102494        -0.023429  ...           0.077410   \n",
       "Idle_Max             -0.011173        -0.105019  ...           0.022541   \n",
       "Idle_Min             -0.033994        -0.102479  ...           0.005424   \n",
       "\n",
       "               Fwd_Seg_Size_Min  Active_Mean  Active_Std  Active_Max  \\\n",
       "Src_Port                    NaN     0.071633    0.078141    0.093275   \n",
       "Dst_Port                    NaN    -0.083619   -0.072533   -0.094501   \n",
       "Protocol                    NaN    -0.057003   -0.050935   -0.066101   \n",
       "Flow_Duration               NaN     0.204677    0.246933    0.288224   \n",
       "Tot_Fwd_Pkts                NaN     0.154701    0.187264    0.212998   \n",
       "...                         ...          ...         ...         ...   \n",
       "Active_Min                  NaN     0.805611    0.087307    0.488649   \n",
       "Idle_Mean                   NaN     0.035745    0.024338    0.029184   \n",
       "Idle_Std                    NaN     0.170803    0.208193    0.207031   \n",
       "Idle_Max                    NaN     0.054250    0.048263    0.053699   \n",
       "Idle_Min                    NaN     0.019376    0.003510    0.007794   \n",
       "\n",
       "               Active_Min  Idle_Mean  Idle_Std  Idle_Max  Idle_Min  \n",
       "Src_Port         0.036443  -0.352647  0.092808 -0.338097 -0.363945  \n",
       "Dst_Port        -0.055584   0.344679 -0.097464  0.329630  0.356215  \n",
       "Protocol        -0.036679  -0.254699 -0.064129 -0.257548 -0.249559  \n",
       "Flow_Duration    0.082243   0.806488  0.302594  0.826469  0.779474  \n",
       "Tot_Fwd_Pkts     0.060601   0.008015  0.064981  0.015746  0.001311  \n",
       "...                   ...        ...       ...       ...       ...  \n",
       "Active_Min       1.000000   0.028753  0.062372  0.034309  0.023404  \n",
       "Idle_Mean        0.028753   1.000000  0.107636  0.994924  0.995917  \n",
       "Idle_Std         0.062372   0.107636  1.000000  0.202446  0.019905  \n",
       "Idle_Max         0.034309   0.994924  0.202446  1.000000  0.982397  \n",
       "Idle_Min         0.023404   0.995917  0.019905  0.982397  1.000000  \n",
       "\n",
       "[79 rows x 79 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inplications\n",
    "\n",
    "    #Implied by findings above, we say the following:\n",
    "\n",
    "    - Missing values and outliers: There are no missing valaues in the trainset. As regards outliers, there are quite a few. \n",
    "    - Data imbalance: the datasetis strongly imbalanced with respect to the instance labels. This impliued that regular classification metrics like accuracy would not be good enough for evaluating final model\n",
    "    - Scaling: Depending on the final algorithm used, there might be a need for feature scaling with a good number of variables in the data. This would discourage from assigning undue degrees of importance (i.e: weights) to a variable simplydue to average magnitude. \n",
    "    - Correlation: There is a low multicinearity within the dataset. Some features exhibit strong correlation with one another. Some of the features may need to be eliminated or combined somehow to maintain feature independence.\n",
    "    - Data Dimensionality. There are around - 84 differenct features in the dataset. Although the number of observations (0.14 million) will offset the curse of dimensionality, the need to reduce the dimensionality may still arise. \n",
    "    - Large Number of Records: The lsrge number of records (- o.14 million) is a characteristics of the amount of data generated from day to day operations of the compyter networs. As such, optimized algorithm would be required for effective computation. \n",
    "    - Irrelevant columns: Some columns are irrelevant since they have a variance of zero. These columns need to be eliminated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the data Implication discovered prior, The following steps will be experimented upon the data preparation stage.\n",
    "\n",
    "    1, Remove invariant and irrelevent columns The invariant are irrelevant columns will be elimimnated\n",
    "    2, Feature Scaling: The dataset will be scaled using the StandardScaler implementation provided by sci-ki tlearn.  In order to satisfy the need optimal computation, \n",
    "    3. Feature Selection: The non numerical features of the dataset are filtered out and the numerical ones are retained. This is done in order to avoid complicated feature engineering. \n",
    "    4. Distributed Computing: In order to satisfy the need for optimal computation, most of (if not all) the algorithms used will be obtained from Pyspark. \n",
    "\n",
    "All these steps are implemented as below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required utilities\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, IndexToString "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the invariant features\n",
    "train.drop(labels = invariant_features, axis = 1, inplace = True)\n",
    "test.drop(labels = invariant_features, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the irrelevant features\n",
    "irrelevant_features = [\"Src_Port\", \"Dst_Port\"]\n",
    "\n",
    "train.drop(labels = irrelevant_features, axis = 1, inplace = True)\n",
    "test.drop(labels = irrelevant_features, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>Fwd_Pkt_Len_Mean</th>\n",
       "      <th>Fwd_Pkt_Len_Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Init_Bwd_Win_Byts</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>268599</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>22194</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>14.72413</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>8782</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4047</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>5792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3819</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>5792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol  Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  TotLen_Fwd_Pkts  \\\n",
       "0         6         268599             2             3                0   \n",
       "1         6          22194             5             5               53   \n",
       "2         6           8782             4             4               30   \n",
       "3         6           4047             2             2                0   \n",
       "4         6           3819             2             2                0   \n",
       "\n",
       "   TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  Fwd_Pkt_Len_Mean  \\\n",
       "0               23                0                0               0.0   \n",
       "1               30               30                0              10.6   \n",
       "2               30               30                0               7.5   \n",
       "3                0                0                0               0.0   \n",
       "4                0                0                0               0.0   \n",
       "\n",
       "   Fwd_Pkt_Len_Std  ...  Init_Bwd_Win_Byts  Fwd_Act_Data_Pkts  Active_Mean  \\\n",
       "0          0.00000  ...                 64                  0          0.0   \n",
       "1         14.72413  ...                215                  2          0.0   \n",
       "2         15.00000  ...                215                  1          0.0   \n",
       "3          0.00000  ...               5792                  0          0.0   \n",
       "4          0.00000  ...               5792                  0          0.0   \n",
       "\n",
       "   Active_Std  Active_Max  Active_Min  Idle_Mean  Idle_Std  Idle_Max  Idle_Min  \n",
       "0         0.0           0           0        0.0       0.0         0         0  \n",
       "1         0.0           0           0        0.0       0.0         0         0  \n",
       "2         0.0           0           0        0.0       0.0         0         0  \n",
       "3         0.0           0           0        0.0       0.0         0         0  \n",
       "4         0.0           0           0        0.0       0.0         0         0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elimanate dupliacted labels\n",
    "train_labels = train_labels.loc[train.index]\n",
    "test_labels = test_labels.loc[test.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine targets and features from pyspark\n",
    "train[\"Label\"] = train_labels\n",
    "test[\"Label\"] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LocalOutlierFactor(novelty=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LocalOutlierFactor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\">?<span>Documentation for LocalOutlierFactor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LocalOutlierFactor(novelty=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LocalOutlierFactor(novelty=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Eliminate outliers\n",
    "outlier_detector = LocalOutlierFactor(novelty = True)\n",
    "\n",
    "outlier_detector.fit(train.drop(labels = \"Label\", axis = 1))\n",
    "\n",
    "#outlier_detector.fit(test.drop(labels = \"Label\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xlade/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/xlade/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Predict outliers in dataset\n",
    "\n",
    "train_outliers = outlier_detector.predict(train.drop(labels = \"Label\", axis = 1).values)\n",
    "test_outliers = outlier_detector.predict(test.drop(labels = \"Label\", axis = 1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of outliers in Train dataset: 4957\n",
      "Numbers of outliers in Test dataset: 2457\n"
     ]
    }
   ],
   "source": [
    "print(\"Numbers of outliers in Train dataset:\", sum(train_outliers == -1))\n",
    "print(\"Numbers of outliers in Test dataset:\", sum(test_outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93217, 64), (40402, 64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data shape\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## eliminate outliers\n",
    "\n",
    "train = train.loc[train_outliers == -1]\n",
    "test = test.loc[test_outliers == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4957, 64), (2457, 64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data shape\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale our data from sklearn.preprocessing impot StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol                  17.0\n",
       "Flow_Duration      120000065.0\n",
       "Tot_Fwd_Pkts           16928.0\n",
       "Tot_Bwd_Pkts           34093.0\n",
       "TotLen_Fwd_Pkts     15000000.0\n",
       "                      ...     \n",
       "Active_Min         104000000.0\n",
       "Idle_Mean          120000000.0\n",
       "Idle_Std            73000000.0\n",
       "Idle_Max           120000000.0\n",
       "Idle_Min           120000000.0\n",
       "Length: 63, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.drop(labels = \"Label\", axis = 1)\n",
    "\n",
    "difference = df.max() - df.min()\n",
    "\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " numbers of categorical variables in df: 0\n"
     ]
    }
   ],
   "source": [
    "print(\" numbers of categorical variables in df:\", sum(df.dtypes == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Protocol', 'Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts',\n",
       "       'TotLen_Fwd_Pkts', 'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Max',\n",
       "       'Fwd_Pkt_Len_Min', 'Fwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std',\n",
       "       'Bwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Mean',\n",
       "       'Bwd_Pkt_Len_Std', 'Flow_Byts/s', 'Flow_Pkts/s', 'Flow_IAT_Mean',\n",
       "       'Flow_IAT_Std', 'Flow_IAT_Max', 'Flow_IAT_Min', 'Fwd_IAT_Tot',\n",
       "       'Fwd_IAT_Mean', 'Fwd_IAT_Std', 'Fwd_IAT_Max', 'Fwd_IAT_Min',\n",
       "       'Bwd_IAT_Tot', 'Bwd_IAT_Mean', 'Bwd_IAT_Std', 'Bwd_IAT_Max',\n",
       "       'Bwd_IAT_Min', 'Bwd_PSH_Flags', 'Fwd_Header_Len', 'Bwd_Header_Len',\n",
       "       'Fwd_Pkts/s', 'Bwd_Pkts/s', 'Pkt_Len_Min', 'Pkt_Len_Max',\n",
       "       'Pkt_Len_Mean', 'Pkt_Len_Std', 'Pkt_Len_Var', 'FIN_Flag_Cnt',\n",
       "       'SYN_Flag_Cnt', 'RST_Flag_Cnt', 'PSH_Flag_Cnt', 'ACK_Flag_Cnt',\n",
       "       'Down/Up_Ratio', 'Pkt_Size_Avg', 'Fwd_Seg_Size_Avg', 'Bwd_Seg_Size_Avg',\n",
       "       'Subflow_Fwd_Pkts', 'Subflow_Fwd_Byts', 'Subflow_Bwd_Pkts',\n",
       "       'Subflow_Bwd_Byts', 'Init_Bwd_Win_Byts', 'Fwd_Act_Data_Pkts',\n",
       "       'Active_Mean', 'Active_Std', 'Active_Max', 'Active_Min', 'Idle_Mean',\n",
       "       'Idle_Std', 'Idle_Max', 'Idle_Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Protocol',\n",
       " 'Bwd_PSH_Flags',\n",
       " 'FIN_Flag_Cnt',\n",
       " 'SYN_Flag_Cnt',\n",
       " 'RST_Flag_Cnt',\n",
       " 'PSH_Flag_Cnt',\n",
       " 'ACK_Flag_Cnt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pick out the categorical features\n",
    "\n",
    "categorical_columns = [\"Protocol\"]\n",
    "\n",
    "categorical_columns += [c for c in train.columns if \"Flag\" in c]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flow_Duration',\n",
       " 'Tot_Fwd_Pkts',\n",
       " 'Tot_Bwd_Pkts',\n",
       " 'TotLen_Fwd_Pkts',\n",
       " 'TotLen_Bwd_Pkts',\n",
       " 'Fwd_Pkt_Len_Max',\n",
       " 'Fwd_Pkt_Len_Min',\n",
       " 'Fwd_Pkt_Len_Mean',\n",
       " 'Fwd_Pkt_Len_Std',\n",
       " 'Bwd_Pkt_Len_Max',\n",
       " 'Bwd_Pkt_Len_Min',\n",
       " 'Bwd_Pkt_Len_Mean',\n",
       " 'Bwd_Pkt_Len_Std',\n",
       " 'Flow_Byts/s',\n",
       " 'Flow_Pkts/s',\n",
       " 'Flow_IAT_Mean',\n",
       " 'Flow_IAT_Std',\n",
       " 'Flow_IAT_Max',\n",
       " 'Flow_IAT_Min',\n",
       " 'Fwd_IAT_Tot',\n",
       " 'Fwd_IAT_Mean',\n",
       " 'Fwd_IAT_Std',\n",
       " 'Fwd_IAT_Max',\n",
       " 'Fwd_IAT_Min',\n",
       " 'Bwd_IAT_Tot',\n",
       " 'Bwd_IAT_Mean',\n",
       " 'Bwd_IAT_Std',\n",
       " 'Bwd_IAT_Max',\n",
       " 'Bwd_IAT_Min',\n",
       " 'Fwd_Header_Len',\n",
       " 'Bwd_Header_Len',\n",
       " 'Fwd_Pkts/s',\n",
       " 'Bwd_Pkts/s',\n",
       " 'Pkt_Len_Min',\n",
       " 'Pkt_Len_Max',\n",
       " 'Pkt_Len_Mean',\n",
       " 'Pkt_Len_Std',\n",
       " 'Pkt_Len_Var',\n",
       " 'Pkt_Size_Avg',\n",
       " 'Fwd_Seg_Size_Avg',\n",
       " 'Bwd_Seg_Size_Avg',\n",
       " 'Subflow_Fwd_Pkts',\n",
       " 'Subflow_Fwd_Byts',\n",
       " 'Subflow_Bwd_Pkts',\n",
       " 'Subflow_Bwd_Byts',\n",
       " 'Init_Bwd_Win_Byts',\n",
       " 'Fwd_Act_Data_Pkts',\n",
       " 'Active_Mean',\n",
       " 'Active_Std',\n",
       " 'Active_Max',\n",
       " 'Active_Min',\n",
       " 'Idle_Mean',\n",
       " 'Idle_Std',\n",
       " 'Idle_Max',\n",
       " 'Idle_Min']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Threshold\n",
    "threshold = 100\n",
    "\n",
    "scale_columns = difference.loc[difference >= threshold].index.tolist()\n",
    "scale_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = difference.index.tolist()\n",
    "\n",
    "int_scale_columns = [columns.index(c) for c in scale_columns if c not in categorical_columns]\n",
    "int_scale_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 30, 40, 41, 42, 43, 44, 45]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remainder_columns = [c for c in range(len(columns)) if c not in int_scale_columns]\n",
    "remainder_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement custom scaling operation\n",
    "\n",
    "def scale_data(train, test, columns_to_scale):\n",
    "    x_train, y_train = train.drop(labels = \"Label\", axis = 1), train[\"Label\"]\n",
    "    x_test, y_test = test.drop(labels = \"Label\", axis = 1), test[\"Label\"]\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers = [\n",
    "            (\"scaler\", StandardScaler(), columns_to_scale)\n",
    "        ],\n",
    "        remainder = \"passthrough\"\n",
    "    )\n",
    "    ## Train te transformer\n",
    "    transformer.fit(x_train)\n",
    "    ## Applt transformer on train and test dataset\n",
    "    x_train = transformer.transform(x_train)\n",
    "    x_test = transformer.transform(x_test)\n",
    "    ## Get the feature aname out \n",
    "    columns = transformer.get_feature_names_out()\n",
    "    columns = [c.split(\"__\")[-1] for c in columns]\n",
    "\n",
    "    train, test = pd.DataFrame(data  = x_train, columns = columns), pd.DataFrame(data = x_test, columns = columns)\n",
    "    \n",
    "    train[\"Label\"] = y_train\n",
    "    test[\"Label\"] = y_test\n",
    "\n",
    "    return transformer, train, test ## pd.DataFrame(data = x_train, columns = columns), pd.DataFrame(data = x_test, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train, test = scale_data(train, test, int_scale_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>Fwd_Pkt_Len_Mean</th>\n",
       "      <th>Fwd_Pkt_Len_Std</th>\n",
       "      <th>Bwd_Pkt_Len_Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Bwd_PSH_Flags</th>\n",
       "      <th>FIN_Flag_Cnt</th>\n",
       "      <th>SYN_Flag_Cnt</th>\n",
       "      <th>RST_Flag_Cnt</th>\n",
       "      <th>PSH_Flag_Cnt</th>\n",
       "      <th>ACK_Flag_Cnt</th>\n",
       "      <th>Down/Up_Ratio</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.760783</td>\n",
       "      <td>-0.088635</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>-0.049230</td>\n",
       "      <td>-0.066699</td>\n",
       "      <td>-0.163651</td>\n",
       "      <td>-0.175432</td>\n",
       "      <td>-0.125471</td>\n",
       "      <td>-0.109850</td>\n",
       "      <td>-0.250528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.760731</td>\n",
       "      <td>-0.088635</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>-0.049230</td>\n",
       "      <td>-0.066699</td>\n",
       "      <td>-0.163651</td>\n",
       "      <td>-0.175432</td>\n",
       "      <td>-0.125471</td>\n",
       "      <td>-0.109850</td>\n",
       "      <td>-0.250528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.760885</td>\n",
       "      <td>-0.094511</td>\n",
       "      <td>-0.085435</td>\n",
       "      <td>-0.049315</td>\n",
       "      <td>-0.066711</td>\n",
       "      <td>-0.175276</td>\n",
       "      <td>-0.175432</td>\n",
       "      <td>-0.132751</td>\n",
       "      <td>-0.120172</td>\n",
       "      <td>-0.253601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.760765</td>\n",
       "      <td>-0.088635</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>-0.049230</td>\n",
       "      <td>-0.066699</td>\n",
       "      <td>-0.163651</td>\n",
       "      <td>-0.175432</td>\n",
       "      <td>-0.125471</td>\n",
       "      <td>-0.109850</td>\n",
       "      <td>-0.250528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.760902</td>\n",
       "      <td>-0.088635</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>-0.049230</td>\n",
       "      <td>-0.066699</td>\n",
       "      <td>-0.163651</td>\n",
       "      <td>-0.175432</td>\n",
       "      <td>-0.125471</td>\n",
       "      <td>-0.109850</td>\n",
       "      <td>-0.250528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  TotLen_Fwd_Pkts  \\\n",
       "0      -0.760783     -0.088635     -0.082789        -0.049230   \n",
       "1      -0.760731     -0.088635     -0.082789        -0.049230   \n",
       "2      -0.760885     -0.094511     -0.085435        -0.049315   \n",
       "3      -0.760765     -0.088635     -0.082789        -0.049230   \n",
       "4      -0.760902     -0.088635     -0.082789        -0.049230   \n",
       "\n",
       "   TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  Fwd_Pkt_Len_Mean  \\\n",
       "0        -0.066699        -0.163651        -0.175432         -0.125471   \n",
       "1        -0.066699        -0.163651        -0.175432         -0.125471   \n",
       "2        -0.066711        -0.175276        -0.175432         -0.132751   \n",
       "3        -0.066699        -0.163651        -0.175432         -0.125471   \n",
       "4        -0.066699        -0.163651        -0.175432         -0.125471   \n",
       "\n",
       "   Fwd_Pkt_Len_Std  Bwd_Pkt_Len_Max  ...  Idle_Min  Protocol  Bwd_PSH_Flags  \\\n",
       "0        -0.109850        -0.250528  ... -0.653222       6.0            0.0   \n",
       "1        -0.109850        -0.250528  ... -0.653222       6.0            0.0   \n",
       "2        -0.120172        -0.253601  ... -0.653222       6.0            0.0   \n",
       "3        -0.109850        -0.250528  ... -0.653222       6.0            0.0   \n",
       "4        -0.109850        -0.250528  ... -0.653222       6.0            0.0   \n",
       "\n",
       "   FIN_Flag_Cnt  SYN_Flag_Cnt  RST_Flag_Cnt  PSH_Flag_Cnt  ACK_Flag_Cnt  \\\n",
       "0           0.0           1.0           0.0           0.0           0.0   \n",
       "1           0.0           1.0           0.0           0.0           0.0   \n",
       "2           0.0           1.0           0.0           0.0           0.0   \n",
       "3           0.0           1.0           0.0           0.0           0.0   \n",
       "4           0.0           1.0           0.0           0.0           0.0   \n",
       "\n",
       "   Down/Up_Ratio  Label  \n",
       "0            1.0    NaN  \n",
       "1            1.0    NaN  \n",
       "2            1.0    NaN  \n",
       "3            1.0    NaN  \n",
       "4            1.0    NaN  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6.0\n",
       "1    6.0\n",
       "2    6.0\n",
       "3    6.0\n",
       "4    6.0\n",
       "5    6.0\n",
       "Name: Protocol, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:5, \"Protocol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'BFA', 'DDoS'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Labels\n",
    "train['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 13:47:22 WARN Utils: Your hostname, MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.198 instead (on interface en0)\n",
      "24/10/22 13:47:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/22 13:47:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 60069)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## instantiate spark session\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").config(\"spark.some.config.option\", \"some-value\").appName(\"Network Intrusion\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas DF to spark DF\n",
    "train = spark.createDataFrame(train)\n",
    "test = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assemble features in vectors\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [c for c in train.columns if c != \"Label\"], outputCol = \"feature\")\n",
    "\n",
    "##Encode labels \n",
    "string_encoder = StringIndexer(inputCol = \"Label\", outputCol = \"Int_Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 13:47:29 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Fit string encoder\n",
    "string_encoder = string_encoder.fit(test)\n",
    "\n",
    "train = string_encoder.transform(train)\n",
    "test = string_encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+-------------------+------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-------------------+--------------------+-------------------+------------------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------+-------------+------------+------------+------------+------------+------------+-------------+-----+---------+\n",
      "|      Flow_Duration|        Tot_Fwd_Pkts|        Tot_Bwd_Pkts|   TotLen_Fwd_Pkts|     TotLen_Bwd_Pkts|     Fwd_Pkt_Len_Max|     Fwd_Pkt_Len_Min|   Fwd_Pkt_Len_Mean|     Fwd_Pkt_Len_Std|    Bwd_Pkt_Len_Max|    Bwd_Pkt_Len_Min|   Bwd_Pkt_Len_Mean|   Bwd_Pkt_Len_Std|         Flow_Byts/s|         Flow_Pkts/s|      Flow_IAT_Mean|       Flow_IAT_Std|       Flow_IAT_Max|        Flow_IAT_Min|         Fwd_IAT_Tot|       Fwd_IAT_Mean|         Fwd_IAT_Std|         Fwd_IAT_Max|         Fwd_IAT_Min|        Bwd_IAT_Tot|       Bwd_IAT_Mean|        Bwd_IAT_Std|        Bwd_IAT_Max|         Bwd_IAT_Min|      Fwd_Header_Len|     Bwd_Header_Len|          Fwd_Pkts/s|         Bwd_Pkts/s|       Pkt_Len_Min|         Pkt_Len_Max|       Pkt_Len_Mean|        Pkt_Len_Std|         Pkt_Len_Var|       Pkt_Size_Avg|   Fwd_Seg_Size_Avg|   Bwd_Seg_Size_Avg|    Subflow_Fwd_Pkts|    Subflow_Fwd_Byts|    Subflow_Bwd_Pkts|    Subflow_Bwd_Byts|  Init_Bwd_Win_Byts|   Fwd_Act_Data_Pkts|         Active_Mean|          Active_Std|          Active_Max|          Active_Min|          Idle_Mean|            Idle_Std|           Idle_Max|           Idle_Min|Protocol|Bwd_PSH_Flags|FIN_Flag_Cnt|SYN_Flag_Cnt|RST_Flag_Cnt|PSH_Flag_Cnt|ACK_Flag_Cnt|Down/Up_Ratio|Label|Int_Label|\n",
      "+-------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+-------------------+------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-------------------+--------------------+-------------------+------------------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------+-------------+------------+------------+------------+------------+------------+-------------+-----+---------+\n",
      "|-0.7607830683932705|-0.08863451784447349|-0.08278855947127488|-0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359|-0.2505276386650332|-0.3102963004844384|-0.3038540528300092|-0.257449040584368| -0.1163134535688262|-0.13448763845228656|-0.5244860959641949|-0.6601252185332748| -0.706920259755148|-0.05651220262606...| -0.4592054637855426|-0.2942205233826982|-0.33461794978690784| -0.4063980453947966|-0.08640714178170446| -0.726565103671593|-0.6346355591489388|-0.6384551591492112|-0.6843875236122664|-0.06278040087672783|-0.08046578594224588|-0.0799317974311313|-0.08952289827958781|-0.1656544565401558|-0.380774285288098|-0.26859293237352805|-0.2922153326570658|-0.2622284234567351|-0.08849874601644288|-0.2865294258093877|-0.1254713382569213|-0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|\n",
      "|-0.7607306783817903|-0.08863451784447349|-0.08278855947127488|-0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359|-0.2505276386650332|-0.3102963004844384|-0.3038540528300092|-0.257449040584368|-0.11661642766565522|-0.13629956293571208|-0.5244210831198739|-0.6600864052247962|-0.7068884356729016|-0.05651086076584...|-0.45920500377291623|-0.2942196415018155|-0.33466272461956614|-0.40643024014784246|-0.08645158517493612|-0.7265354485268181|-0.6345645176275315|-0.6384065720124391|-0.6843498724724814|-0.06277616619606616|-0.08046578594224588|-0.0799317974311313| -0.0914019368955921|-0.1672940924450522|-0.380774285288098|-0.26859293237352805|-0.2922153326570658|-0.2622284234567351|-0.08849874601644288|-0.2865294258093877|-0.1254713382569213|-0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|\n",
      "+-------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+-------------------+------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-------------------+--------------------+-------------------+------------------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------+-------------+------------+------------+------------+------------+------------+-------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## peek at data\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use vector assembler \n",
    "train = assembler.transform(train)\n",
    "test = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------+-------------+------------+------------+------------+------------+------------+-------------+-----+---------+--------------------+\n",
      "|      Flow_Duration|        Tot_Fwd_Pkts|        Tot_Bwd_Pkts|     TotLen_Fwd_Pkts|     TotLen_Bwd_Pkts|     Fwd_Pkt_Len_Max|     Fwd_Pkt_Len_Min|   Fwd_Pkt_Len_Mean|     Fwd_Pkt_Len_Std|     Bwd_Pkt_Len_Max|    Bwd_Pkt_Len_Min|    Bwd_Pkt_Len_Mean|     Bwd_Pkt_Len_Std|         Flow_Byts/s|         Flow_Pkts/s|      Flow_IAT_Mean|       Flow_IAT_Std|       Flow_IAT_Max|        Flow_IAT_Min|         Fwd_IAT_Tot|        Fwd_IAT_Mean|         Fwd_IAT_Std|         Fwd_IAT_Max|         Fwd_IAT_Min|        Bwd_IAT_Tot|       Bwd_IAT_Mean|        Bwd_IAT_Std|        Bwd_IAT_Max|         Bwd_IAT_Min|      Fwd_Header_Len|      Bwd_Header_Len|          Fwd_Pkts/s|          Bwd_Pkts/s|       Pkt_Len_Min|         Pkt_Len_Max|        Pkt_Len_Mean|         Pkt_Len_Std|         Pkt_Len_Var|        Pkt_Size_Avg|   Fwd_Seg_Size_Avg|    Bwd_Seg_Size_Avg|    Subflow_Fwd_Pkts|    Subflow_Fwd_Byts|    Subflow_Bwd_Pkts|    Subflow_Bwd_Byts|  Init_Bwd_Win_Byts|   Fwd_Act_Data_Pkts|         Active_Mean|          Active_Std|          Active_Max|          Active_Min|          Idle_Mean|            Idle_Std|           Idle_Max|           Idle_Min|Protocol|Bwd_PSH_Flags|FIN_Flag_Cnt|SYN_Flag_Cnt|RST_Flag_Cnt|PSH_Flag_Cnt|ACK_Flag_Cnt|Down/Up_Ratio|Label|Int_Label|             feature|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------+-------------+------------+------------+------------+------------+------------+-------------+-----+---------+--------------------+\n",
      "|-0.7609132748961934|-0.08863451784447349|-0.08278855947127488|  -0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359| -0.2505276386650332|-0.3102963004844384| -0.3038540528300092|  -0.257449040584368|-0.11457911045318046|-0.12411546874039653| -0.524647674380392|-0.6601856658910947|-0.7069878905825654|-0.05651220262606...|-0.45932952344072264| -0.2944583556034788| -0.3347657634406231|-0.40656361841046107|-0.08654946645764867|-0.7266309863256685|-0.6347933868721644|-0.6385419889186874|-0.6844577510107556|-0.06278040087672783|-0.08046578594224588| -0.0799317974311313|-0.07876654082573557|-0.15626853453886147|-0.380774285288098|-0.26859293237352805| -0.2922153326570658| -0.2622284234567351|-0.08849874601644288| -0.2865294258093877|-0.1254713382569213| -0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7609132748961...|\n",
      "|-0.7608180037514978|-0.09451119971403625|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|-0.13923976710546043|-0.5241399965912937|-0.6597117432270476|-0.7067310646556642|-0.05650549332499649| -0.4594233372657174|-0.29463214123321113| -0.3349797409457907| -0.4067404979167786|-0.08657988901849177|-0.7267180436541634|-0.6349985121229836|-0.6386505410542636|-0.6845457404930283|-0.06276628527452224|-0.08952796321922217|-0.08413645174151108|-0.09445104696053765| -0.1699547244820334|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|-0.09451119971403625|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.6680626284915734|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7608180037514...|\n",
      "|-0.7608531735752164|-0.08863451784447349|-0.08278855947127488|  -0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359| -0.2505276386650332|-0.3102963004844384| -0.3038540528300092|  -0.257449040584368|-0.11565997794401106|-0.13057955359125945|-0.5245730922662526|-0.6601371184322274|-0.7069364881760364|-0.05651220262606...|-0.45926678921879843|-0.29433808911318315| -0.3345979333418436|-0.40643100668958165|-0.08654576284154604| -0.726617126056931|-0.6347601833729464|-0.6385430100893669|-0.6844584600014948|-0.06277828353639699|-0.08046578594224588| -0.0799317974311313|-0.08547005698083311| -0.1621179756750547|-0.380774285288098|-0.26859293237352805| -0.2922153326570658| -0.2622284234567351|-0.08849874601644288| -0.2865294258093877|-0.1254713382569213| -0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7608531735752...|\n",
      "|-0.7608897241401625|-0.09451119971403625|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|-0.13643126825638582|-0.5243476648359897|-0.6599470303058402|-0.7068570210232923|-0.05650817704542...| -0.4594049655114508|-0.29452648089315503| -0.3349797409457907|-0.40669967956916686| -0.0864108453978071|-0.7267182556659222|-0.6350000358017269|-0.6386505410542636|-0.6845460390154448|-0.06277193151540447|-0.08952796321922217|-0.08413645174151108|-0.09153852061553354|-0.16741327444021337|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|-0.09451119971403625|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.6680626284915734|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7608897241401...|\n",
      "|-0.7608276428883688|-0.09451119971403625|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919| -0.1389661147899563|-0.5241679069621346|-0.6597458345486354|-0.7067488563648031|-0.05650415146478344| -0.4594203471836458| -0.2946149445581472| -0.3349797409457907|-0.40673385455503897|-0.08655237644172932|-0.7267179376482839|-0.6349977502836119|-0.6386505410542636|  -0.68454559123182|-0.06276346215408113|-0.08952796321922217|-0.08413645174151108|-0.09416725849384662|-0.16970709265828107|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|-0.09451119971403625|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.6680626284915734|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7608276428883...|\n",
      "|-0.7607273177097461|-0.08863451784447349|-0.08278855947127488|  -0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359| -0.2505276386650332|-0.3102963004844384| -0.3038540528300092|  -0.257449040584368|-0.11663253959502935|-0.13639591968519008|-0.5244169127286746|-0.6601234157188668|-0.7069201853128505|-0.05651052530079541| -0.4591767417471823| -0.2941654609519648|-0.33488450020541144|-0.40651347380502256| -0.0859817550179158|-0.7265221447889476|-0.6345326473472139|-0.6383531686597449|-0.6843152065568616|-0.06277687197617643|-0.08046578594224588| -0.0799317974311313| -0.0915018627244873| -0.1673812870218361|-0.380774285288098|-0.26859293237352805| -0.2922153326570658| -0.2622284234567351|-0.08849874601644288| -0.2865294258093877|-0.1254713382569213| -0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7607273177097...|\n",
      "|-0.7603883848159831|-0.06512779036622246| -0.0695539452131856|  -0.049229903531959|-0.06658317155133996|-0.16365055468451684|-0.17543184217636523|-0.1303246717800687|-0.11421287544810269| -0.2505276386650332|-0.3102963004844384|-0.28935819527677936| -0.2583665402108411|-0.11394420207029907| -0.1309040894671716|-0.5245904760089808|-0.6600491271240708|  -0.70669916613112| -0.0565165636717541|-0.45875284011196243|-0.29428984622633797| -0.3344521951371839| -0.4059392062854147|-0.08658861897073371|-0.7262050282005856|-0.6347196496114713|-0.6384022733364015|-0.6841806848929121|-0.06277828353639699|-0.04421707683434...|-0.05890852587923235|-0.08698280238896515| -0.1613853188063012|-0.380774285288098|-0.26859293237352805|-0.28512989484308104| -0.2612308226799502| -0.0884973607935884| -0.2804761988420036|-0.1303246717800687|-0.28935819527677936|-0.06512779036622246|-0.04920297966010...| -0.0695539452131856|-0.06650728357782669|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7603883848159...|\n",
      "|-0.7607346903468664|-0.08863451784447349|-0.08278855947127488|  -0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359| -0.2505276386650332|-0.3102963004844384| -0.3038540528300092|  -0.257449040584368|-0.11659674829820688|-0.13618187126341808|-0.5244260617265375|-0.6600681364526148|-0.7068885101151993|-0.05651186716100845|-0.45920923013892123| -0.2942277437814129| -0.3346612453377872|-0.40646524555393204|-0.08658174082654309|-0.7264837706605882|-0.6344407187296369|-0.6382658537069881|-0.6842546065063057|-0.06277969509661754|-0.08046578594224588| -0.0799317974311313|-0.09127988589604688|-0.16718759159968458|-0.380774285288098|-0.26859293237352805| -0.2922153326570658| -0.2622284234567351|-0.08849874601644288| -0.2865294258093877|-0.1254713382569213| -0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7607346903468...|\n",
      "| -0.760795703478088|-0.08863451784447349|-0.08278855947127488|  -0.049229903531959|-0.06669877124632466|-0.16365055468451684|-0.17543184217636523|-0.1254713382569213|-0.10985029194127359| -0.2505276386650332|-0.3102963004844384| -0.3038540528300092|  -0.257449040584368| -0.1162219451387872|-0.13394037594359032|-0.5245017753422592| -0.660128616645834|-0.7069482872802143|-0.05651253809111497| -0.4592092876404995| -0.2942278540165646| -0.3346669144666456|-0.40646914214110624|-0.08657327541830849| -0.726615005939342|-0.6347551044437385|-0.6385387088487188| -0.684454616525382|-0.06277969509661754|-0.08046578594224588| -0.0799317974311313|-0.08895536503324217| -0.1651592310136525|-0.380774285288098|-0.26859293237352805| -0.2922153326570658| -0.2622284234567351|-0.08849874601644288| -0.2865294258093877|-0.1254713382569213| -0.3038540528300092|-0.08863451784447349|-0.04920297966010...|-0.08278855947127488|-0.06662268079378793|-0.8464264574468668|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.7607957034780...|\n",
      "|-0.7608924595708962|-0.09451119971403625|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|-0.13627459030200453|-0.5243555853465909|-0.6599270637389686| -0.706850023447313|-0.05650649972015627| -0.4594135332466174| -0.2945757559813189| -0.3349797409457907|-0.40671871535569004|-0.08648967951199181|-0.7267181231585729|-0.6349990835025124|-0.6386505410542636|-0.6845458524389344|-0.06276840261485309|-0.08952796321922217|-0.08413645174151108|-0.09137603927083508|-0.16727149435949853|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|-0.09451119971403625|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.6680626284915734|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     6.0|          0.0|         0.0|         1.0|         0.0|         0.0|         0.0|          1.0|  BFA|      2.0|[-0.7608924595708...|\n",
      "|-0.6309654395137971|-0.09744954064881763|-0.08675894374870166|-0.04919021524772361|-0.06669288617094361|-0.15822517338989148|  0.4399974958546557|-0.0900420035379454| -0.1201722753448156|-0.24909331310221097| 0.6508083405263955|  -0.266817136792618|-0.26682152943537213|-0.11817397201960107| -0.1456426106994915| 0.6051974835058159|-0.6602835916569161|-0.5212023972156885|  1.6186130838602366| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267187591938497|-0.6350036545387423|-0.6386505410542636|-0.6845467480061841|-0.06278534133749979|-0.09745736833657644|-0.08886668784068835|-0.10109105346895164|-0.17574874754638775|1.3632757328898661| -0.2671957150587086|-0.24613713063369766|-0.27014783620481136|-0.08850391849752344|-0.22076543848593885|-0.0900420035379454|  -0.266817136792618|-0.09744954064881763|-0.04916333294202768|-0.08675894374870166| -0.0666168060264299|-0.8533345777721929|-0.07067959423002035|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|    17.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          1.0|  NaN|      0.0|[-0.6309654395137...|\n",
      "|-0.7610528079153321|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  1.1703078421200186| -0.524816559063582|-0.6602835916569161|-0.7070634867358316| -0.0565071706502628| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267181761615127|-0.6349994644221982|-0.6386505410542636|-0.6845459270695385|-0.06276981417507364|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|   2.205900580986336|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610528079153...|\n",
      "|-0.7610530163291023|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  1.9222828430758916|-0.5248183694660052|-0.6602835916569161|-0.7070637845050223|-0.05650985437068888| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267183881732715|-0.6350009881009415|-0.6386505410542636|-0.6845462255919551|-0.06277546041595587|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|  3.5668460535269926|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610530163291...|\n",
      "|-0.7610528860704959|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|   1.378090408068858|-0.5248172379644908|-0.6602835916569161|-0.7070635983992781|-0.05650817704542...| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267182556659222|-0.6350000358017269|-0.6386505410542636|-0.6845460390154448|-0.06277193151540447|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|  2.5819513034724517|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610528860704...|\n",
      "| -0.761052026363694|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  0.4111023128864302|-0.5248097700544953|-0.6602835916569161|-0.7070623701013669|-0.05649710669866496| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267173811174168|-0.6349937506269108|-0.6386505410542636|-0.6845448076104765|-0.06274864077176526|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|   0.831869095332045|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610520263636...|\n",
      "|-0.7610530944842662|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|    2.48626409245381|-0.5248190483669138|-0.6602835916569161|-0.7070638961684687|-0.05651086076584...| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267184676776811|-0.6350015594804703|-0.6386505410542636|-0.6845463375378613|-0.06277757775628671|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|  4.5875551555091505|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610530944842...|\n",
      "|-0.7610524692429556|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  0.6815240918388763|-0.5248136171596445|-0.6602835916569161|-0.7070630028608968| -0.0565028096045704| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267178316424044|-0.6349969884442404|-0.6386505410542636|-0.6845454419706117|   -0.06276063903364|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|   1.321286024450568|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610524692429...|\n",
      "| -0.761052990277381|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  1.7844207585757417|-0.5248181431657023|-0.6602835916569161|-0.7070637472838734|-0.05650951890563...| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267183616718017|-0.6350007976410986|-0.6386505410542636| -0.684546188276653| -0.0627747546358456|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|   3.317339381766628|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610529902773...|\n",
      "|-0.7610522087257429|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  0.4977079806195619|-0.5248113541566155|-0.6602835916569161|-0.7070626306494086|-0.05649945495403779| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267175666277058|-0.6349950838458112|-0.6386505410542636| -0.684545068817591|-0.06275358123253721|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|  0.9886104647232365|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610522087257...|\n",
      "|-0.7610525734498407|  -0.100387881583599|-0.08543548232289273|-0.04931494985532057|-0.06671138212214116| -0.1752763717444283|-0.17543184217636523|-0.1327513385416424| -0.1201722753448156| -0.2536011934425094|-0.3102963004844384|-0.31146437804317184|-0.26682152943537213|-0.11817965950549919|  0.7882560273809054| -0.524814522360856|-0.6602835916569161|-0.7070631517454922|-0.05650415146478344| -0.4594249185591206| -0.2946412356286776| -0.3349797409457907| -0.4067440112330832|  -0.086594438938895|-0.7267179376482839|-0.6349977502836119|-0.6386505410542636|  -0.68454559123182|-0.06276346215408113|-0.09859014049619848|-0.08939226962948582|-0.10109706602483479|  1.5144524784773414|-0.380774285288098| -0.2715869694767127|-0.30044358301886637|-0.27014783620481136|-0.08850391849752344| -0.2949607062354709|-0.1327513385416424|-0.31146437804317184|  -0.100387881583599|-0.04928793691312...|-0.08543548232289273| -0.0666352695809837|-0.8533345777721929|-0.07839521775395197|-0.14844887471593235|-0.11076468891383316|-0.16697881058439065|-0.11041645976391577|-0.6710726506863514|-0.16107288675639547|-0.6803538536838091|-0.6532215639427359|     0.0|          0.0|         0.0|         0.0|         0.0|         0.0|         0.0|          0.0|  NaN|      0.0|[-0.7610525734498...|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------+-------------+------------+------------+------------+------------+------------+-------------+-----+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modelling\n",
    "    1, Logistic regression\n",
    "    2, Decision Tree \n",
    "    3, OVR + Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate our models\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(featuresCol = \"feature\", labelCol = \"Int_Label\", predictionCol = \"prediction\", maxDepth = 10, impurity = \"entropy\")\n",
    "log_model = LogisticRegression(featuresCol = \"feature\", labelCol = \"Int_Label\", predictionCol = \"prediction\", maxIter = 500, aggregationDepth = 2)\n",
    "ovr_model = OneVsRest(\n",
    "    featuresCol = \"feature\", labelCol = \"Int_Label\",\n",
    "    classifier = LogisticRegression(featuresCol = \"feature\", labelCol = \"Int_Label\", predictionCol = \"prediction\", maxIter = 500, aggregationDepth = 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIt models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 13:47:53 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtc_model = dtc_model.fit(train)\n",
    "log_model = log_model.fit(train)\n",
    "ovr_model = ovr_model.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOdel Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_score(model, data, metric):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol = \"Int_Label\", predictionCol = \"prediction\", metricName = metric)\n",
    "    predictions = model.transform(data)\n",
    "    score = evaluator.evaluate(predictions)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metric, train_score, test_score):\n",
    "    print(f\" Train {metric.capitalize()} = {100 * test_score: .3f}%\")\n",
    "    print(f\" Test {metric.capitalize()} = {100 * test_score: .3f}%\")\n",
    "    print(f\" Generalization error {100 * (test_score): .3f}%\")\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data, metric):\n",
    "    train, test = data\n",
    "\n",
    "    if isinstance(metric, str):\n",
    "        train_score = generate_model_score(model, train, metric)\n",
    "        test_score = generate_model_score(model, train, metric)\n",
    "\n",
    "        print_metrics(metric.lower(), train_score, test_score)\n",
    "    else:\n",
    "        for m in metric:\n",
    "            train_score = generate_model_score(model, train, m)\n",
    "            test_score = generate_model_score(model, test, m)\n",
    "\n",
    "            print_metrics(m.lower(), train_score, test_score)\n",
    "            print(\"=\"*20 + \"\\n\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics\n",
    "\n",
    "metrics = [\"accuracy\", \"weightedRecall\", \"weightedPrecision\", \"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Accuracy =  97.436%\n",
      " Test Accuracy =  97.436%\n",
      " Generalization error  97.436%\n",
      "====================\n",
      "\n",
      " Train Weightedrecall =  97.436%\n",
      " Test Weightedrecall =  97.436%\n",
      " Generalization error  97.436%\n",
      "====================\n",
      "\n",
      " Train Weightedprecision =  95.765%\n",
      " Test Weightedprecision =  95.765%\n",
      " Generalization error  95.765%\n",
      "====================\n",
      "\n",
      " Train F1 =  96.483%\n",
      " Test F1 =  96.483%\n",
      " Generalization error  96.483%\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Decision tree\n",
    "test_model(dtc_model, [train, test], metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Accuracy =  97.517%\n",
      " Test Accuracy =  97.517%\n",
      " Generalization error  97.517%\n",
      "====================\n",
      "\n",
      " Train Weightedrecall =  97.517%\n",
      " Test Weightedrecall =  97.517%\n",
      " Generalization error  97.517%\n",
      "====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Weightedprecision =  96.593%\n",
      " Test Weightedprecision =  96.593%\n",
      " Generalization error  96.593%\n",
      "====================\n",
      "\n",
      " Train F1 =  96.631%\n",
      " Test F1 =  96.631%\n",
      " Generalization error  96.631%\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## logistic regression\n",
    "test_model(log_model, [train, test], metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ovr + logistics regression\n",
    "test_model(ovr_model, [train, test], metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get model weight \n",
    "## Extract weights by label\n",
    "## Combine. the weight plus features\n",
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights\n",
    "weights = log_model.coefficientMatrix.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 63)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_per_label(weights, columns, label = 0):\n",
    "    label_weights = weights[label].tolist() #Extract label weights\n",
    "    data = dict(zip(columns, label_weights))\n",
    "    return pd.Series(data = data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol          -10.615265\n",
       "Flow_Duration       2.931037\n",
       "Tot_Fwd_Pkts        3.830585\n",
       "Tot_Bwd_Pkts       17.734891\n",
       "TotLen_Fwd_Pkts     5.270902\n",
       "                     ...    \n",
       "Active_Min        -23.552575\n",
       "Idle_Mean          -0.775006\n",
       "Idle_Std           15.073389\n",
       "Idle_Max          -21.340749\n",
       "Idle_Min           -1.511181\n",
       "Length: 63, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_per_label(weights, columns, label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weights_per_label(weight, columns, label = 1, large = True, num_weights = 10):\n",
    "    label_weights = weights_per_label(weights, columns, label)\n",
    "    \n",
    "    label = pd.DataFrame(data = [label], columns = [\"Int_Label\"])\n",
    "    label = spark.createDataFrame(label)\n",
    "    label_mapper = IndexToString(inputCol = \"Int_Label\", outputCol = \"Label\", labels = string_encoder.labels)\n",
    "\n",
    "    label = label_mapper.transform(label).toPandas()\n",
    "    label = label[\"Label\"].values.item()\n",
    "\n",
    "    label_weights = label_weights.sort_values(ascending = False)\n",
    "\n",
    "    if large:\n",
    "        final_weights = label_weights.head(n = num_weights)\n",
    "        title = f\"Top {num_weights} largest (or positive) weights for the `{label}` label\"\n",
    "    else:\n",
    "        final_weights = label_weights.tail(n = num_weights)\n",
    "        title = f\"Bottom {num_weights} smallest (or negative) weights for the `{label}` label\"\n",
    "    \n",
    "    x, y = final_weights.index, final_weights.values\n",
    "\n",
    "    plt.bar(x=x, height=y)\n",
    "    plt.title(title, fontsize = 25, pad = 5)\n",
    "\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Feature weights\")\n",
    "\n",
    "    plt.xticks(rotation = 45)\n",
    "\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_weights_per_label(weights, columns, label = 1, large = True, num_weights = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAAIwCAYAAABOYfRiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAADZ+klEQVR4nOzdd3gUVfv/8c8GQuiE3nuRjnQILSACClbkAQGpgihFAZXwiCAogg0RVPpDERQFKQqKonQB6UgNSG+BYCABAiHl/P7gl/nupk5Ckk3k/bquvZKdPTNzz+7Ue86c4zDGGAEAAAAAACBBHu4OAAAAAAAAICMgiQIAAAAAAGADSRQAAAAAAAAbSKIAAAAAAADYQBIFAAAAAADABpIoAAAAAAAANpBEAQAAAAAAsIEkCgAAAAAAgA0kUQAAAAAAAGzI7O4AAAAAAAD3nDhxQl999ZUkKXPmzHr99deVNWtWN0eFpNq9e7d+/PFHSVKuXLk0bNgwORwON0eFlEASBQAAAADSifLly+vkyZNWIuX8+fOaPn26m6NCUtWsWVNvvvmm1q1bJ0kKDw+Xn5+fm6NCSuBxHgCpxuFwWK/Tp0/HWWbevHlWGV9f3zSNLyM7efKksmbNKofDoV69erk7HPzLbdiwwdpOy5Qp4+5w7ktUVJSqVq0qh8Oh8uXLKywszN0hpVvu3j+XKVPGmv+GDRvSfP7pSWBgoMaOHavGjRsrX758ypw5s/XdPMjHgF69elnfwzvvvOPucFLU7Nmz1axZM0nSjBkztHTpUjdHhKTy9PTU999/r4ceekiS9Pbbb2v79u2pOk937TdPnz7tct6f3r3zzjv3tQ9NVhLFeYcV3ytLliwqWLCg6tWrp5dfflkbNmyQMSY5s0MGFxYWpp07d+rLL79Unz59VKNGDZeD//2emN2+fVvz589Xu3btVKZMGWXNmlVFixZV48aN9cEHHyggICBlFgRIR4YPH66wsDBlyZLlX3fiCKQmDw8Pvfvuu5LuJSMnT57s3oCARPz111+qXr263nnnHW3fvl3Xrl1TZGSku8NCKsuSJYuWL1+uChUqSJL69esX7w2p+CR0zZYpUyblzZtXZcqUUa1atfSf//xHH3zwgdatW6eIiIgkx5vQdWHWrFlVuHBhVapUST4+Pnr55Zc1Z84c+fv7J3k+qS08PFxLly5Vr169VL16deXPn1+enp7KkSOHihUrJh8fH/Xu3Vtffvml/vrrr0Sn5+3trdWrV6tAgQKKiIjQ888/r+vXr6f+giB1mWTo2bOnkZTkV4sWLczJkyeTM8v71qJFCyuOuXPn2hrn1KlTLvEj6Xr37m08PT0TXS+Sa8+ePaZy5coJTj9Pnjzmm2++SbmFgm3Ov8OpU6fiLDN37twUWRfcKa2XYcuWLdb8XnzxxVSfH/5d7GyXMa1fv94ap3Tp0qkaX1qIiooy1apVM5JM7ty5TVBQkLtDSpfcvX8uXbq0Nf/169en++mmhqioKFOjRg0rXofDYWrUqGEeffRR07ZtW9O2bVvz8ccfuzvM+5bcfYzzNcmYMWNSLT538vf3N3nz5jWSTKNGjUx4eLjtcZN7zVa0aFEzatQoc+nSJdvzSs58JJmmTZuahQsXmsjIyOR8PSlq9erVpmTJkkmKv1ixYiY4ODjRaW/evNl4eXkZSaZjx46ptgzu2r9ltOvmMWPGWLH27NkzyePfd5soefPmVYMGDWINDw0N1blz51wyphs3blTz5s21bds2lShR4n5njQzg5MmTCg8PT5VpHzp0SL6+vgoJCbGGFS1aVBUrVlRQUJAOHTokY4yCg4P1/PPPKyIiQt27d0+VWIC0NHr0aEn37voMHz7czdEAGY/D4dDrr7+u3r17KyQkRJMmTbJqpwDpyc6dO3XgwAFJ92pRbdiwwXrEAw+GSpUqadmyZWrTpo22b9+ut956Sx988EGSpxPXNVtoaKiuXbumgIAAXb161Rp+6dIlvffee5o2bZpmzJihjh07Jmle1atXV/Hixa330efj169f1+nTp10eo9yyZYu2bNmiWbNmacGCBSpVqlSSly0lTJ8+XS+//LLLsEyZMqlSpUoqVKiQHA6Hrl69qmPHjunu3btWmYsXL7q8j0/Tpk01Z84cde/eXd9//72mTZsWa37IOO47iVKzZk2tWbMm3s+PHz+uN954QytXrpR0r2Gk1157jef6HjBeXl6qUaOG6tevr3r16mnJkiUJrjeJuXPnjp588kkrgZIzZ07Nnj1bnTp1kofHvafUjh07pl69emnbtm2SpBdffFEPP/ywqlevfv8LBLjJn3/+aTVQ1rp1a1WuXNnNEeFB4Ovr+697JLdr1656/fXX9c8//2jq1KkaMWKEcubM6e6w0pVevXo90O1tpAe7d++2/m/WrBkJlAeUr6+vZsyYoT59+uijjz5Sq1at1LZt2yRNI7FrtpMnT2rdunX6/PPPtX//fknSP//8o+eee04TJ07UiBEjbM9r+PDh8e477t69q71792rZsmWaOXOm9WjLxo0b9fDDD+uPP/5QlSpVbM8rJezatUsDBw603ufLl09jx47VCy+8oDx58riUvXv3rnbt2qVly5Zp8eLFunDhgu35dOvWTceOHdO4ceM0bNgwNW3aVDVq1Eix5UDaSfWGZStWrKhly5a5tHuxYsUK/fPPP6k9a6QDfn5+2rVrl27cuOHSLkrhwoXva7pffvmlTp48KeneHcUVK1aoc+fOVgJFupe5/+2331SpUiVJ99pmeeutt+5rvoC7ffbZZ9b/ffv2dWMkQMaWJUsWq3ZicHCw5s+f7+aIgNiCgoKs/0uWLOnGSOBuvXv3ljFGUVFRSU6g2FGuXDm9+OKL2rdvn+bNm6ds2bJZn40cOVLLly9PkflkyZJFDRs21AcffKCzZ8+qc+fO1mfXrl3TE088kebXiW+//baioqIkSblz59bWrVs1aNCgWAkU6V78Pj4++vjjj3X69Gl98803Lt9VYsaOHStjjG7fvk0CJQNLk955PDw89Nprr1nvIyMjtWvXrrSYNdysXbt2qlu3rjw9PVNsmlFRUfroo4+s9507d9YjjzwSZ9ns2bO7XHT+8MMPOnLkSIrFAqSloKAgff/995KkHDly6KmnnnJzREDG1rVrV+v/GTNmuDESIG7Oj0RnypTJjZHgQdKzZ0+tXbtWmTPfe2jBGKOXXnpJoaGhKTqfXLlyafHixS6PtZw4cUJjxoxJ0fkk5MaNG/r999+t94MHD7Z600lM5syZ1aVLF+XIkSO1wkM6lWZdHMescm43w3js2DG99dZbql+/vgoXLiwvLy8VLVpUPj4+evfdd3Xu3LkEx49uFXrjxo3WsN69e8fZcnR0t43RXfqVLVs2zmnFfCXUM0ZkZKQWLVqkTp06qVy5csqRI4dy5cqlChUqqHv37lq+fLmtKtLxdS956NAhDR48WFWrVlWuXLmUI0cO1a1bV5988kmc3TZevXpV77zzjurUqaNcuXIpW7ZsqlSpkl577bUM04vN1q1bXWIdMGBAguXbtm3r8p0tW7YsxWI5c+aM3nnnHbVo0cJaP728vFSgQAHVqVNHL7zwgqZPn66LFy/GOX583YGdPn1a//3vf1WrVi3lzZtXWbNmVbVq1TR69GiXNmCi3bx5Ux9//LF8fHyUJ08eeXl5qUyZMnrxxRd1/Phx28tz9OhRTZ48WR07dlTlypWVO3dueXp6qkCBAnr44Yc1aNAg6/EodzLGaMWKFerdu7cqV66svHnzKlu2bCpVqpSefPJJ/e9//0tSWzw7duzQoEGDVKdOHavryOzZs6tYsWJq0qSJBg4cqO+++063bt1yGS+61fvevXtbwzZu3BjvvuJ+u5pbsmSJ9dxtu3btlDVr1iSNv2HDBg0YMEBVq1a1vrPSpUvr8ccf17Rp02ItX3zi6ro6MDBQkyZNUtOmTVWiRAl5enom2LV1YuLrtvKXX36x9qdZs2ZVgQIF1KxZM02ePDlZXdXu2LFDw4cPV+3atVWoUCF5eXmpSJEiatasmSZMmODyjLgdoaGhmjx5spo0aaKCBQsqW7ZsqlChgjp16qRff/010eWLy5kzZzRjxgx17dpVNWrUkLe3tzw9PZUvXz5VrVpVL774on755ZcEp+F8DHFWtmzZONfVmNWwE+vi+D//+Y/1ebdu3RKMJaZq1apZ477//vsJlr1586ZmzJihJ5980uWYWrFiRfXu3dvlO7ajfv36VhttBw4csNXTQmLq1atnLU9Cjy7H3P/Xq1cvwel26dLFKjtx4sQEy6bUPjI5XRz/+uuv6tKli0qXLm31ltekSRNNnTrVOn7dT5fZYWFhmjt3rlq1aqXixYvLy8tLxYoV01NPPZXg8d35+z5z5ow1vGXLlnFuA/Et7/0e9+1w7npz7Nix1vD58+fbjlOSLly4oPHjx6tJkyYqWrSovLy8VKhQIdWtW1cjR460fVMprv1VVFSUVq5cqU6dOqlixYrKmTNnsroZjl7Wli1bWsPOnDkT73F03rx5tqab3o8VGUGTJk00btw4631gYKBmzZqVKvP69NNPXWplzJkzx9Z1ye3btzVjxgy1b99epUuXVrZs2eTt7a3KlSurf//+LsmR+Jw+fdplf9i4cePkLUQGlBbn/SdPnpSfn59q1qypvHnzKmfOnKpataqGDRuWpGuUaHfv3tXChQvVuXNnVaxYUblz51b27NlVtmxZdenSRUuXLk2bx4+T05qtc0vPdltr/+uvv1xa7F25cmWC5SMiIsybb76ZaM8u2bJlMxMmTIh3OgmNG/MV3Rq4c2v0dl7xtQa+a9cuq/X/hF4NGzY0x44dS/D7iKvV8k8//dRkzpw5wemGhIRY0/j5559Nvnz54i3v7e1tduzYkWAcKSU561A0Pz8/a9ycOXOaiIiIRMd56aWXrHEaN26czKhdffrpp1Yr24m9smXLFuc04mrJevHixSZHjhzxTqt8+fLmwoUL1jR27tyZYEviWbNmNT/88EOiy1O3bl3b6/yzzz5rbty4keg0ncdJqd55du3aZWrXrp1ojBUrVjS7du1KcFp37twxPXr0sL3cjz32mMv4SW31/n5bSX/00Uetac2aNcv2eIGBgaZDhw6Jxle8eHGzevXqRKcX83f96aefTMGCBeOcpt3eX2KK2ePCjRs3TJcuXRKM/6GHHjLnzp2zNf0rV66Yjh07JvqdeHt7m/nz59ua5s6dO03ZsmUTnF63bt3MrVu3bPco8cwzzxiHw2Fr/WrWrJkJCAiIczrOxxA7r5gt1SfWc8aKFSusz3PkyGFu3rxp6zvbu3evNZ7D4TCnT5+Ot+yiRYtMkSJFEo29TZs2JjAw0Nb8jTGmT58+1rhvv/227fHiM2zYMGt6AwcOjLdczHONTJkymevXr8db3nnZt23bFm+5lNxHJmX/HBoaav7zn/8kOM+yZcuaPXv22O6JJWYvE8ePHzcPP/xwgvN45plnTFhYWKxpxTzeJvaKa3lT4rhvh3OvEcmJ0xhjPvnkkwTPJSSZzJkzm6FDhyba20vM/VVAQIB55JFH4pxmUnvIScqySrF72MyIx4q0dD/n28YYc/PmTZMnTx5rGlWqVIm3bEK/kx1fffWVyzQ++OCDBMv/8ssvplSpUon+Nu3atTOXL1+Odzp//PGHS/nFixcnOfb0xG7vPCl93h/XNc1XX31lsmXLFu90s2bNaqZOnWp72X755RdTvnz5ROOtV69eoj0Cu713HrtiZrESatwzKipKzz//vJYsWWINczgcqlKligoVKqSLFy/q2LFjku5lIEeOHKnz58/r888/jzWt6GcGd+zYoWvXrlnzdm4xOlp0Ox3FixdX27Ztdfv2bW3atCnWtGKK7r/d2datW/XYY4+51BrImzevqlSpoqioKB0+fNj67M8//1SzZs30+++/q1q1avF+L86mT5+uoUOHSpLy5MmjqlWrKnPmzPrrr78UHBxsTbdTp05as2aNNmzYoKeeekp3796Vp6enatSooTx58ujvv/+2avNcv35dHTp0kL+/v7y9vW3F4Q7RjV1J9+4i2qne2rhxY6uq9l9//SVjTKw7skkxc+ZM6/uPVrZsWZUqVUqZM2dWcHCw/v77b6uxrOjnLBPz008/6fnnn5cxRtmzZ1eNGjWUNWtWHTlyRFeuXJF0r5pj27ZttXfvXh0/flytW7dWcHCwPDw8VK1aNRUoUEDnzp3T33//LeleI7ydO3fWwYMHVa5cuXjnvW/fPut/T09PVaxYUQUKFFCmTJl05coVHT16VJGRkZLu1ea5dOmSNm3aZFX1TAtr1qzRc88951JjokCBAqpYsaK8vLx06tQp6w7j8ePH1bJlS/3yyy/x3lXo3bu3vvnmG+t95syZ9dBDD6lQoUIyxigoKEjHjh3TnTt3JMX+HWvUqKG2bdvqwoULOnjwoKT4eyyT7jVUlly3b9/W5s2brffNmze3Nd7ly5fVqlUrHT582Brm5eWl6tWrK0eOHDp+/LguXbok6d5dy6eeekpfffWVunTpYmv6W7duVc+ePRUREWHtpwsXLqyrV6+6zPN+REZGqmPHjlYtg6JFi6pChQqKjIzU/v37rfXB399fHTp00K5duxJcL0+dOqU2bdpY24gkZcuWTdWqVVPu3Ll1+fJlHT58WMYYXb9+XT179lRwcLAGDx4c7zQPHDigNm3aWMcZ6V415apVq8rT01P+/v4KDAzUokWLFB4ebvv56ej9lXSvKn/58uVVqFAhZcmSRf/884+OHDli1U7avHmzmjRpoj179ih37twu08mXL591DHOutdK8efM4Y0nqc9qPPfaY8ubNq2vXrunWrVtauXKly6My8Vm0aJH1f5MmTVS6dOk4y7377rtWr1TRypQpo1KlSikyMlJHjhyx2o749ddf1axZM23evFkFChRINIYWLVrof//7n6R7343zndfk8PX11aRJkyQpwdpnMT+LjIzU5s2b1aFDh1hljx49at2VzZkzZ7y1VlJ6H2lXRESEnnnmGZd1y+FwqFq1aipYsKAuXbqko0eP6tSpU2rdurXLY7Z2BQQEqHv37lYjjpUqVVLx4sV1/fp1/fXXX9bxafny5Ro2bFisc8Js2bJZ28DGjRut/Xr9+vXj3DfXrFnT5X1qHffjUqFCBSvWv//+WydOnJAkFStWLNa2GTNO6V6jntHroPM0S5QooatXr1q9F0ZEROjTTz/VyZMntXTpUlvH87CwMD3++OPas2ePpHvnzhUrVlRERIT8/f2TvaxBQUHauXOnJClr1qxq0aJFnOXjOn+PlhGOFRlNjhw51KVLF+sc+siRIwoMDFTBggVTfF7/+c9/9Morr+jGjRuSpE2bNunNN9+Ms+yyZcvUpUsXlxokhQsXVqVKlXT79m0dPHjQ2sbXrFmjZs2aaf369SpWrFisaeXPn9/l/YYNG1zaafm3Su3z/lWrVumFF16QdO/8Jfra89SpUzp79qyke9cogwcPVmRkpF599dUEpzdv3jz169dPERER1rBixYqpXLly8vDw0LFjx6zj5K5du+Tj46PNmzfHeZ2eIpKcdjFJz2oGBga63J1r1KhRguU//PDDWBnEEydOuJQ5cOCAadSokUu5BQsWxDvNFi1aJDk7mtz+rq9du2aKFy9ujZcrVy4zZ84cc/fuXavM7du3zaRJk1zuaFStWtXcuXMnzmk637XJkSOH8fLyMjly5DCzZs1yme6dO3dc7oJJMitWrDBFixY1kszQoUNNUFCQy7QXLlzoUuPnrbfesr2syXU/mfEyZcpY47744ou2xtm8ebPLd3LmzJlkRH3P3bt3XWr0PPXUU7HWz2hHjx41EyZMMJUqVYrz85jrWL58+UzmzJnNhAkTTGhoqFUuMjLSfPzxxy5lZ82aZWrVqmUkma5du7rUTjHGmLVr15rcuXNb5bt165bgcuXPn9+8+uqrZtOmTS7rVLSgoCDz3nvvuayz77//foLTdI73fmuiHD9+3OTMmdMq26BBA7NhwwYTFRXlUu7PP/90uQtbunTpOO/u7tq1yyW+UaNGmWvXrsUqFxERYf744w8zZMgQ06lTp/tahvvhvA/IkyeP7fHat29vjedwOMzrr7/uspxRUVHmxx9/NMWKFbPKZcuWzfj7+8c7TefvLVeuXEaSef75583Zs2ddyl28eNFlPU4K531E/vz5rX1kzLsqoaGh5tVXX3WJafbs2fFO986dO9Z2I8kULVrUfPXVV7HuXJ87d87lbqanp6fZuXNnnNMMDw83NWvWtMp6eXmZTz/91Ny+fdsqExERYRYvXmwtS4ECBazyCd25rVGjhunbt69Zs2aNy/Si3bx503z55Zcudwr79+8f7/SMsbddxmSn5kD//v2tMu3bt090mlFRUaZEiRLWONOmTYuz3OLFi11i7tatW6zam5GRkea7775z+V6ffvppW8t2+PBhaxwPDw/btWjic/36dePh4WFtc1euXImzXPTdQue7dMOHD4+z7LRp06wybdu2jbNMSu8jjbG/b/vggw9cfqMnnngiVq2io0ePGl9f31jrv92aKNHbzpNPPmmOHz/uUu7cuXOmZcuWLr9jQjV87d6pjZaSx/2kSurd0u+++87lt6hfv77Zt2+fS5nTp0/Hqp04bty4eKfpvD+O3ueXL1/e/PLLLy7r1927d2MdB+yyWzspodjS+7HCHe63JooxxsyfP9/le1u2bFmc5ZzLJKcmijHGZTv29vY2kZGRscqcPHnSZV9XpEgRs3z5cpeywcHBZuTIkS41OVu3bh1rf2jMveOH8/bt4eGRoWuj2N2/pfR5f8xrmuj9/PPPP28uXbrkUnb9+vWmXLlyVtnMmTOb/fv3xzvtLVu2mEyZMlnl27VrZ/bs2ROr3K+//uoy3fr168db0+5+a6KkWhLl9u3b5tixY+aLL75wedQgR44cZvfu3fFO+/LlyyZr1qxW+ccffzzexzVu3bplGjRoYJXNly9fvCfsaZlEGTp0qMvOdOPGjfGWXbJkics8Jk6cGGe5mFWxM2XKZDZs2BDvdFu1amWVzZIli5Fk3nvvvXjLO69IpUqVsr2syZXcnXpUVJR1cprYQd/ZmTNnXL6/hH6TxGzatMmaTtmyZePc8cQU3zocV/Xir776Kt7p9O7dO9bvmlAiyfkEOFu2bAleHNi9cHCutl+0aNEEl995ue43idK8eXOXE/SE5nvz5k2XKt9xrSfjxo2zPu/evXu803IW3++YFkkU5ySa3UfSVq5c6fIbJPToo7+/v8tJRLt27eItG3Od7devX5KXJzExH5WqUqVKnEmuaE888YRVtlmzZvGWGz16tMv2e/HixQTj6Nevn1W+VatWcZaZOXOmS6zfffddvNPbvXu3yzFOSjiJYne73Llzp5UMz5o1q7l69Wq8Ze1slzHZucDZuHGjy7EvoRhiTjO+8kFBQS4JoviOkdGOHDliXeRJMps2bUp02SIiIlxOEu2Mk5g6depY01uyZEmsz533/T179jR58+Y1kkzdunXjnF7nzp0T3Y5Teh9pjL1927Vr10z27Nld5h3XhY8x9y5MmzZt6rIO2k2iSPduGMR1EWSMMTdu3HBJBif0aFZSkygpedxPqqSc6IeFhbk89lWnTp149yGRkZHmySefdNkG43vEJeb+uGTJkrEuiu5XSiRR0vuxwh1SIoly4MABl+/4o48+irOcc5nkJlGGDx/uMp24Hs185plnrM/z5Mljjhw5Eu/0Yt6AjC858vrrr8c6t6lXr5758MMPzfbt2+O9yZ0e2d2/pfR5f1zXNC+88EK80z137pzL/iq+7SY8PNwlMfLyyy/HexwwxpiAgACXGzTxVbJwexIlKS9fX1+zd+/eBKf9/vvvW+Vz5MgR6+56TAcOHHDJTMWXVU6rJMqtW7eMt7e3Nc7QoUMTHcf5GeLSpUvHeeCNmUQZMGBAgtP85ptvXMpXq1Yt3pMaY4y5cOGCS7bW7rOiyZXcnfqNGzdcluuzzz6zNd61a9dcxlu1alUyIzfm66+/tqbTuXPnZE/HmNjrWEIXrsYYs23bNpfy+fPnT3AnGBYW5nJBsXnz5vuKN1qzZs2saf7xxx/xlnOO9X6SKNu3b3dZ5oROkOIap1ixYrF2uM53zeO7A25XWiRRnNttsJv0adOmjTVO3bp1EzzoGGPMl19+aZV3OBzx3sl1/l0LFy5833fu4xLzOJPYhe26deussl5eXnHeebh165ZLosjOxfKtW7esu5uSzNGjR2OVqVevnvX5E088keg0R4wY4bJsSW1DID4vvPCCNc1FixbFW87OdhmTnQucqKgol+fTv/zyywSn6XzREd/3NnHixERPsGJyrhXRpUsXW+NUqlTJGmf69Om2xklIYu2izJs3z/p8/vz55qmnnjJS/O2iOJ9obt26NdbnqbGPNMbevu3zzz+3ymTNmtWcP38+wfkePnzY5XzDbhLF29vbBAcHJzht5wvfhNaXpCZRUvK4n1RJOdF3jtPhcCR6zh0QEOByjjBq1Kg4y8XcH8eVGLxfKZVESc/HCndIiSTKpUuXXL7j//73v3GWcy6T3CTKhAkTXKYT8zzk7NmzLtd9iV0HREVFuTy50LRp0zjLhYSEJNiOZZYsWUy9evXM4MGDzdKlS13anExvkrp/s8POeX/Maxo7x6KYtZziOu90ro360EMPJdqGkzHGfPvtt9Y48T0Bc79JlDTrnad58+YaOHBgnM9uOluxYoX1f6dOneJ8ds1Z9erV1bp16zjHd4eNGzdaz8M6HA4NGTIk0XGcn7E9c+aMyzNq8enbt2+Cn8dsk6FXr17y8Ij/5y5WrJjVQ4GkdNsNcMzeQ+z2ThLzmX+7vZDExXmeBw8evK/nnmNK7HetU6eOSxswiXWrliVLFj388MPW+5T6XRs2bGj9H/0Mc2r66quvrP979uxpq82ehg0bWs9BXrx4UUePHnX53Pl3TIkeOVKbc28Sie0XpXu9mPz222/W+8GDByfaDlDv3r2VJ08eSZIxRj/88EOi8+natWuqd+1XuXJlNWvWLMEyjRs3tvZxYWFhOnXqVKwyP/30k9VuRp06dRKdpnSvm/RnnnnGer9u3TqXzwMDA7Vr1y7r/UsvvZToNO2USY603i5jcjgcLu2gOLd3EtPdu3ddeq7p3r17nOWct/3XXnvNVhzOvQOtX7/e1jjO7Sw4b2vJ5dyeQ1ztojgP8/X1tXpYiW4XxZm/v7/1nHeOHDlUv379WNNLjX2kXT/99JP1f4cOHRJss0KSqlSpYrtNJ2ddunSJ1dZPTE2bNrX+T+7yxCU1j/spyfkcuEWLFi7H/7gULlzYZZu1cw5dsGBBPf3008kLMJWl52NFRpY3b16X99HfjTvmtWrVKqudjhw5ciR63uxwOFza2tiyZUucPSnlypVLmzZtinfdvnv3rnbt2qWpU6fqueeeU5EiRdSvXz+rjaZ/u+ScX3Tv3j3RY9Hzzz/v0iZVXPsg5+PbwIEDbbXJ8swzzyh79uxWvDdv3rQVc1Lcd4uQ8TWiGBkZqaCgIB09elShoaHatGmTNm3apPr162vJkiVxNh4XFhbmkkB47LHHbMXQoUMHqzGzP//8M3kLkkKc51+5cmVbXfc1atRI+fPnt7p9/vPPP1W3bt14y8e8MI5LkSJFYs0jMUWKFHFpZDY9itklo93GjWKWi26IMTnq1Klj/X/o0CH17dtXEydOtBomvh/OO6m4ZMmSRfny5VNgYKAk+79rNDu/a3h4uNatW6edO3fq77//VkhIiG7fvu3SXZhzI2tpcQBxvqho1aqV7fGqV69uxbpnzx5VqVLF+sx5G5sxY4YqVaqkl156yXaDn2nN+aAf8yQjLrt27XI50bezP82aNatat26t77//XpK9/anzRUtqsdPoZdasWZU/f35r24hrXb+f9ShadGOK0ZxPJhwOR7yNITorW7asSpcunaSL9aioKG3ZskXbt2+Xv7+/rl+/rtDQUJft0nlbdNeJXbdu3azud7du3arTp0/HeRz86aefrEZ4c+XKpSeeeCJWmaCgIJfGiZ27QE1I8eLF5e3trevXr+vy5cu6cOFCohf2zttU9Dp0P5o3by4PDw+rIfmYDTFGJ1GiGyZ17qZ2w4YNLo3LOidcmjRpEudxLzX2kXY5bwN2fyNfX19t3LgxSfOxsx9w/p1T8jwmNY/7Kcl5n52Uc+joRkMPHz6sGzduKFeuXPGWb9SoUZo2KJ8U6flYkZHFTBreT8cM9zsv53W8efPmtm7iPP7443I4HNbxcseOHXr88cdjlcuXL5+WL1+urVu3asaMGVqxYoVLByHOQkNDNXv2bC1evFhfffVVuk0s2pFa5/3t2rVLtIynp6dat26t7777TlLsBI0xRn/88Yf13u726OnpqUqVKmnfvn1Ww9JNmjSxNa5d970XrFmzptasWRPv5+Hh4VqxYoWGDRum8+fPa+fOnWrZsqV27doVqzX0c+fOuVzc2u0dwLlcYGCgQkJCEr1bkVqcV7Kk9G5Qo0YN60TJeRpxyZ8/f6IHsOjsW7RChQolGoPzOKGhoYmWd4eYyxXd8nZiYpa7nzvnpUuX1jPPPKPly5dLutda9MKFC9W8eXM98sgjatasmRo0aCAvL68kT9vOCZnzd5CSv2tkZKQ+++wzTZgwIc4sfXyie4NKLcYYHTp0yHr//vvva+rUqbbGPXDggPV/zGV67rnn9N///lcXLlxQVFSUhg4dqjFjxqhNmzby9fVVs2bNVKNGjVQ9WUgK59pTdhI9zvuRQoUK2VpXpHv7ougkSmL7IkkqX768renej5hJ4fgktq5H96Ak3bub5bx+JMT5hCHmehTdwrwklShRQjlz5rQ1zSpVqthOoixYsECjRo2yktx2pPZ2GZ/q1aurZs2aVq9C33zzjUaOHBmr3Ndff239/+yzz8a5Tkf3ICLdS4Q/99xztuNw3udfvXo10SSK8/zvp6ZiNG9vb9WqVUt79+6VMUYbN2604j9z5oxOnz4tSVbypGbNmlbvRjFrrsSstRJTau0j7bhz545L0qly5cq2xktOssbOfiC1zmNS87ifUiIiIlz2Kck5h46KitKpU6cSrDWeFvv85ErPx4qMLObx5H56GrzfeSXnOit37twqXbq0td9N7NzGx8dHPj4+ioyM1N69e7Vt2zbt3LlTf/75p9U7bLSbN2/queee02+//Rbn/jk9S+3z/oR64nXm3DPt8ePHXT47f/68S6Lz1VdftZ3Edd4fpsb2mOqpZE9PT3Xq1En16tVTrVq1dOPGDZ06dUp+fn6aOXOmS9mY2eCYXU7FJ2YXhteuXXNbEsV5GezGL7kug3MXmXHJkiVLkuNK6jjO2cf0JOYFyu3bt22NF/MgafdCJz6zZ8/WlStXrOxoRESE1q1bZ1XfzJYtm1q2bKkXXnhBnTp1stUNs5T03ymlfteIiAh16tQpWY/DhYWFJXmcpAgODraqbkr37m4ndzrOsmfPrh9//FEdOnTQxYsXJUkhISFaunSp9ZhBgQIF1L59e/Xt29dWdd60Ymf7TIt9kaQE71imlOTs8+L6jqJr+0n3qvonp7p/zPXI+XtOStfw0Y9NJWbw4MGxumq1I7W3y4R069bNekTu66+/jpVEuXHjhn788UeX8nFx/r0iIiJcus9NCjsnfKlxzPP19dXevXsl3UuERCdRnJMi0TU3PDw81Lx5c61cuVL79u1TcHCwtY4419iI6yQ9tfaRdsQ8b7O7Ddhd/50lZz+QklLruJ9SUvIcOiFpsc9PrvR8rMjIYtbOS80kSmLzup9zm+gkip1zG+let7z16tVz6VL+3Llzmjdvnj755BPrN46MjNRLL72kw4cPp/l2n1xpcd5v9/dxLhdzP+a8LUrS77//bmuaMaXG9phmbaKULVtWvXv3tt5/9dVXsZ5Pivmj2N0ZxiznzpNH53knZWfuXNad8ad3WbJkcTmAX7p0ydZ40c+TR0vKjjcu+fLl06ZNmzR//nw1btw4Vm2F27dv66efftLzzz+v6tWrWyfS6dXHH3/ssiNt3Lixpk2bpl27dunKlStWtb7o15gxY9IstpS4KyzFriIqSbVr19aRI0f03nvvxdmP/NWrVzV//nw1b95cHTp0cOudJefaU3ZqYKXVviihtpbSm5RYl1KqLQQ739vixYtdEijVqlXTpEmTtG3bNl26dEmhoaGKioqytsu5c+emSGz3q2vXrtY+8eDBg7HaHFq2bJm1DhctWjTe6rmpue3H5JyQT6k2fmI+ohMtvqRIXO2iHDt2zDrO5ciRw+VkPlpafk8pJSPtN6Kl9+N+Wp1DZ8TfLqnS07EiPdi9e7fL+9SsjeQ8r7x588Z6fNnd11klS5bU22+/rb1797rUcDx27Fic7V+lV2lx3m/393GuwRfzt0nPx7c03RM6Pzt/584dl8b4pNh3Jm7cuGFrujHLJeVuYEpzXga78ccs6874M4KHHnrI+t+5Kn1CnKvBOxwOl2kkl4eHh3r06KGtW7cqMDBQS5cu1eDBg2NVXzt69KhatWqlkydP3vc8U0NkZKQ+/vhj6/2gQYO0detWDRgwQHXr1lXBggVjNeCblHX7fsXcL+zcudNlx2739c4778Q5/dy5c+utt97S8ePHdeLECc2ZM0c9evSIVf1/9erVateunSIiIlJrUROU1Boi7Itic/5OPvroo2StRzFPkpynmZQ7HXZ+w+i2RSTp6aef1t69ezV06FA1atRIRYoUUbZs2Vwu5NJyu0xIiRIlXNqGidnArPP7Ll26xHvnzvm7zZEjR7J+L2OMrSrWzr+Hc9sl96NZs2bWBWd0uyjS/yVUypUrp5IlS1rl40q6OK9vPj4+8vT0jDWf1N5HJiTmvO1uA3bvBKc36fm4/284h04vUuNYkZE5t0nhcDhSrS20sLAwlyRK06ZNYyUr08u5TdmyZfXBBx+4DHP+ntKztDrvT84+KOaTJDH3a4GBgcnaHnv16pXk+BOTpkmUmCttzFoEMU9c4moxOy4nTpyw/s+UKZOtRhdTi/My2I1fcl2GlDqB+7dyfpbaTk9GklzuCJUsWTLFexPJnz+/OnbsqClTpujAgQM6fvy4+vfvb31+/fp1jR8/PkXnmVL27NljVZfLnj17rINCXNKy0cqcOXO6PL985cqVVJtXuXLl1KdPH82fP1/nzp3T5s2bXS4Gd+/erW+++SbV5p8Q58a47Xz/zvuR8+fP207+/Jv3Rc5tDqXUelSqVCnr//Pnz9u+a5JY9fArV65o//791vtPP/00zgtoZ+mplwDnR3QWL15sVZm/fPmyS68V8T3KI7n+Xrdu3UqxO1Jxcf7u4mr4Pjny5s1rtS0R3S7K2bNnrXODmMmd6HZRpLiTKPElg9JyHxlTtmzZXBK8dh97SMmec9wlvR33c+bM6dK2T3LOoaV/334/OVLjWJFR3bhxQ99++631vmrVqvddmzs+ixcvdnlKIa5evJJznWWMcSmbUut427ZtXd7brR3vbml13m/393EuF7P9vphtRaan7TFNkygx7zzEbEiucOHCLl137tixw9Z0nVtqrlGjRpwnms7VD+0++xyzyqKd8ZxbcN+7d2+s3mTicv36dfn7+8c5DcTmvFM9fvy4Ll++nOg4zi2tJ6drxaSqUKGCZsyYoZ49e1rDfv3111Sfb3I41+apWrVqrMZ747Jt27bUDCkW516Itm/fnibzjL7bsmbNGpfGEuP6HZOzf0kq5+ShnQZfnfcjd+/etZ1wdN6f/tv2RamxHjk/XhEVFWWrxxHnhkXj41x7rkCBArZ6erO7XTrf2Uut9fW5556zquiePXvW2gcvXrzYar/joYceSrAnulq1armcJ6RW73sRERGx9oMpJWbtkoSSItHtokiy2kVJrD2UaO7YR0Zz3gbsdimd1J55Ulpq7LPTw3G/du3a1v/JOYfOmzevrX1NakiL46hd7tye0pvPPvvMpabAgAEDUmU+YWFh+uijj6z32bJlU48ePWKVcz4vsbuOHzp0yCU5k1LnNjHbB0rsRkd6kVbn/XZ/H+dyMX+bggULqly5ctb79LQ9pmkSZdOmTS7v47rb49x4o507vhERES4Z0vgaf3SueWC3MdKYtRXsjOc8/+vXryfYc1E055PKTJky2eqi7UH2xBNPuBxsnXt5iMvly5ddGiJ66qmnUi22mJy7PLOT7HEHO4k+Z+vXr7f9GFVKcc72L1q0yKURxdSWNWtWl/nH9TsmZ/+SVM4Xm4cPH070JLNixYouPRXY2Z8ePXrUpSptempMNyU4/45bt261lYxKTOHChV0O+jEbTI+LnTJJ3S5PnDjhkixOSFqsr97e3i5dSEY/wuP8KE9CtVCke89TOycO5s+fn7JB/n/Hjx+3nsP28PBwuRC9XwklUeLqDti5XZQ5c+ZYjV5nz55d9evXj3c+7txHOv/Oq1atSvRu7NGjR92eREnNbcCdx33nffb3339vaz+ycOFC6/+4Hp9IK2mxX7IrNY4VGdGmTZs0duxY633hwoX14osvpsq8hgwZ4tLLWL9+/eLsVdB5HT906JCtnpOc13Fvb2/bvcYkJmZPPc4VAdKztDrvd74+j8+pU6dckihxPSrmvD2m1nlAcqRZEuXvv//WvHnzrPdFixbVww8/HKtcnz59rP/37Nlj9ZIRn88++0znz5+33vft2zfOcs4XE3Z3ht7e3i7PhNkZr3Llyi5JkNGjRydYjf7GjRt69913rfdPPPGE7a5IH1SFCxd26Xt88uTJsRopdvbBBx9Yv0HBggXj7Bs+KZJyh8Q5e5+arZnfj6JFi1r/Hzx4MMFn2sPDwzVs2LC0CMvFiy++aPWodPLkSU2YMOG+p5mSv6Pz/uXkyZOpchetYcOG1p39GzduuNRei49zY97Tp09P9CD45ptvWv8XKlRIHTp0SGa06VODBg3k4+Mj6d5F6sCBA1OksTHnKvwrV660uoiOy759+zRp0qREp+m8XV69ejXWyVpMr776qu31LjnHw+To3r279f/SpUt1+PBh7dy50xqWWBJFkoYOHWr9v2jRolRpZ8C5fbY6dercd+9tzpo3b+7SLsrq1asl3WuYsUSJErHKOyddPvzwQ+v/+NpDiZYa+0i7unfvbtUYun37tl5++eV4t6u7d+/qpZdecnujm0ndBjLKcd95nx8QEKDPPvsswfLff/+9S02U+M6h04Lzb3L16lW39m6TWseKjGTevHku7cB5eHho5syZsdrKuF83btxQ586dXW4uVKxYMd42mh599FGXfWfM3t9iOnv2rEsD7b169YrVDtfVq1dt3fSO6YsvvnB5H1diPD1Kq/P+9evX67fffkuwzKhRo6z9a758+fTEE0/EKjNkyBDrOLpp0yaXpJg7pXoSJTw8XN999518fX1dnmceOXJknNnuRx99VA0aNLDe9+3bN94qRCtXrnTZeDp06KBatWrFWdb5TuF3331n3d1JSKZMmaznmSVpypQptnaib731lvX/vn371KtXL929ezdWuZCQED377LNWLJkyZUp0Z4B73n33XWv9OXv2rPr06RNnZvX77793OYn473//a6vaWkI+/PBDvfLKK4lexF69etWlYci0eIwoORo0aGCdAN+5c0fDhg2L84Tx5s2b+s9//mP7sZCUlC9fPo0aNcp6P3r0aI0dOzbRbPr169c1ZcoUde7cOdZnzz//vD744INY3enFtHv3bi1evNh6H9fvWKNGDavf+n/++UcLFixIcJrJkT17dpcMvZ07uYMGDbIa5QoNDVWHDh1i9VQl3btAGDlypEu3s2+++abbuxRNDR9++KH1W/3666969tlnFRQUlOA4d+/e1bJly9SoUaM4e0bq06ePy52t7t27a8qUKS6tzEdFRWnJkiVq06aN7ty5E6tb0ZhKly7tUltzyJAhcR5HwsPD9corr1gX53Y4Hw+nTZuWaj3CtW/f3lr/goKCXG6SNG7c2KWKbnweffRRPfbYY5LuXcw8/fTTWrZsWaLjnTp1Sq+//rqtNimct6WYz7jfr7x586pGjRqS7m1n0c9zx/dojnO7KM61GBJrHDc19pF25c2bV2+//bb1fuXKlerYsaPLI2nSvbu2jz32mDZt2pTo+p/anLeBuXPnJnrBnlGO+w899JDVlbZ075wnvi5Mt2/f7rJN1qpVy62J8+LFi1s3EY0xiSaAUltqHCvSu1OnTmn27Nl6+OGH1bt3b5caQR988IGefPLJFJnP3bt39eeff+rNN99UqVKl9N1331mf5cuXT6tWrYq3fctMmTLJz8/Per969Wr5+fnFeX0WEBCgJ554wrr+zJkzp1577bVY5a5fv67HHntMPj4++uabbxL97SIiIvTuu+9qxowZ1rBatWq5XL+mZ2l53t+1a1cdPHgwzs8+/PBDl6cJhg4d6tJTT7TKlSu73Kzq27evpk+fnmhyOyAgQO+++64GDx6czOgTlvl+J/DXX3+51AqIFhkZqevXr+vw4cMKDQ11+axjx4565ZVX4pyew+HQvHnzVK9ePYWGhiokJETNmjXTCy+8oA4dOqhgwYK6dOmSvv/+ey1ZssQaL3/+/C4rc0zPPvushg4dqrCwMF24cEHlypVTnTp1VKBAASu7VahQoVjVrLt27WpVM5ozZ45Wr16t6tWru1Q77NKli7p06WK9b9++vXr37m11N7lo0SLt3r1b/fv3V40aNRQVFaXdu3fHujP85ptvZpgN0K5NmzapTZs2sYY7n9ht2rQpzsz2rFmz9MILL8Q53Tp16mj48OFW69JLliyRv7+/XnnlFVWqVElBQUFavny5vvnmG2vH2qRJk3jXu6S4ffu2pk2bpmnTpql27dpq1aqVateurcKFCytbtmy6evWqtm/frjlz5lgX6JkzZ3bZ6acn2bJlU79+/TRlyhRJ0v/+9z8dPXpUL774oipUqKBbt25px44dmjVrls6fP6+cOXOqQ4cOLomFtPDmm29qx44dWrZsmdWTxJw5c/T888+rYcOGKlCggCIiIhQUFKSDBw9q27ZtWr9+vcLDw9WwYcNY0wsICJCfn59GjRqlli1bqmnTpqpevbry588vh8OhCxcuaO3atVq0aJF18VqqVKk418ncuXOrQ4cO1slqr1699P7776t8+fIuiYj33nvvvqqRPvvss9ajab/88oteeumlBMsXK1ZMU6ZMsZ7RP3DggKpVq6aXXnpJTZs2Vfbs2XXs2DH973//c7kb2bRpU5caAP8mTZo00SeffKJXX31V0r0LvtKlS6tLly5q0aKFihUrpsyZM+v69es6fvy4du3apTVr1uj69evxTtPT01MLFy5UixYtFBwcrDt37ujVV1/V22+/rWrVqilz5szy9/e3LqCfe+455ciRw6qWGl+y6tVXX7XuAP3yyy+qW7euXn75ZVWrVk13797V/v37NWfOHB09elSZMmVSjx49bHVz3LVrV+ukdc2aNVbNUOdW8Vu1aqUhQ4Yk/oUmwMvLS88995zmzJkjybXtBTu1UKItXLhQDRo00IkTJxQcHKyOHTuqfv36euaZZ1SzZk3lyZNHoaGhunLlivbt26eNGzdatUtGjBiR6PSd263o2LGj7bjs8vX1dWkkOHpYXKLbRVm5cqWt8s5Seh+ZFG+88YbWr1+vtWvXSpJWrFihlStXqnr16ipQoIACAgJ05MgRSfeSLpMmTbLaO3BHsvb555+3el3Zt2+fihcvrjp16ihv3rzWDZrq1avrvffek5SxjvtffPGFNm/erMuXLys8PFzPPPOMOnbsqI4dO6p48eK6evWqfvrpJ82fP9+qZZA1a1YtWLAg3p6y0krXrl01efJkSdKYMWM0Z84cValSxeUccciQIfF2i56SUuNY4W5xXbPdvn1b169f16VLl+K8qVSgQAHNnDlTzzzzTJLm9cknn7icJxpjFBISouvXr+v06dNxJip8fX21YMECl17L4vLKK69o2bJlViPlH3zwgdatW6c+ffrooYce0p07d/THH39o+vTpVgOq0TEl1HD4tm3btG3bNuXJk0ctW7aUj4+PypcvbzWke/nyZe3Zs0ffffedS2Oo2bJl04wZM9z2KFxSpdV5/3/+8x999913ql+/vl588UU9+uijypMnj06dOqUFCxa4tKFVvXp1l9rQMU2ePFn79u3T9u3bdffuXb388suaMmWKOnXqpDp16ihfvnwKCwvT1atX9ddff2nLli36448/FBUVdV83CRJkkqFnz55GUpJfWbJkMWPGjDF3795NdB6bN282efLksTXdIkWKmAMHDiQ6zRkzZhgPD494p1O6dOlY49y9e9e0bNkywfmPGTMmzvG6dOli+7sZPHiwiYqKijf29evXJxhnXJynf+rUqUTLt2jRwio/d+5cW/NIjHPcSX0lFkNkZKTp2rWrrWnVqFHDXLlyJUWWacyYMUlajsyZM5v58+fHOa1Tp065lLWjdOnSVvn169cnWt55e41rXTXGmJs3b5patWoluixeXl7m+++/d/kOevbsGe+87ayDc+fOtcq0aNEiwWUJDw83AwcOTPK61LBhw1jTcl7f7bwKFSpk9u7dG29sp06dMiVKlEhwGnZ+r4QEBgYaT09PI8lkz57dhIaG2hrvs88+Mw6Hw9ZyNmnSxFy/fj3B6SV135IcdtbbmJKybcydO9d4eXkleV26fft2vNP8888/XWKI69W5c2dz8+ZN07lzZ2vY559/Huf0IiIiTNu2bRONycPDw0yZMiVJ21L37t0TnGbM7To5xyBjjFm3bl2c+8Sk7o8vX75smjZtmuTfa8SIEQlOd+fOnVbZqlWrJikmu5YvXx4rrnPnzsVb/tNPP3Upmz17dlvnTcak7D7SmKTtn2/dumU6duyY4HxKly5tdu3aZX7++WdrWL169eKdZlKPd0k5pr711lsJxuq8vCl53E8qu8dbZ4cPHzbFixe3FWuuXLkS/W6Tsz9OjuvXr5vq1asnGG/Mc8OMeKxIS8m9ZitWrJh5++23TUBAgO15JWc+kkzTpk3NokWLTGRkpO15hYSEGF9fX9vz+Oijj+Kd1okTJ5Ide+HChc26detsx50W7KzfqXHeH3P/e+3atUS3Z0mmbNmy5vz584ku182bN82zzz6b5N+oc+fOcU4vOftWZ6n2OI/D4VCuXLlUtmxZPfXUU/r000917tw5vfPOO7ZaL27atKkOHjyo7t27x3uXIlu2bHrllVd04MABW3d3+/fvrx07dqh///6qXr26cufOHasHnpg8PT21du1azZs3Tx06dFDJkiVj9SoU33hff/21Fi5cqPLly8dbrnr16vrhhx80ZcqUDJPBTC88PDy0aNEizZ49O97Mcp48efTGG29ox44dKdal2XPPPadBgwYl+LtK96octm/fXrt3746zhfH0JEeOHNq0aZN69uwZ752oxo0ba9u2bXr22WfTOLr/kzlzZn3++efavHmz2rRpk+BdM4fDodq1a+vdd991qbUWbcSIEXr++ecTXS9y5cqlAQMG6ODBg3G24xStTJky2r9/vyZMmKDmzZurUKFCKX6HtUCBAtb3HxoaGutudXyGDBmirVu3JthQbOHChfXJJ59o/fr11iMY/2a9evXSkSNH1Ldv30S7PC9TpowGDRqknTt3Jvg8eIMGDXTo0CF98sknaty4sfLnz6+sWbOqbNmy6tixo1avXq3FixcrR44cLt30xfdoQ6ZMmfTDDz9o2LBhcVZxle4dQ3755ZckV1f96quvtGzZMj333HMqV66ccuTIkSrHoBYtWsRq+6NNmzZJ3h8XKlRIGzZs0IIFCxI93nt5eemRRx7RrFmzXB6vjYtzVeLEanYlV/PmzV2+2/jaQ4kWs9ZJYu2hOEvJfWRSZc+eXUuXLtXPP/+sTp06qUSJEsqSJYsKFSqkRo0aadKkSdq3b5/q1q1ra/1Pbe+9957WrVun7t2766GHHlLOnDnj3QYy2nG/SpUq+uuvvzRkyJB492+enp56/vnndfDgQVs1ndJCnjx5tGPHDk2dOlWPPvqoihYtmuJtcCRVahwr0gsPDw/lyZNHJUuWVI0aNfTcc89p4sSJ+v3333XmzBmNGzcuVhezyZUlSxYVKFBA5cuXV6NGjfTSSy9p1qxZ8vf31+bNm9W1a9dEr8mc5cqVS2vXrtVnn33m0sZHTD4+PtqyZYtef/31eMuUK1dOJ0+e1Mcff6xHHnkk0d9ZksqWLau3335b/v7+GaYtFGdpcd7v7e2tbdu2qU+fPnGew2TOnFm9evXS7t27Vbx4cVsxf//99/rhhx/UuHHjBM9ZMmXKJB8fH02aNElTp05NVvyJcRjj5n7EbLhx44Y2bNigs2fPKjg4WHnz5lXZsmXVokULWwmN9ODAgQPas2ePrly5IofDocKFC6tRo0aqWLGiu0P7VzDGaPv27Tpy5IguX75sddPn6+ubqgeyy5cva//+/Tp16pSuXbumqKgo5c6dW+XLl1eDBg2sKoAZycWLF7V+/XqdP39emTNnVrFixVS/fn1VqFDB3aHFEhwcrC1btujcuXMKCgpS5syZ5e3trQoVKqhmzZq2T86PHz+uw4cP6+zZs7px44Y8PDyUN29eVa1aVfXq1UtX+5nt27dbjVe3bt3aqj5v14ULF7R582ZdunRJYWFhKliwoKpVq6YGDRok6QTm3yT6+exjx47pn3/+UWRkpHLnzq3SpUurevXqKd7lZ2RkpPLnz2+1w3DkyBGXbrTj8s8//2j9+vVWFeKiRYuqZs2aLu12PUjOnz+vbdu2KSAgQMHBwcqWLZsKFiyoSpUqxeoaOT7h4eEqVqyYrl69qly5cunChQuxuqzM6FJqH5nSBg8ebDX2OGLECJd2RNK7jHbcv3PnjjZt2qSTJ08qKChIuXPnVqlSpeTr6+vyCB8Sl9bHCthjjNHOnTt14MABBQYGysvLS0WKFFGzZs0STFjHJyIiQkePHpW/v78uXrxonRfmypVLxYoVU61atWy16ZVRpMV5f1BQkNavX69z584pPDxcJUuWVOvWre/rGBQYGKg//vhDFy9e1LVr15QlSxblz59fFStWVK1atVJ9/5YhkigAgP/TqlUrrV+/Xg6HQ4cPH070Ahzpy5IlS/Sf//xH0r32vK5cufLAJrDc6auvvrJqC4wcOVLvv/++myN6MNy+fVulSpXS1atXJd1rayKlGqwEACAtcNYGIMV88cUXKlOmjLJmzaqGDRu69P0elyVLlqhy5crKmjWratSooZ9++imNIs3Yxo0bJ+ne3ZdPPvnEzdFAku0uUC9evOjSaG+PHj1IoLhJdMPkuXLl0vDhw90cTcZnZxswxmjQoEFWAqVQoUJW70sAAGQUnLkBSBHffvuthg0bpjFjxmjPnj2qVauW2rZt6/Lsu7OtW7fq+eefV9++fbV37149/fTTevrpp+PtCg3/p2nTpnrqqackSQsWLNCZM2fcHBGOHTumJk2aaP78+S69AUQLCwvTwoULVb9+fV24cEHSvYv3uLpbROpbvny5/vrrL0n3aqGkt0cwMqJnnnlGo0eP1oEDB+L8fPfu3Wrfvr3+97//WcNGjhxpu70XAADSCx7nAZAiGjZsqPr161vPuUdFRalkyZIaPHhwnN08du7cWbdu3dKqVausYY0aNdLDDz+s6dOnp1ncGdXJkydVtWpVhYWFqWfPnpo3b567Q3qgHT16VFWqVLHelylTRiVKlJCXl5eCgoJ0+PBhhYWFWZ97eHjoq6++UteuXd0R7gMtKipKNWrU0OHDh1W2bFkdOXIk3oZ7YV+jRo2sbqy9vb1VsWJF5cmTR7du3dKJEydiJdQff/xxrVq1ikb1AQAZTmZ3BwAg47t79652796tkSNHWsM8PDzUunVrbdu2Lc5xtm3bpmHDhrkMa9u2rVasWBHvfMLCwlwuRKOiohQUFKT8+fM/cCfiBQoUcLkoCQkJcWM0CA0NdXl/+vRpnT59Os6yhQoV0uTJk9W+fXt+Nzdx3i/F3K8geZzvyV2/fl07d+6Ms1ymTJnUq1cvffDBB7px40ZahYd0xhijGzduqFixYjzSCCDDIYkC4L5dvXpVkZGRsbrCK1y4sI4ePRrnOAEBAXGWDwgIiHc+EyZM0NixY+8/YMCNrly5Qg0UPLAiIyM1Z84czZkzx92hIB04d+5csnpQAQB3IokCIMMYOXKkS+2V4OBglSpVSufOnUvxrsyqj/klRaeXEg6ObZtomYwat5T+YifutEXcaYu409a/Pe6kCgkJUcmSJf913YoDeDCQRAFw3woUKKBMmTLp8uXLLsMvX76sIkWKxDlOkSJFklRekry8vOJsuyB37twpnkTx8MqeotNLCXaWMaPGLaW/2Ik7bRF32iLutPVvjzu5HrRHcQH8O/AQIoD7liVLFtWtW1e///67NSwqKkq///67GjduHOc4jRs3dikvSWvXro23PAAAAAC4GzVRAKSIYcOGqWfPnqpXr54aNGigyZMn69atW+rdu7ckqUePHipevLgmTJggSXr11VfVokULffLJJ2rfvr0WL16sXbt2aebMme5cDAAAAACIF0kUACmic+fOCgwM1OjRoxUQEKCHH35Ya9assRqPPXv2rEsL/D4+Pvr66681atQo/fe//1XFihW1YsUKVa9e3V2LAAAAAAAJIokCIMUMGjRIgwYNivOzDRs2xBrWqVMnderUKZWjAgAAAICUQZsoAAAAAAAANpBEAQAAAAAAsIEkCgAAAAAAgA0kUQAAAAAAAGwgiQIAAAAAAGADSRQAAAAAAAAbSKIAAAAAAADYQBIFAAAAAADABpIoAAAAAAAANpBEAQAAAAAAsIEkCgAAAAAAgA0kUQAAAAAAAGwgiQIAAAAAAGADSRQAAAAAAAAbSKIAAAAAAADYQBIFAAAAAADABpIoAAAAAAAANpBEAQAAAAAAsIEkCgAAAAAAgA0kUQAAAAAAAGwgiQIAAAAAAGADSRQAAAAAAAAbSKIAAAAAAADYQBIFAAAAAADABpIoAAAAAAAANpBEAQAAAAAAsIEkCgAAAAAAgA0kUQAAAAAAAGwgiQIAAAAAAGADSRQAAAAAAAAbSKIAAAAAAADYQBIFAAAAAADABpIoAAAAAAAANpBEAXBfTp8+rb59+6ps2bLKli2bypcvrzFjxuju3bsJjufr6yuHw+HyGjBgQBpFDQAAAABJl9ndAQDI2I4ePaqoqCjNmDFDFSpU0MGDB9WvXz/dunVLH3/8cYLj9uvXT+PGjbPeZ8+ePbXDBQAAAIBkI4kC4L60a9dO7dq1s96XK1dO/v7+mjZtWqJJlOzZs6tIkSKpHSIAAAAApAge5wGQ4oKDg5UvX75Eyy1atEgFChRQ9erVNXLkSIWGhiZYPiwsTCEhIS4vAAAAAEgr1EQBkKL+/vtvTZ06NdFaKF27dlXp0qVVrFgx/fXXXxoxYoT8/f21bNmyeMeZMGGCxo4dm9IhAwAAAIAt1EQBECc/P79YDb/GfB09etRlnAsXLqhdu3bq1KmT+vXrl+D0+/fvr7Zt26pGjRrq1q2bFixYoOXLl+vEiRPxjjNy5EgFBwdbr3PnzqXIsgIAAACAHdREARCn4cOHq1evXgmWKVeunPX/xYsX1bJlS/n4+GjmzJlJnl/Dhg0l3avJUr58+TjLeHl5ycvLK8nTBgAAAICUQBIFQJwKFiyoggUL2ip74cIFtWzZUnXr1tXcuXPl4ZH0Sm779u2TJBUtWjTJ4wIAAABAWuBxHgD35cKFC/L19VWpUqX08ccfKzAwUAEBAQoICHApU7lyZe3YsUOSdOLECb377rvavXu3Tp8+rR9++EE9evRQ8+bNVbNmTXctCgAAAAAkiJooAO7L2rVr9ffff+vvv/9WiRIlXD4zxkiSwsPD5e/vb/W+kyVLFv3222+aPHmybt26pZIlS6pjx44aNWpUmscPAAAAAHaRRAFwX3r16pVo2yllypSxEiqSVLJkSW3cuDGVIwMAAACAlMXjPAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAFw38qUKSOHw+HymjhxYoLj3LlzRwMHDlT+/PmVM2dOdezYUZcvX06jiAEAAAAg6UiiAEgR48aN06VLl6zX4MGDEyw/dOhQ/fjjj1qyZIk2btyoixcv6tlnn02jaAEAAAAg6TK7OwAA/w65cuVSkSJFbJUNDg7WnDlz9PXXX6tVq1aSpLlz56pKlSravn27GjVqlJqhAgAAAECyUBMFQIqYOHGi8ufPr9q1a+ujjz5SREREvGV3796t8PBwtW7d2hpWuXJllSpVStu2bUuLcAEAAAAgyaiJAuC+DRkyRHXq1FG+fPm0detWjRw5UpcuXdKkSZPiLB8QEKAsWbLI29vbZXjhwoUVEBAQ73zCwsIUFhZmvQ8JCUmR+AEAAADADmqiAIiTn59frMZiY76OHj0qSRo2bJh8fX1Vs2ZNDRgwQJ988ommTp3qkvBICRMmTFCePHmsV8mSJVN0+gAAAACQEGqiAIjT8OHD1atXrwTLlCtXLs7hDRs2VEREhE6fPq2HHnoo1udFihTR3bt3df36dZfaKJcvX06wXZWRI0dq2LBh1vuQkBASKQAAAADSDEkUAHEqWLCgChYsmKxx9+3bJw8PDxUqVCjOz+vWrStPT0/9/vvv6tixoyTJ399fZ8+eVePGjeOdrpeXl7y8vJIVEwAAAADcL5IoAO7Ltm3b9Oeff6ply5bKlSuXtm3bpqFDh6p79+7KmzevJOnChQt65JFHtGDBAjVo0EB58uRR3759NWzYMOXLl0+5c+fW4MGD1bhxY3rmAQAAAJBukUQBcF+8vLy0ePFivfPOOwoLC1PZsmU1dOhQl8duwsPD5e/vr9DQUGvYp59+Kg8PD3Xs2FFhYWFq27atvvzyS3csAgAAAADYQhIFwH2pU6eOtm/fnmCZMmXKyBjjMixr1qz64osv9MUXX6RmeAAAAACQYuidBwAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKAAAAAAAADaQRAEAAAAAALCBJAoAAAAAAIANJFEAAAAAAABsIIkCAAAAAABgA0kUAAAAAAAAG0iiAAAAAAAA2EASBQAAAAAAwAaSKADuy4YNG+RwOOJ87dy5M97xfH19Y5UfMGBAGkYOAAAAAEmT2d0BAMjYfHx8dOnSJZdhb7/9tn7//XfVq1cvwXH79euncePGWe+zZ8+eKjECAAAAQEogiQLgvmTJkkVFihSx3oeHh2vlypUaPHiwHA5HguNmz57dZVwAAAAASM94nAfIoEJCQrRixQodOXLE3aG4+OGHH/TPP/+od+/eiZZdtGiRChQooOrVq2vkyJEKDQ1NgwgBAAAAIHmoiQJkEP/5z3/UvHlzDRo0SLdv31a9evV0+vRpGWO0ePFidezY0d0hSpLmzJmjtm3bqkSJEgmW69q1q0qXLq1ixYrpr7/+0ogRI+Tv769ly5bFO05YWJjCwsKs9yEhISkWNwAAAAAkhpooQAaxadMmNWvWTJK0fPlyGWN0/fp1TZkyRe+9916Kz8/Pzy/eBmOjX0ePHnUZ5/z58/rll1/Ut2/fRKffv39/tW3bVjVq1FC3bt20YMECLV++XCdOnIh3nAkTJihPnjzWq2TJkve9nAAAAABgFzVRgAwiODhY+fLlkyStWbNGHTt2VPbs2dW+fXu98cYbKT6/4cOHq1evXgmWKVeunMv7uXPnKn/+/HryySeTPL+GDRtKkv7++2+VL18+zjIjR47UsGHDrPchISEkUgAAAACkGZIoQAZRsmRJbdu2Tfny5dOaNWu0ePFiSdK1a9eUNWvWFJ9fwYIFVbBgQdvljTGaO3euevToIU9PzyTPb9++fZKkokWLxlvGy8tLXl5eSZ52cpye2D5N5pPSMmrcAAAAQEbA4zxABvHaa6+pW7duKlGihIoVKyZfX19J9x7zqVGjhnuDk7Ru3TqdOnVKL774YqzPLly4oMqVK2vHjh2SpBMnTujdd9/V7t27dfr0af3www/q0aOHmjdvrpo1a6Z16AAAAABgCzVRgAzilVdeUcOGDXX27Fk9+uij8vC4lwMtV66cxo8f7+bo7jUo6+Pjo8qVK8f6LDw8XP7+/lbvO1myZNFvv/2myZMn69atWypZsqQ6duyoUaNGpXXYAAAAAGAbSRQggxg3bpxef/111a1b12V4q1at9NFHH8nHx8dNkd3z9ddfx/tZmTJlZIyx3pcsWVIbN25Mi7AAAAAAIMXwOA+QQYwdO1Y3b96MNTw0NFRjx451Q0QAAAAA8GAhiQJkEMYYORyOWMP3799v9doDAAAAAEg9PM4DpHN58+aVw+GQw+FQpUqVXBIpkZGRunnzpgYMGODGCIGUQc9CAAAASO9IogDp3OTJk2WMUZ8+fTR27FjlyZPH+ixLliwqU6aMGjdu7MYIAQAAAODBQBIFSOd69uwpSSpbtqx8fHzk6enp5ogAAAAA4MFEEgXIIFq0aKGoqCgdO3ZMV65cUVRUlMvnzZs3d1NkAAAAAPBgIIkCZBDbt29X165ddebMGZfugiXJ4XAoMjLSTZEBAAAAwIOBJAqQQQwYMED16tXT6tWrVbRo0Th76gEAAAAApB6SKEAGcfz4cS1dulQVKlRwdygAAAAA8EDycHcAAOxp2LCh/v77b3eHAQAAAAAPLGqiAOnYX3/9Zf0/ePBgDR8+XAEBAapRo0asXnpq1qyZ1uEBAAAAwAOFJAqQjj388MNyOBwuDcn26dPH+j/6MxqWBdzn9MT27g4hWTJq3AAAAO5EEgVIx06dOuXuEAAAAAAA/x9JFCAdK126tLtDAAAAAAD8fyRRgAzihx9+iHO4w+FQ1qxZVaFCBZUtWzaNowIAAACABwdJFCCDePrpp2O1jyK5tovStGlTrVixQnnz5nVTlAAAAADw70UXx0AGsXbtWtWvX19r165VcHCwgoODtXbtWjVs2FCrVq3Spk2b9M8//+j11193d6gAAAAA8K9ETRQgg3j11Vc1c+ZM+fj4WMMeeeQRZc2aVf3799ehQ4c0efJkl957AAAAAAAph5ooQAZx4sQJ5c6dO9bw3Llz6+TJk5KkihUr6urVq2kdGgAAAAA8EEiiABlE3bp19cYbbygwMNAaFhgYqDfffFP169eXJB0/flwlS5Z0V4gAAAAA8K/G4zxABjFnzhw99dRTKlGihJUoOXfunMqVK6eVK1dKkm7evKlRo0a5M0wAAAAA+NciiQJkEA899JAOHz6sX3/9VceOHbOGPfroo/LwuFep7Omnn3ZjhAAAAADw70YSBchAPDw81K5dO7Vr187doQAAAADAA4ckCpCOTZkyRf3791fWrFk1ZcqUBMsOGTIkjaICAAAAgAcTSRQgHfv000/VrVs3Zc2aVZ9++mm85RwOB0kUAAAAAEhlJFGAdOzUqVNx/g8AAAAASHt0cQxkMHfv3pW/v78iIiLcHQoAAAAAPFBIogAZRGhoqPr27avs2bOrWrVqOnv2rCRp8ODBmjhxopujAwAAAIB/P5IoQAYxcuRI7d+/Xxs2bFDWrFmt4a1bt9a3337rxsgAAAAA4MFAmyhABrFixQp9++23atSokRwOhzW8WrVqOnHihBsjAwAAAIAHAzVRgAwiMDBQhQoVijX81q1bLkkVAAAAAEDqoCYKkEHUq1dPq1ev1uDBgyXJSpzMnj1bjRs3dmdoAJBmTk9s7+4QAADAA4wkCpBBvP/++3rsscd0+PBhRURE6LPPPtPhw4e1detWbdy40d3hAQAAAMC/Ho/zABlE06ZNtW/fPkVERKhGjRr69ddfVahQIW3btk1169Z1d3gAAAAA8K9HEgXIQMqXL69Zs2Zpx44dOnz4sBYuXKgaNWqk6jzHjx8vHx8fZc+eXd7e3nGWOXv2rNq3b6/s2bOrUKFCeuONNxQREZHgdIOCgtStWzflzp1b3t7e6tu3r27evJkKSwAAAAAAKYMkCpBB9OjRQ3PnztXJkyfTdL53795Vp06d9PLLL8f5eWRkpNq3b6+7d+9q69atmj9/vubNm6fRo0cnON1u3brp0KFDWrt2rVatWqVNmzapf//+qbEIAAAAAJAiSKIAGUSWLFk0YcIEVahQQSVLllT37t01e/ZsHT9+PFXnO3bsWA0dOjTeGi+//vqrVSvm4Ycf1mOPPaZ3331XX3zxhe7evRvnOEeOHNGaNWs0e/ZsNWzYUE2bNtXUqVO1ePFiXbx4MTUXBwAAAACSjSQKkEHMnj1bx44d07lz5/Thhx8qZ86c+uSTT1S5cmWVKFHCbXFt27ZNNWrUUOHCha1hbdu2VUhIiA4dOhTvON7e3qpXr541rHXr1vLw8NCff/4Z77zCwsIUEhLi8gIAAACAtEISBchg8ubNq/z58ytv3rzy9vZW5syZVbBgQbfFExAQ4JJAkWS9DwgIiHecQoUKuQzLnDmz8uXLF+84kjRhwgTlyZPHepUsWfI+owcAAAAA+0iiABnEf//7X/n4+Ch//vzy8/PTnTt35Ofnp4CAAO3duzdJ0/Lz85PD4UjwdfTo0VRakuQbOXKkgoODrde5c+fcHRIAAACAB0hmdwcAwJ6JEyeqYMGCGjNmjJ599llVqlQp2dMaPny4evXqlWCZcuXK2ZpWkSJFtGPHDpdhly9ftj6Lb5wrV664DIuIiFBQUFC840iSl5eXvLy8bMUFAAAAACmNJAqQQezdu1cbN27Uhg0b9MknnyhLlixq0aKFfH195evrm6SkSsGCBVPsEaDGjRtr/PjxunLlivWIztq1a5U7d25VrVo13nGuX7+u3bt3q27dupKkdevWKSoqSg0bNkyRuAAAAAAgpfE4D5BB1KpVS0OGDNGyZcsUGBion376SVmyZNHAgQNVpUqVVJvv2bNntW/fPp09e1aRkZHat2+f9u3bp5s3b0qS2rRpo6pVq+qFF17Q/v379csvv2jUqFEaOHCgVWtkx44dqly5si5cuCBJqlKlitq1a6d+/fppx44d+uOPPzRo0CB16dJFxYoVS7VlAQAAAID7QU0UIIMwxmjv3r3asGGDNmzYoC1btigkJEQ1a9ZUixYtUm2+o0eP1vz58633tWvXliStX79evr6+ypQpk1atWqWXX35ZjRs3Vo4cOdSzZ0+NGzfOGic0NFT+/v4KDw+3hi1atEiDBg3SI488Ig8PD3Xs2FFTpkxJteUAAAAAgPtFEgXIIPLly6ebN2+qVq1aatGihfr166dmzZrJ29s7Vec7b948zZs3L8EypUuX1k8//RTv576+vjLGuAzLly+fvv7665QIEQAAAADSBEkUIINYuHChmjVrpty5c7s7FAAAAAB4IJFEATKI9u3buzsEAAAAAHig0bAsAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAZyFdffaUmTZqoWLFiOnPmjCRp8uTJWrlypZsjAwAAAIB/P5IoQAYxbdo0DRs2TI8//riuX7+uyMhISZK3t7cmT57s3uAAAAAA4AFAEgXIIKZOnapZs2bprbfeUqZMmazh9erV04EDB9wYGQAAAAA8GEiiABnEqVOnVLt27VjDvby8dOvWLTdEBAAAAAAPFpIoQAZRtmxZ7du3L9bwNWvWqEqVKmkfEAAAAAA8YDK7OwAA9gwbNkwDBw7UnTt3ZIzRjh079M0332jChAmaPXu2u8MDAAAAgH89kihABvHiiy8qW7ZsGjVqlEJDQ9W1a1cVK1ZMn332mbp06eLu8AAAAADgX48kCpABRERE6Ouvv1bbtm3VrVs3hYaG6ubNmypUqJC7QwMAAACABwZtogAZQObMmTVgwADduXNHkpQ9e3YSKAAAAACQxkiiABlEgwYNtHfvXneHAQAAAAAPLB7nATKIV155RcOHD9f58+dVt25d5ciRw+XzmjVruikyAAAAAHgwkEQBMojoxmOHDBliDXM4HDLGyOFwKDIy0l2hAQAAAMADgSQKkEGcOnXK3SEAAAAAwAONJAqQQZQuXdrdIQAAAADAA40kCpBBLFiwIMHPe/TokUaRAAAAAMCDiSQKkEG8+uqrLu/Dw8MVGhqqLFmyKHv27CRRAAAAACCV0cUxkEFcu3bN5XXz5k35+/uradOm+uabb9wdHgAAAAD865FEATKwihUrauLEibFqqQAAAAAAUh5JFCCDy5w5sy5evOjuMAAAAADgX482UYAM4ocffnB5b4zRpUuX9Pnnn6tJkyZuigoAAAAAHhwkUYAM4umnn3Z573A4VLBgQbVq1UqffPKJe4ICAAAAgAcISRQgg4iKinJ3CAAAAADwQKNNFCCDGDdunEJDQ2MNv337tsaNG+eGiAAAAADgwUISBcggxo4dq5s3b8YaHhoaqrFjx7ohIgAAAAB4sJBEATIIY4wcDkes4fv371e+fPncEBEAAAAAPFhoEwVI5/LmzSuHwyGHw6FKlSq5JFIiIyN18+ZNDRgwwI0RAgAAAMCDgSQKkM5NnjxZxhj16dNHY8eOVZ48eazPsmTJojJlyqhx48ZujBAAAAAAHgwkUYB0rmfPnpKksmXLysfHR56enmk6//Hjx2v16tXat2+fsmTJouvXr7t8vn//fk2cOFFbtmzR1atXVaZMGQ0YMECvvvpqgtMtU6aMzpw54zJswoQJ8vPzS+lFAAAAAIAUQRIFyCBatGhh/X/nzh3dvXvX5fPcuXOnynzv3r2rTp06qXHjxpozZ06sz3fv3q1ChQpp4cKFKlmypLZu3ar+/fsrU6ZMGjRoUILTHjdunPr162e9z5UrV4rHDwAAAAAphSQKkEGEhobqzTff1Hfffad//vkn1ueRkZGpMt/onn/mzZsX5+d9+vRxeV+uXDlt27ZNy5YtSzSJkitXLhUpUiRF4gQAAACA1EbvPEAG8cYbb2jdunWaNm2avLy8NHv2bI0dO1bFihXTggUL3B2ei+DgYFs9Bk2cOFH58+dX7dq19dFHHykiIiLB8mFhYQoJCXF5AQAAAEBaoSYKkEH8+OOPWrBggXx9fdW7d281a9ZMFSpUUOnSpbVo0SJ169bN3SFKkrZu3apvv/1Wq1evTrDckCFDVKdOHeXLl09bt27VyJEjdenSJU2aNCnecSZMmGDVjAEAAACAtEZNFCCDCAoKUrly5STda/8kKChIktS0aVNt2rQpSdPy8/Ozuk2O73X06NEkx3jw4EE99dRTGjNmjNq0aZNg2WHDhsnX11c1a9bUgAED9Mknn2jq1KkKCwuLd5yRI0cqODjYep07dy7JMQIAAABAclETBcggypUrp1OnTqlUqVKqXLmyvvvuOzVo0EA//vijvL29kzSt4cOHq1evXonOLykOHz6sRx55RP3799eoUaOSNK4kNWzYUBERETp9+rQeeuihOMt4eXnJy8srydMGAHc7PbG9u0MAAAApgCQKkEH07t1b+/fvV4sWLeTn56cnnnhCn3/+ucLDwxN8BCYuBQsWVMGCBVMstkOHDqlVq1bq2bOnxo8fn6xp7Nu3Tx4eHipUqFCKxQUAAAAAKYkkCpBBDB061Pq/devWOnr0qHbv3q0KFSqoZs2aqTbfs2fPKigoSGfPnlVkZKT27dsnSapQoYJy5sypgwcPqlWrVmrbtq2GDRumgIAASVKmTJmsRM2OHTvUo0cP/f777ypevLi2bdumP//8Uy1btlSuXLm0bds2DR06VN27d1fevHlTbVkAAAAA4H6QRAEyoDt37qh06dIqXbp0qs9r9OjRmj9/vvW+du3akqT169fL19dXS5cuVWBgoBYuXKiFCxda5UqXLq3Tp09Lutc9s7+/v8LDwyXdeyxn8eLFeueddxQWFqayZctq6NChGjZsWKovDwAAAAAkl8MYY9wdBIDERUZG6v3339f06dN1+fJlHTt2TOXKldPbb7+tMmXKqG/fvu4OMc2FhIQoT548Cg4OVu7cud0dDgD865TxS7intbRmt20Z4k4ZqdWWD8dvABkZvfMAGcT48eM1b948ffjhh8qSJYs1vHr16po9e7YbIwMAAACABwNJFCCDWLBggWbOnKlu3bopU6ZM1vBatWolqztiAAAAAEDSkEQBMogLFy6oQoUKsYZHRUVZbY0AAAAAAFIPSRQgg6hatao2b94ca/jSpUutxl4BAAAAAKmH3nmADGL06NHq2bOnLly4oKioKC1btkz+/v5asGCBVq1a5e7wAAD/QqnVsCgAABkVNVGADOKpp57Sjz/+qN9++005cuTQ6NGjdeTIEf3444969NFH3R0eAAAAAPzrURMFSOdOnjypsmXLyuFwqFmzZlq7dq27QwIAAACABxI1UYB0rmLFigoMDLTed+7cWZcvX3ZjRAAAAADwYCKJAqRzxhiX9z/99JNu3brlpmgAAAAA4MFFEgUAAAAAAMAGkihAOudwOORwOGINAwAAAACkLRqWBdI5Y4x69eolLy8vSdKdO3c0YMAA5ciRw6XcsmXL3BEeAAAAADwwSKIA6VzPnj1d3nfv3t1NkQAAAADAg40kCpDOzZ07190hAAAAAABEmygAAAAAAAC2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRACRo/Pjx8vHxUfbs2eXt7R1nGYfDEeu1ePHiBKcbFBSkbt26KXfu3PL29lbfvn118+bNVFgCAAAAAEgZJFEAJOju3bvq1KmTXn755QTLzZ07V5cuXbJeTz/9dILlu3XrpkOHDmnt2rVatWqVNm3apP79+6dg5AAAAACQsjK7OwAA6dvYsWMlSfPmzUuwnLe3t4oUKWJrmkeOHNGaNWu0c+dO1atXT5I0depUPf744/r4449VrFix+4oZAAAAAFIDNVEApIiBAweqQIECatCggf73v//JGBNv2W3btsnb29tKoEhS69at5eHhoT///DPe8cLCwhQSEuLyAgAAAIC0Qk0UAPdt3LhxatWqlbJnz65ff/1Vr7zyim7evKkhQ4bEWT4gIECFChVyGZY5c2bly5dPAQEB8c5nwoQJVs0YAAAAAEhr1EQBHkB+fn5xNgbr/Dp69Kjt6b399ttq0qSJateurREjRujNN9/URx99lOJxjxw5UsHBwdbr3LlzKT4PAAAAAIgPNVGAB9Dw4cPVq1evBMuUK1cu2dNv2LCh3n33XYWFhcnLyyvW50WKFNGVK1dchkVERCgoKCjBdlW8vLzinB4AAAAApAWSKMADqGDBgipYsGCqTX/fvn3KmzdvvAmPxo0b6/r169q9e7fq1q0rSVq3bp2ioqLUsGHDVIsLAAAAAO4HSRQACTp79qyCgoJ09uxZRUZGat++fZKkChUqKGfOnPrxxx91+fJlNWrUSFmzZtXatWv1/vvv6/XXX7emsWPHDvXo0UO///67ihcvripVqqhdu3bq16+fpk+frvDwcA0aNEhdunShZx4AAAAA6RZJFAAJGj16tObPn2+9r127tiRp/fr18vX1laenp7744gsNHTpUxhhVqFBBkyZNUr9+/axxQkND5e/vr/DwcGvYokWLNGjQID3yyCPy8PBQx44dNWXKlLRbMAAAAABIIodJqB9SAEjHQkJClCdPHgUHByt37tzuDgcAkE6U8Vvt7hBcnJ7Y3la5jBp3UnH8BpCR0TsPAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRACRo/Pjx8vHxUfbs2eXt7R3r83nz5snhcMT5unLlSrzTLVOmTKzyEydOTMUlAQAAAID7k9ndAQBI3+7evatOnTqpcePGmjNnTqzPO3furHbt2rkM69Wrl+7cuaNChQolOO1x48apX79+1vtcuXKlTNAAAAAAkApIogBI0NixYyXdq3ESl2zZsilbtmzW+8DAQK1bty7OhEtMuXLlUpEiRVIkTgAAAABIbTzOAyBFLViwQNmzZ9dzzz2XaNmJEycqf/78ql27tj766CNFREQkWD4sLEwhISEuLwAAAABIK9REAZCi5syZo65du7rUTonLkCFDVKdOHeXLl09bt27VyJEjdenSJU2aNCnecSZMmGDVjAEAAACAtEZNFOAB5OfnF29jsNGvo0ePJnm627Zt05EjR9S3b99Eyw4bNky+vr6qWbOmBgwYoE8++URTp05VWFhYvOOMHDlSwcHB1uvcuXNJjhEAAAAAkouaKMADaPjw4erVq1eCZcqVK5fk6c6ePVsPP/yw6tatm+RxGzZsqIiICJ0+fVoPPfRQnGW8vLzk5eWV5GkDAAAAQEogiQI8gAoWLKiCBQum6DRv3ryp7777ThMmTEjW+Pv27ZOHh0eiPfoAAAAAgLuQRAGQoLNnzyooKEhnz55VZGSk9u3bJ0mqUKGCcubMaZX79ttvFRERoe7du8eaxo4dO9SjRw/9/vvvKl68uLZt26Y///xTLVu2VK5cubRt2zYNHTpU3bt3V968edNq0QAAAAAgSUiiAEjQ6NGjNX/+fOt97dq1JUnr16+Xr6+vNXzOnDl69tln5e3tHWsaoaGh8vf3V3h4uKR7j+UsXrxY77zzjsLCwlS2bFkNHTpUw4YNS9VlAQAAAID74TDGGHcHAQDJERISojx58ig4OFi5c+d2dzgAgHSijN9qd4fg4vTE9rbKZdS4k4rjN4CMjN55AAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2ZHZ3AAAAAEBKOj2xvbtDAAD8S1ETBQAAAAAAwAaSKAAAAAAAADaQRAEQr9OnT6tv374qW7assmXLpvLly2vMmDG6e/euS7m//vpLzZo1U9asWVWyZEl9+OGHiU777Nmzat++vbJnz65ChQrpjTfeUERERGotCgAAAADcN9pEARCvo0ePKioqSjNmzFCFChV08OBB9evXT7du3dLHH38sSQoJCVGbNm3UunVrTZ8+XQcOHFCfPn3k7e2t/v37xzndyMhItW/fXkWKFNHWrVt16dIl9ejRQ56ennr//ffTchEBAAAAwDaHMca4OwgAGcdHH32kadOm6eTJk5KkadOm6a233lJAQICyZMkiSfLz89OKFSt09OjROKfx888/q0OHDrp48aIKFy4sSZo+fbpGjBihwMBAazqJCQkJUZ48eRQcHKzcuXOnwNIBAOA+ZfxWuzsEF6nVQC/HbwAZGTVRACRJcHCw8uXLZ73ftm2bmjdv7pL4aNu2rT744ANdu3ZNefPmjTWNbdu2qUaNGlYCJXqcl19+WYcOHVLt2rXjnHdYWJjCwsKs9yEhISmxSAAApAv0KgQA6R9togCw7e+//9bUqVP10ksvWcMCAgJckiGSrPcBAQFxTic540jShAkTlCdPHutVsmTJZC0HAAAAACQHSRTgAeTn5yeHw5HgK+ajOBcuXFC7du3UqVMn9evXzy1xjxw5UsHBwdbr3LlzbokDAAAAwIOJx3mAB9Dw4cPVq1evBMuUK1fO+v/ixYtq2bKlfHx8NHPmTJdyRYoU0eXLl12GRb8vUqRInNMuUqSIduzYkaRxJMnLy0teXl4Jxg0AAAAAqYUkCvAAKliwoAoWLGir7IULF9SyZUvVrVtXc+fOlYeHawW2xo0b66233lJ4eLg8PT0lSWvXrtVDDz0UZ3so0eOMHz9eV65cUaFChaxxcufOrapVq97HkgEAAABA6uFxHgDxunDhgnx9fVWqVCl9/PHHCgwMVEBAgEu7JV27dlWWLFnUt29fHTp0SN9++60+++wzDRs2zCqzfPlyVa5c2Xrfpk0bVa1aVS+88IL279+vX375RaNGjdLAgQOpaQIAAAAg3aImCoB4rV27Vn///bf+/vtvlShRwuWz6N7R8+TJo19//VUDBw5U3bp1VaBAAY0ePVr9+/e3ygYHB8vf3996nylTJq1atUovv/yyGjdurBw5cqhnz54aN25c2iwYAAAAACSDw0RfCQFABhMSEqI8efIoODhYuXPndnc4AADABo7fADIyHucBAAAAAACwgSQKAAAAAACADSRRAAAAAAAAbCCJAgAAAAAAYANJFAAAAAAAABtIogAAAAAAANhAEgUAAAAAAMAGkigAAAAAAAA2kEQBAAAAAACwIbO7AwCA5DLGSJJCQkLcHAkAALAr+rgdfRwHgIyEJAqADOvGjRuSpJIlS7o5EgAAkFQ3btxQnjx53B0GACSJw5ACBpBBRUVF6eLFi8qVK5ccDoe7w4lTSEiISpYsqXPnzil37tzuDsc24k5bxJ22iDttEXfayghxG2N048YNFStWTB4etC4AIGOhJgqADMvDw0MlSpRwdxi25M6dO92ezCaEuNMWcact4k5bxJ220nvc1EABkFGR+gUAAAAAALCBJAoAAAAAAIANJFEAIBV5eXlpzJgx8vLycncoSULcaYu40xZxpy3iTlsZNW4AyChoWBYAAAAAAMAGaqIAAAAAAADYQBIFAAAAAADABpIoAAAAAAAANpBEAQAAAAAAsIEkCgAAAOAm9PEAABkLSRQAAB4gkZGR7g4BgKQlS5YoKChIDoeDRAoAZCAkUQAAaS4qKsr6/+LFi26M5MGTKVMmSdKxY8dIqCBOztvnv1nM5UzLRMb8+fM1fPhwffnll7p+/TqJFADIQEiiAMADJL1cHHl43Dv8/Pe//9V7772na9euuTki++L7DtPLdxufNWvWaPDgwZKkIUOG6I033tCdO3fcHFXKyqi/TVzceUEdvX1OmzZNv//+u9viSG3RyzllyhSdOHFCDocjzebds2dPde7cWStWrNCUKVN07dq1DJFIyYjbEgCktMzuDgAAkDaMMdZFw48//qizZ8+qfv36qlq1qnLmzJlmMURfqGzatEnff/+9Fi5cqLx586bJ/O+X83c4depU+fv7KyoqSmPGjFHhwoXdHF38wsLCtG/fPq1du1aNGjXS0aNHtX37duXIkcPdoaUY599m1qxZOn/+vBwOh8aMGWMNzyiioqKsmP/55x85HA7ly5cvzeZvjFFgYKDefvttLViwIM3m6w6nTp3Shx9+qGbNmqXZPMPCwuTl5aWPPvpIr732mn799Vd5eHhoyJAhyp07t8t+Mj1x3sa+/vprXblyRbly5VLfvn3dHBkApK2MdVYBAEi26JNyPz8/de/eXZ9//rlatGih9957T8eOHUvTGKZOnaqffvpJ7du3V/369dP93Vfp3oVtdPyjRo3S2LFjdfHiRW3cuFHVqlXTzp073Rxh/Ly8vDR06FAVL15cO3bs0JNPPqnKlStL+ne0keL82/j5+WnEiBHavHmzZs6cqRo1auj8+fNujjBpoi9U3377bbVv3161atXSxx9/rICAgFSbZ3QNg+jvslChQqpVq5b8/f0l/XsaP41Zk6JkyZLy9PTUpk2b0mT+xhh5eXlJuvdIj6enp44ePapPP/1Un3/+ebp9tMc5sTNy5Ei99NJLWrJkiV566SV16tSJxzIBPFBIogDAv5zzRfKOHTu0c+dOrVmzRkeOHNFnn32mFStW6PPPP0+zRIokrV27Vh9++KH27t2rW7dupcu7rjFFX9gGBQUpJCREa9as0bJly7Rx40a1bNlS7dq1044dO9wcpavoC7GoqCjduXNHTZo00Wuvvab9+/frtddek3SvjZTw8HA3Rnn/on+b4OBgnT9/XuvXr9cvv/yiLVu2KFeuXGrdurXOnj3r5igT53yBP336dM2ZM0fdu3dXjx499NZbb2ncuHE6efJkqsw7+js8ceKENSxv3rzWOh29jaa3i/ukil7OGzduKCIiQpkzZ1aVKlV048YNSVJERISk1FvO6O9x7Nixeu211/Twww9r1qxZat68ub766itNnTpVwcHB6SqR4pxAOX/+vHbs2KHNmzdr7dq12rNnjzZu3Kh+/frpwoULbo4UANIGSRQA+JfavHmzpP9rSHTGjBmaPn26SpQooUaNGkmS+vfvr9dff12//vqrvvjii1RJpDhfCERfJP7www966aWXtHnzZq1YsUJhYWEpPt+UsGDBApf4FyxYoEKFCumPP/6wHoEqUKCA5syZo0ceeUSPP/54ukmkONfO8PDwUJ48eTRu3DiNHj1aXbt21W+//WYlUjw9PSVJ+/fvzzBtHvz6668u77/88ktVqVJFly5dUv78+eXp6aly5cppyZIlyps3r9q2batz5865KVp7oi/w9+zZo4CAAH3++ecaNGiQxo8fr++//17ffPONPvzwQ506dSpV5j937lzVqVNHtWrVko+PjyIiInT+/HmtWrVKQUFBunHjRoZIeCZm1qxZKlq0qHx8fDRgwABduHBBv/76q/z9/RUcHCxJqbacUVFRCgwM1IoVKzR+/Hh169ZNzzzzjJYvX65WrVpp5syZ+vLLL9NFImXHjh2KjIy0vosPPvhA3bt3V548eVS2bFllz55dNWvW1KZNm7Rz50699NJLJFIAPBBIogDAv9CQIUP0zTffuJyAnzhxQvPmzdOePXtcTnRffPFFvfHGG/rtt980fvz4FL3QdL6Qj4yMdGnIdNq0aerUqZMGDhyon3/+WXfv3k2x+aaElStXatKkSS7fYaNGjfT444/r0KFDun37tqR7y5g7d27Nnj1bjz76qBo1aqTDhw+7K2xL9AX5p59+qp49e+qFF17QoUOH5O3trRdffFE9evTQunXr9MorrygkJERt2rTRpEmTMkT7IdOnT9fIkSNdfps6deqoePHi2rt3r7XORUVFqUSJElq6dKny58+vmjVr6vLly+4KO1HGGO3du1f16tXT+PHjrdoRktShQwd99dVX+vbbb/Xxxx/r+PHjKT7/unXr6o8//pCfn5+aN2+uTJky6Y8//tAbb7yh6tWrq1atWmrdurW+/vrrFJ93WqpXr55mz56tvn376vbt2ypQoIC2bNmi5s2bq3nz5mrWrJkee+wx7d69O0Xm57yeenh4qGDBgsqcObNu3rwp6f9qv3zxxRcqUaKEZs2apffee8+tSavXX39dfn5+VhJekmrUqKH9+/dr586d1roZFRWlypUra/PmzdqzZ486duyowMBAt8QMAGnGAAD+dY4ePWru3r1rjDHmyJEj1vCPP/7YFCxY0Lzzzjvm4sWLLuN89tln5vnnnzeRkZEpEkNERITLfJ999llTrVo1M3XqVHPixAnrs86dO5u8efOaFStWmLCwsBSZd0qJXoYtW7ZYw/7++2/TokULU7p0aXP+/HljjDFRUVHGGGOuXbtmRo0a5bLsac359xs9erQpUKCA6datm2nYsKHJmjWr+emnn4wxxly9etV89tlnplSpUqZEiRKmTp061jqTEUTHeuDAAWPMvd9g165dplKlSqZx48bWuhT925w+fdr079/frb+NXV9//bVxOBymX79+JjAw0OWzVatWGYfDYT788MP7moed7fz33383RYoUMUePHjXr1q0zX375pRk5cqQJDw+/r3mnpcSWMyoqyvz888+mefPmZsOGDea3334zb775pnn11VdTZDl37txp/T9x4kQzf/58ExUVZTp06GCaNWtmzSN6vezdu7epUKGCGThwoLXuukv0NnTixAnr//Xr15ucOXOa3r17m9DQUGPM/21jBw4cMO3bt0+xYwgApFckUQDgX8b5Qvirr74yjRo1MkuWLLGGvfPOO6ZkyZLmvffeM5cuXXIZN/pkOCVPgkeOHGmKFClixo4daz799FOTM2dOM2jQILNnzx6rzPPPP28cDofZtGlTis33foSEhFj/79q1yzgcDjNu3Dhr2IkTJ0zTpk1NmTJlrERKzO/M3Realy9fNiNHjjTbtm0zxtxbpgEDBpisWbOa1atXG2OMuXXrljl16pRZtWqVdRHn7rgTE33hZowxv/32m3E4HGbBggXWsF27dpny5csbHx8fa1uIeTGaXhIpCW1nc+bMMQ6Hw4wePdoEBQW5fPbHH3/c1+/kPN+ff/7ZLFq0yHz99dfWsOjv7dq1a6ZixYrmjz/+iDWN9PIdJsR5OTdu3GjWrFljNmzYEKvcsWPHjJeXl9m6dWusz+5nOc+cOWMcDocZOHCgGT58uMmVK5c5ePCg9VnhwoXNc889Z4KDg63vvHPnzmb58uVW7O5IpDjv/xYtWmQyZcpkfv75ZyvGX375xWTPnt28+OKL1vYYc10mkQLg34wkCgD8iyxbtsyMGDHCBAcHG2OM+fPPP03z5s1N+/btzffff2+Ve+edd0ypUqXM+++/byUBot3vSfvy5ctNz549rf/Lly9vduzYYYwxZvfu3cbhcJh8+fKZ7t27m/3791vjjR49Ol1cwM+fP988+eST5vDhw9awL7/80mTJksW899571rATJ06YZs2amfLly5szZ864I9R4ffPNN8bhcJgqVaqYvXv3WsNv375tBgwYYLJly2bVSHGW3i+MFy5caF566SVz9uxZa9jrr79usmXLZhYuXGgN27Vrl6lQoYJp1qxZuqvdFM35InPZsmVm2rRp5osvvjBBQUHWNjhz5sx4EynGJC/h5bx9jxgxwpQrV85UrVrV1K5d2zRt2tTcunXLKnf79m1Tvnx589FHHyV5Pu7mvJwjR440JUqUMNWrVzeenp5m2LBhLttscHCwqVSpkvnxxx9TNIbIyEizdu1a4+npaXLlymWOHTtmjPm/JNWWLVtM0aJFTdWqVU2rVq1M3bp1TcWKFa3t0B2JiKVLl5qRI0eaU6dOWcMeffRRU7x4cbNmzRqXREqOHDlM//79rXUGAB4UJFEA4F/iwIEDxuFwmDJlyhg/Pz/zzz//GGOM2bNnj2nVqpVp166dSyJl7NixxtPT08yfPz/FYggPDzdjxowxlStXNmfOnDE//fST+eyzz4wxxvz444/G29vbfP311+ann34yDofDDBgwwKop4TwNd4iMjDSBgYHGw8PDOBwO89RTTxl/f3/r8+nTpxsPDw+XRMrJkydN5cqVTceOHd0RsuXPP/80ixcvNp9//rkx5t5d7h49epjMmTObdevWGWP+74Ls9u3bZuDAgcbhcMT67tOryMhI665+9Hpz4cIF6/M333zTeHp6uiRSdu/ebXLmzGkGDBjgjpATFDORUbhwYfPII4+YAgUKmDZt2pg1a9ZYv9fMmTNNpkyZzGuvveZSQ+B+ffzxx6ZIkSJWgnPq1KnG4XCYunXrmmvXrlnl2rRpY0aNGpVi801rEyZMMEWLFrVqmYwfP944HA7Tp08fl2Rc7dq1zX//+98UmeehQ4esxyV///1343A4jJeXlxkyZEisstevXzfvvPOOee2118yIESNiPd6Tlg4ePGgcDofJli2beffdd83ff/9tfdauXTtTuHBhl0TKr7/+ahwOh5k4cWKaxwoA7kQSBQD+JY4dO2YKFixoqlatap566inzxhtvWHevd+/eHWciZc6cOSl+sn7w4EGTPXt2M2vWLGOMMefPnzeBgYGmUaNG5oMPPjDG3HuMpHTp0unyBHz8+PGmbdu2pnDhwqZhw4bW3WNj/i+RMn78eGvYhQsX3FqDY/78+aZGjRqmT58+VsLKGGPOnTtnnnnmGZMvXz6XdkOMufdIzEcffZQuav4kxauvvmqaNGlismXLZjp27OjyOFpciZSjR4+m69o1n376qSlRooTZvXu3McaYxYsXG4fDYXx9fc3PP/9sJVI+/fRT4+Pjc1+1xJwfgzp37pzp3r27tS9YtWqVyZ07txk9erSpUqWKadCggZVIWb58eYZaT6J/76ioKHPmzBnTpUsX63HGZcuWmbx585qhQ4caLy8v06dPH3P8+HFjjDGzZs1KkeX8+uuvTc2aNc2rr75qJbIvXbpkfvrpJ5M9e3ZbST13ft9t27Y1RYsWNfnz5zd+fn4uNVKiEym//PKLlUjZsWNHhlo/ACAlkEQBgH+RL7/80rRo0cK8+OKLpmHDhmbEiBEuiZRHHnnEPP744y4Xmsak3F3P6Iu+4cOHm1q1alm1BU6ePGmqVq1qVq1aZYwxJiAgwAwaNMisXLky3VzkRl+gLl261Dz++OPm4MGD5uGHHzYNGjSIlUjx9PQ0fn5+LuO7YzkWLlxosmXLZr799luX2gPRLly4YJ588kmTP39+qy2G9NZ2ix3RMc+aNct07drVbN++3RQsWNA8++yzLomUESNGmKxZs5qZM2e6jJ9e1jFn169fN8OGDTOzZ882xtxb77y9vc3EiRNNlSpVTN26dc3q1atdkgLOf5Mirkc0vv/+e3PhwgWzc+dOU7p0aTNt2jRjjDEffPCBcTgcpkSJEubGjRtW+fT4HcYU83HGa9eumW+//daEhISY7du3m9KlS5spU6YYY+49PuhwOMwzzzzjUsPnfpZzzpw5JkeOHGbmzJkuDcoac+8RnqVLl5ps2bKZQYMGWcMHDRpkvv32W2OMe9o/iRadFJk3b57x8/MzU6dONTly5DBvvPGGy3rz2GOPmWLFipmVK1e67Dsywn4EAFIKSRQAyMCiT3yjT2A3bdpknn76abN//37z/vvvm7p167okUvbs2WNq1qxphg0bluKxOF98rF692hQvXtz88ssvxhhj9u3bZwoXLmz8/PzM8uXLzeOPP25atmwZ57hp7c6dO7GG+fj4mFdffdUEBgaaSpUqmUaNGrkkUj755BPTtGlTt170nDhxwtSsWdO6KIwWM6boREqhQoVc2kfJCGKuF2FhYaZs2bJm0qRJ5siRI8bb29s899xzLomUAQMGmObNm6d1qEkWHh5uNm/ebK5cuWIOHDhgKlSoYCZPnmyMuffom6enp6lbt67VqGtUVFSy1reYj2g4XxAbc6+Wy5NPPmklTObNm2d69eplXn755QyROInm/DjjyJEjraTizZs3jTHGvP322+bpp5+23k+cONE8++yzpmXLlinS9siWLVtMyZIlzdKlS2N95tzY95IlS0y2bNlM8+bNjY+Pj6lQoYJbExAxe+Q6ePCgKVCggNmyZYtZtWqVyZkzpxkxYoTLelO/fn3ToUOHNI4UANIPkigAkEH98MMPZsiQIS7tdhhjzOOPP2610TF69GjToEED4+fnZ11U+Pv7p1iDhRs3brR6eompffv2plGjRtaF36xZs0zRokXNQw89ZJo2bRpvzylpafbs2eaRRx4xkyZNcrlI+O2338xjjz1mrl+/bi5dumTKli1rfHx8rKr/xtxfzYCUsHXrVlO6dGnrUZ2YnH/joKAg07hxY/PYY4+lVXj3be7cueaFF14w8+bNc2m48ptvvjHPPvusiYyMNDt27DC5cuUynTp1MgEBAVYZd3cNG1PM7S163Y8ePmPGDNOkSRNz5coVY8y9R0K6du1q+vXrlyKJjJiPaJw7d876bPDgwaZUqVLGmHuP2T311FMuPVFllERKzMcZ33zzTXP9+nVjzL2EVefOnc1jjz1mQkNDTXh4uHniiSesmnHG3H8jrnPnzjVt27Z1WVd/++03M3r0aNOoUSPz5ptvWg1p79y507zwwgtm+PDh1rrgju/5u+++M0OHDo2V+Jk4caJ5/PHHjTH3atfkypXL+Pn5mdOnT1tl6H0HwIOMJAoAZEC7du0ymTJlMg6HwxQvXtyMHDnS/O9//zPGGHPkyBHz5JNPmr/++stEREQYPz8/4+PjYwYMGJBi1fOjoqLMtWvXTPHixU3x4sVNkyZNzJo1a1wuzlavXm0qVapk1qxZYw07deqUOX36tHUC7q47sFFRUeaff/6xGipt2bKlyZ8/v/noo4/M77//bu7evWuqVq1qvvjiC2PMvTYNKlWqZCpUqOCyjO68WF+4cKHJmTOnCQwMjLfMiRMnrJoqgYGBGeLCJyoqypw7d876bRo3bmwqVKhg5s2bZ/bv32+uXLliSpcubV0A79y50+TLl8888sgjVhsU0dNJD5y/888//9z069fPtGjRwsybN89q2PT999831atXN3/99Ze5fv3/tXfncTXl/x/AX+feSiOpGF9hKGuypYYUsoSRBoOQ3XcmQ5JKyJ5dtkKNpoQsY8m+liXriBn7ktGUkl2krO3d9+8Pv3u+91YI6d7L+/l4zOP77dxz7n2fc889zud9Pu/P5xl1796dlixZIm73sb/Vd5VoyM/j2NhYql69OhkbG1PDhg2pQYMGGluaUbCcceLEiWIiZc+ePSQIAtnY2FD9+vWpUaNGJbqf06ZNo6pVq4p/jxs3juzs7MjKyoqcnJyoYcOG5OzsXOTvVRXHW95zR0dHh4yNjalHjx60bt06evr0KV2/fp1atWpFcXFxRPQm2WxoaEgjR45U6vWlCdcTxhj7HCRgjDGmcf7zn/9g0KBB6Ny5M5o0aQJdXV34+fmhV69e2LNnD+7fv4+DBw9CKpVizpw5sLKyQn5+PvT09MT3kEqlH/35giDA0NAQZ8+eRXh4OHR1dTFy5Eg4ODggPDwcd+/eRZcuXVCuXDls2bJF3M7U1BQmJiaQSCSQyWTQ0tL6pOPwKfFXqFABJ0+exDfffIM6depg4sSJiI2NhZubGyZNmoRmzZph+fLluH37NoyNjXHs2DFYWVmhSpUqSu+jKgYGBnj9+jUuXrwIAJDJZIXW2b9/P27evAkA+Pbbb8Xjrs4EQcB3332HtWvXAgDatWuHnj17IioqCr169cLWrVthYWGBhQsXIjU1Fc2aNcP+/fshlUphaGio9D7qQCJ5c6s1YcIEzJs3DxUrVkTnzp3x888/IyAgAPn5+ejfvz/S0tLQvXt3WFhY4Pbt2xg1apT4Hh/6W83NzQUAaGtrAwCaNWuGlStXwtLSEhEREfj9998RFBSEhw8fomHDhjh06BDc3Nzg4uKCK1euQEtLC/n5+SV0BD4f+X7m5eUBABo1agQjIyOMHj0aP/30Ew4fPgw/Pz+kp6ejW7duiIyMhK2tLfr164dLly6V6H4OHToUOjo6qFGjBurUqYMtW7Zg4MCB2L17N7Zt24bhw4fj0KFDeP78udJ2RKSS62CjRo3g5eWFatWqwd3dHXp6eoiMjIS1tTXi4+ORkpKCSZMmgYjg4uKCOXPmICEhAZUrVxbfQ35uM8bYV0fVWRzGGGMfRv6E/datWzRs2DDq2LEjLVu2jJ49e0YTJkygoUOHkiAIVL9+ffEpbH5+fomXnxR8Crl3717y8vKismXLkpWVFc2cOZOCg4OpQoUK9Ndff5XIZ5YkefzR0dEklUrJx8eH4uLi6ObNm9SnTx+ytLSkqlWriiUWitSlxMHa2poaNmwo9sBQ/E4yMjKoZ8+eSlMyawLF8zMkJISkUiktXbqU4uPj6dixY2Rvb0+1a9emWrVqUXp6eqHzWR2fjp88eZJq1qwpTid88eJFEgSB1q9fL65z+/ZtWrlyJa1atUrsmfAxPRQ+pETDx8dHnIpXkbqc3+/yoeWM8nGhFPetJHuA5OXl0bVr12j27Nk0Z84cevbsmdK5eODAAWrevLlSSYyqKB6DESNGUNOmTSkoKIiSk5Ppt99+o59++on+85//kLm5eZG9u9SllxdjjKkKJ1EYY0wDKSZShg8fTs2aNaPw8HAietOIXLlypThWhuKN/Oe4+S3YaD1//jzNnz+fvvvuOypfvjwJgkChoaEl/rklQR77oUOHSCqV0s8//0yZmZmUn59Pt2/fpqSkJCJSv0aDPJ4dO3ZQ5cqVqXHjxvTPP/+I+5OQkEBdunQha2trjSzNUDzewcHBJAgC+fr6EtGbcTuuXr0qNp7V7bshIsrMzFT6Oyoqitq1a0dEb6YxLleuHAUHBxMR0fPnz4tMMn5MIuNjSjRcXV0pJSXlgz9LlT60nNHW1pZGjhwpDipb2jIyMujHH38kJycntTlfFc8vV1dXql27tli++Pz5c4qJiaGrV68S0ef/N4QxxjSNQESk6t4wjDHGPhwRQRAE3L59G/PmzcPly5cxYMAAeHp6iuvIZLJS7XItjwkAsrOzsXz5cty6dQtLlixRWenO+8iP0ZEjR+Dg4IDBgwfDz89P7LZe2sfwQ2RnZ2Pbtm2YM2cOkpOT0bRpU+Tl5SE/Px/ffPMNjh8/Dm1tbeTn539S+ZYqKJ5LK1asgKurK6ZOnYpx48ahfPnyANTzu9mwYQP+/PNPTJkyBdWrVwcA7N27F2PHjsW0adMwevRo+Pn5YeTIkQCA3bt3Y926dVi2bBm+++67T/58b29v7Nq1Cy4uLrhx4wby8/Nx7tw5LF68GOPHj0fjxo2xfft2CIKA5cuXY9euXTh06JDalD8Vx927dzFt2jSkpKRAEATY2Njgjz/+QKNGjWBjY4MtW7agX79+GDduHPLz8+Hl5YXs7GyEhoZ+1v2Un7Py/3358iXi4+Mxbdo03L9/HxcuXICWlpbanLeK1wV3d3fs27cP48ePx4ABA2BkZARAPX9jjDGmapxEYYwxDVYwkXLt2jX069cPHh4eKo2rqEZ7Xl6eRiRSunTpgp9//hnTpk0rkUbt5yL/7vPy8pCamoqwsDDcv38furq6aN68Ofr16wepVKrWx/19FBMpYWFhGDFiBGbMmIFRo0ahYsWKKo5OmUwmw71792BqagoAGDFiBKZNm4aqVavi+fPnGDBgAKKiojB79mxMmTIFAJCVlYW+ffuiXLly2LBhwyc18BV/c66urvj777/h4uKCbt26Yd++fTh8+DDOnDmDihUr4tSpU6hQoQKAwg1/dSePMzk5GXPnzkVycjK6deuGoUOHws/PD48ePcK6detgZmaGv/76CwYGBpDJZBAEoVT3Mzs7G35+fjh06BAqVqyIHTt2QFtbW+1+jwUTKQcOHIC3tzf69esnniOMMcaUcRKFMcY0nGIiZf78+eJgin369FF1aGph79690NHRQefOnd+5njyRcvToUXTs2BHz5s3DxIkTSynKz0MTe6AUpNjoXblyJYYPH46VK1fil19+UXFkRfPy8sL58+dx8eJF/Pjjj1i+fDn+85//YMuWLQgICICuri4mTJiA1NRUbNiwAffv3xcHOf3Up/6K3/fIkSNx+PBheHt7w83NDS9evEBsbCz09fXRuHFjpc/SlASKnGIixc/PDxcvXsSoUaPw3//+FzKZDOHh4WjRogUaNWqksv3MyclBbGwsUlJS0LlzZ0gkErVLoMgpnjceHh5YvXo11q1bh169eqk4MsYYU0+cRGGMsS+AvHGQlJSEbdu2YezYsSXSeH5bo05TGl0hISHw9PTEkSNH0Lp16/euL9/fCxcuwMLCQmUNnqKOu6Yc889Bcd/37NkDR0dHtWuMyr+zlStX4tixY/Dw8EC3bt3QqlUrhIeHw9DQEFu3bsXmzZtx6NAhWFhYoHr16li3bl2Jllx9LSUapVnO+LHXQcXX1TWBIqd43ixZsgQeHh4an4BljLHPhZMojDGmhj7m5r/gDf2nNsoUY5BPe2piYoJy5coV+XlFxZGbmytOs1rawsLC4O7ujg0bNqB3797F3k6xsZOfnw+JRFKqyQvF47dz505UqFABbdu2LfTau7YD1LsXysec34olGYBqzy1FBY9zTk4O6tevj9GjR6NLly6wtbWFvb09Vq1aJU7BfPv2bVSpUgXa2tpiSVZJNrC/lhKN0ihn/NjroOJ2OTk50NHRKbGYiuNjEj8Fz2V1+Y0xxpi60ezHEIwx9gVSvPn9999/8fjxYzx//lx87W0K5sQ/tQEtj8HHxwe9evXC999/j2HDhmH37t0AAEEQCsWjeIMeHByMvn37Ii8v75Pi+BibNm3CiBEjEBwcjN69exc7BiISG7N37tyBVCot1QSKPFEAAPHx8Rg6dCiCg4Nx7tw5ABDHdCgqbvl2u3fvRkpKikYkUC5cuICTJ08iKytLfP1tz3YUEyipqalq0bhbs2YNfv75Z6xduxYZGRkAAB0dHcybNw+nTp1CvXr1cOjQIRw+fBi//vorHj16BAAwMTGBjo6O+H2WdA8FqVSK/Px8AMBvv/0GR0dH+Pj44Pjx4yX6OaomP34mJiaYPHkyLCwsEBgYiK1bt5bYZ3zsdVC+XXBwMJydnUv1Olgw8XP9+nW8evVKjPdtvzHFpAsnUBhj7B1KdK4fxhhjJWby5MlkYmJCtWvXJicnJ4qNjSWiwlMKEylPO7ls2TKaOXPmR3+u4vvv37+f6tatS9HR0bR161b64YcfyN7enjZu3FjosxVjCAkJIQMDA9qyZctHx/GxQkJCSBAEMjExofr169O9e/eIqOjjpqhg/NbW1vTw4cPPGuvbPn/y5Mnk6elJtWrVIh0dHercuTP9/fffRa5bMG5dXV06fvx46QT9CcaNG0fVqlWjsmXLUosWLWjLli2UnZ1NRIWnUVX8OzQ0lDp16kTp6emlGW6heO7evUuCIJAgCGRra0t16tShNWvW0JUrV+jx48dkYmJC+/btIyKic+fOUYUKFahDhw6UlpZWanEqTmMbEBDwUdMmawL5+ZGYmEgLFiwokf3U9OsgEdH48eOpVq1aVKZMGXJ2dqZdu3aJrxW8HirGvXz5curRo4dGTo/OGGOlgZMojDGmJhRvYqOioqhKlSoUGRlJCxcupO7du5O5uTldvnyZiJRvgAs2MHV1dWnTpk2fHM+BAwdo1KhRtHjxYnHZtWvXqGfPntS+fXulBoTizXZISAiVL1+etm3b9skxfKjg4GDS0tKinTt30uPHj6lVq1ZUq1YtevDgARG9PZFSsOFTrlw52r59e6nEXNCyZcvI0NCQzpw5Qzdu3KBjx46RsbExde3alc6ePSuuJ5PJCsVdvnx5lcX9PorHPjIykho3bkyHDx+mq1evkqOjI1lbW9OqVasKJVIK7qOenp7a7OO6detIEASaNGkSjR8/npydnal27dq0fPly6t69O7Vp04aePHlCRERnzpyhH3744b3JvHcpzvlbUMGEQk5Ozkd/fmn5mGNU8BiUVMJIk66DX0LihzHGNAEnURhjTM1s3LiRfH19KSgoSFwWExNDP/30E5mZmdGVK1eI6E0jQfGmuSQb0bdv36aGDRvSN998Q56enkqvyRsQHTt2pJUrVyq9FhoaqpIESn5+PqWkpFCtWrWUPjshIeG9iRR1S0QMGjSIBg0aRET/i+3cuXNkaGhIjo6OdObMGXFd+euqTFx9qO3bt9P48eNp9uzZ4rKMjAzq06cPNW/enFavXi0mUhQbwuq0jwXPGalUSkuXLqX4+Hg6duwY2dvbU+3atalWrVqUnp5eqIH/MUkCxW0uX75MsbGx9PLlyyJjelusmpZAiYuLo5SUFHr27Fmh1961XUnRtOugnCYlfhhjTBNxEoUxxtRIXFwc2djYkJ6eHgUEBCi9FhMTQz169KAGDRrQuXPnlF771Jv2op5I/vnnn9SqVSuytLSkAwcOKK0fGxtLbdq0odGjR4vL1qxZQ4IgqCQBIW9APX78mIiUG983b94sVo+U33//nQwNDVXWgJD3LOnTpw85OTkR0Zv9kCcUAgMDSVtbmwYMGEDXrl0TtwsMDFRp3B8iIyODGjRoQIIg0MCBA5Vey8zMpD59+pCNjQ0FBQWJ+030v6fj6rSPir+V4OBgEgSBfH19iYjo9evXdPXqVfr3338LrfupvpYSDVWUM2r6dZBIcxM/jDGmSTiJwhhjKlRU42rbtm1kY2NDdevWpVu3bim9dvr0aWrdujX1799fXLZs2TIqW7bsR9+0KzZKHjx4QA8ePBAbsKdPn6ZWrVpRjx496PDhw0rbJSUlidu+fv2agoKCaM+ePR8Vw6eIioqi8PBw8Wm1XFGJlNq1a4uJFMVjv2PHDtLR0VFZ13tFmzZtIkEQxPE05HGuWLGCevToQcbGxjRy5EgietMoqlevXomUb30ORZ3fqamp1LFjR6pfvz7t3r1b6XvKzMwke3t7GjZsmLjt5s2bSUtLSy0bdwVL6QRBoGnTptHz58/F5Z/aQ+JrKdFQdTmjpl4Hv4TED2OMaRpOojDGmIoo3rS/evVKaRDTQ4cOkZ2dHbVr146Sk5OVtrt27Zq4rUwmoylTpig1oj6E4o337NmzqVmzZmRubk7m5ubizfepU6fEBkR0dPRb90Ox50BpSUhIIF1dXWrRogXVrFmTVq9erTQAq6KbN29SmzZtSE9Pj1JTU5Vei4iIoKNHj5ZGyESk/N0nJyfTtWvXlMqz3NzcSFdXl7Zs2UJPnz6l9PR06tatG23atIm2b99OgiBQQkICpaamUlJSUqnF/SEU9zEhIYGSk5MpISGBiIiePHlCLVu2pNatW9P+/fuVzsPs7GylcyokJIQOHjxYusF/AMXYV6xYQYIg0MyZMwudY5/qaynRUEU5o6ZeBzU18cMYY5qOkyiMMaYCijftc+bMoQ4dOlDlypVp6NChFBkZSUREe/bsIXt7e2rXrh3dvn270HuU5EwbM2bMoEqVKtH27dvp/v371Lx5czI1NRUb6CdPnqQ2bdqQnZ1doVIiVbp79y41bdqUtm/fTtu2bSNnZ2cyMTGhSZMmUUxMTKH1b9y4Qa6uriqdpUSx4TNt2jRq1KgR6evrU/v27WnNmjWUnZ1Nz549o/Hjx5OWlhbVqVOHatSoQQ0aNKDs7Gw6ceIE1a5du1RnDvpQiuf39OnTydLSkszMzMjExIR+//13InrTI0WeSImMjCzUY0P+HWnCjDKK+xsWFkaCINCqVatK7P2/lhINVZUzymnSdVBTEz+MMfYl4CQKY4yp0LRp06hy5cq0du1aOn/+PNWoUYNsbGzo/v37RES0a9cu6tixIzVs2JAePXr0WWJITU0lOzs78Qnuvn37yNDQUGzsym+0Dxw4QK6urp9lAMdPERQURBYWFvTy5UtKTU2ly5cvU8uWLalatWrUtWtXunTpEqWkpBCRcsNDFY1zxc+fMWMGGRsb065duyg1NZXatGlD5ubmFBAQQFlZWUT0puG4fv162rRpkxjv2LFjydramp4+fVrq8X+oWbNmUcWKFSk6Opru379Pzs7OJJVK6fr160T0pkdK69atyczMTGnAXE2k+N3u3r37k8Ye+VpKNNShnFFOU6+DmpT4YYyxLwUnURhjTAVkMhklJiaShYWFWKpw+vRp0tXVLfQEe/PmzTR69OjP1ui/desWGRsb07Nnz+jw4cNUrlw5seHw6tUrmjt3rtIsIESfZyaM4pJ/tvx43Lp1i7p160b79+8X1zEzM6Nu3bqRvb091a9fn0xNTen06dMqiZeI6Pz580T0v0bjhQsXqFmzZuJ3f+zYMdLT0yNbW1uqXbs2LV26lF69eqX0HgkJCfTrr7+SkZGRWNKgzl6/fk1dunShrVu3EhHRzp07ycjISDy3MjMziYjo4cOHNGLECLXrcfKxM+h86mw4X0uJhjqUMyrStOsgkeYmfhhjTNNxEoUxxlQkKSmJLCwsiOjNwKYFb9ojIiLoxYsXStt8robmjz/+SH379qVy5coplQQkJSVRy5YtaefOnURUsrOMfIyoqChatWoVvX79Wmn54MGD6YcffiAioqZNm1Lr1q3FwT23bdtGvr6+KpuVJCQkhARBEJM8MpmMHj58SGvXrqWsrCw6duwYVapUSTzulpaWVL9+ffL19RUTDa9evaKdO3dS//79NSKBQkT06NEjMjIyokuXLtGRI0eUzu/MzEzy9fUttC/qkkhRbGyeP3+eTpw4IX4XRMWbTvjJkycf/LlfS4mGupUzymnKdVBOExM/jDH2JeAkCmOMqciDBw+oWrVqNGbMGDI0NKTg4GDxtYsXL1LHjh3p5MmTJfZ58ptnxZvo/Px8ysvLo9mzZ5OxsTE5OzuLr71+/ZocHR2pU6dOatO47dGjB5mamtL69euVEikpKSn0/fff0zfffEOtW7cWy3cKUsV+JCYmij1I5DPu5OXlUVpaGslkMurfvz+NHTtWjM3Z2Zlq1apF7u7uSo21zMzMQskjdefi4kJ9+/YlPT09pUbpnTt36IcffhBnUVGXRmlB48aNo2rVqlHZsmWpRYsWtGXLFjE5UTDmgrPEdOrUidLT0z/qc7+WEg1VlDN+CddBRZqW+GGMsS8BJ1EYY6yUFLxpJyKaO3culS1bln799VfxtczMTOratSs5OjqW2FPD6OhocnNzExvhBd83LS2NhgwZQk2aNKFOnTrRyJEjqVWrVtSkSROxJEFdGhADBgygBg0a0Nq1a8X9efHiBQ0aNIjMzMyK1WOgtNy4cYNycnIoOTmZRowYQQYGBrR3717x9by8POrYsSN5eHiIywYOHEgHDx4ssrGnjgqWHSny9/cnIyMj6tu3r/i9pKenk6OjI7Vr105tzik5xWMdGRlJjRs3psOHD9PVq1fJ0dGRrK2tadWqVYUSKQWnE9bT0/voMTq+hhINVZUzaup18EtL/DDGmKbjJApjjH1GO3bsoAULFoh/F7xpj4uLIxcXFzIwMKAxY8aQt7c3dejQgRo2bCjetH9qI0kmk9HUqVOpSZMm5O3tXagBIf/ftLQ0Wrt2LTk7O9OQIUNo+vTpYgmMqkphFCk2BpydncVEiry7ekxMDGlra6vNOBDLly+nBg0aiKUIiYmJNHz4cDIwMBB7pGRlZdGQIUOoRYsW9Msvv1CbNm2oYcOG4r6qewP50KFDNGLECHHqYjnFpMKYMWPIzMyMWrZsSX369CFbW1uysLBQu+Scou3bt9P48eNp9uzZ4rKMjAzq06cPNW/enFavXi0mUhTjL4nphL+WEo3SLmfU1OugpiZ+GGPsS8ZJFMYY+0yysrLI19eXJBIJLV26VFxe8CY4KSmJgoODqXnz5tSrVy8aN25cid+0Z2Zm0pw5c6hFixbk6elZ6IZc3ujNzMws9JnqdANeVCJlzZo1YmNr8ODB1Lt3b0pLS1NViET0ppxDIpEUakwnJCSIiRR5sufp06f0yy+/UK9evWjAgAElljwrDf7+/mRmZkaenp508+ZNpdcUv6uIiAiaPHkyubq6UkBAgFol5wrKyMigBg0akCAINHDgQKXXMjMzqU+fPmRjY0NBQUFK446EhISQgYFBiUwn/DWUaJR2OSOR5l0HNTXxwxhjXzpOojDG2Gf06NEjmjt3LpUvX54CAgLE5QVn8ShKSd20y2+0s7KyaObMmW9tQDx8+JB69uxJgYGBRKS+DbSCiRRzc3Nat24dEREFBARQ+/btVRp7aGgolSlT5q3lHIo9Unbt2kVEhQcB1aSGT1BQEFlaWpK7u7tSIkUmkynNFlMwsaUuybmizpXU1FTq2LEj1a9fn3bv3q0Ua2ZmJtnb29OwYcPEbTdv3kxaWloflED52ko0VFnOqPiZmnYd1LTED2OMfQ04icIYY59ZSkoKzZ49u1AiRX7z++jRI+rQoQP98ccf4vKSvnF/WwMiIyODiN48Fbazs6PatWtrRANesXHQr18/atiwofjEvqhxKkrL2bNnSRAEWr58udLyDh06kK+vr/h3YmIijRgxgipWrEhbtmxRWlfVjbbiUmzgLlu2rMhECtGbc8vR0ZEWL15c2iG+l+I+JCQkUHJyslia9OTJE2rZsiW1bt2a9u/fr/S9ZGdnK82CExISIo7tURxfS4mGOpQzKtK066CmJn4YY+xLx0kUxhgrBYqJFH9/f3G5/KbdzMxMbDR8LgVvyG1sbGjMmDF069Yt6tChAzVo0EAtGmjFbQAoxtipUyfq16/fB79HSUtISKAOHTqQqampOMNI7969qWHDhpSYmKi0blJSEvXt21ecmlkTvS2RIt/Xhw8fUps2bcjU1FQtGqWKFM+R6dOnk6WlJZmZmZGJiYk4NkdqaqqYSImMjCzUoJefgx/ye/laSjTUqZxRkaZcB+U0LfHDGGNfA4GICIwxxj67x48fY8WKFVi0aBFmzZoFT09PtGnTBqmpqbhy5Qq0tbWRl5cHLS2tzxaDTCaDRCJBdnY2Fi5ciMjISFy+fBmmpqa4evVqqcTwoeQxFyU/Px9SqfS965Wmu3fv4pdffkFcXBwaNGiA1NRUbN26FbVq1QIAEBEEQQAAPHjwAMbGxmoR98dSPO6BgYFYs2YN7OzsMGDAAEyZMgUPHjwotfP7Y8yePRvLli1DREQEzM3N4e3tjW3btuHq1avi99ezZ088efIEa9asgY2NzSd/ZlZWFvz9/bF3717Y2Nhg3rx5KFu2rHgs5edIVlYWtLS0lI6Z4jmv7lJSUrBq1SosWLAAM2bMwJgxYwC8OWcEQRB/B0X5nPupaddBxXgXLFiAqKgo2NrawsPDA8OGDcPDhw9x+fJlaGtra9T5wRhjGku1ORzGGPu6yHukGBkZUbly5cjc3Fx86vmpTxELPjV9Wzd4xSebEyZMICcnJ7V7wr1o0SKlcRLepWAPHnV4enz79m3q3bs3CYJAJ06cIKJ3lyVowiCy76IYf2BgIFlZWZGenp7SU311ObcUvX79mrp06UJbt24lIqKdO3eSkZGR2BNFPi3zw4cPacSIESVybn1tJRqlXc74JV0HFSnGO2vWLLKxsSFdXV2qX7++Wv/GGGPsS8Q9URhj7BMVfHr8Po8fP0ZgYCAuXLiAPXv2lPhTz5iYGLRq1apYMefm5kJLSwuCIKj0yWvBY7dx40bMnTsX/v7+cHBwKNZ2R48eRfv27Yv1HZSGpKQkuLm5ITY2FidOnEDt2rXVprdMcRER8vPzlc6Lt53nivvm7++PmJgYbNmyBVpaWmr1VF9RSkoKzM3NcfToUaSlpeGnn37CokWL4OrqiqysLPj5+cHJyQlNmjQRtymJJ/0FexZERkbCxsYGfn5++Oabb/Dw4UM4OzvjwYMHiIuLU8tj9yEUe+FNnz4d3t7eACDu5+PHj3Ht2jVoa2uX2Gdq0nWw4Dn1tuuE4nkzffp03Lx5E5s3b1br3xhjjH2JOInCGGOfIDs7G2XKlAEAxMfHo169esXa7unTp6hQoQIEQUBubu4nNR527tyJrVu3YuPGjRgzZgxOnz6NyMhIVKxY8Z3bqctNd1GN8jt37mD8+PGoVKkSFi5ciLJly75zu9DQUHh7e+P48eNo3rx5qcRdHHfu3IGLiwtu3LiBkydPolatWsVOtqkDxXPz2LFjsLS0hKGh4VvXV2z8yfdTXc6ztxk2bBhevnyJ/fv3Y9myZXBxcQHwpixr2LBh+Pnnn9GvX78S/96+thKNz13OqOnXQUCzEj+MMfZVU0X3F8YY+xJERESQn58fERF5enpSvXr16OXLl+/driS75ctkMtq3bx/p6OhQ06ZNqXz58hQbG/tBMURFRdHTp09LLKaPNXfuXGrVqhXFxcUREdHRo0dJV1eX9u7dS0TK3fIV4w8JCaHy5ct/0PSyn6KoqWnf5fbt29S5c2eSSCTiYLOa4ODBg9S0aVMiIvL29iYLCwt68uTJe7dTx2lWX7169dbX/P39ycjIiPr27SuW76Snp5OjoyO1a9fus8b/tZVofK5yRk29Du7YsYP69+9PREReXl5kbW1Nqamp793uSzonGGNME3EShTHGPtKiRYtIEARq27YtGRkZ0bVr1967jeJN++nTpwtNB/shFN+ra9euJAgCde/evcjX37ZdSEgICYJAMTExHx3Hp5LJZJSVlUW2trYkCAL17NmTZsyYQbdv36bAwEAyMTGhpKQkpfXlSjuBQkTiFLgFY3mXxMRE8vT0VIuEQnHIZDKKjo6mJk2akImJCRkaGtKtW7eKtZ3c+vXr6e7du58xyuI5dOgQjRgxQul7I1KOdcyYMWRmZkYtW7akPn36kK2tLVlYWHzSLC1f6tgcBcnjL+5vISUlhaZMmUIODg4llkCR06TroKYmfhhjjHEShTHGPphiY8jOzo4kEgmNGTPmvdsp3vz+9ttvZGhoSFevXv3keJKTk2nDhg20bNkyMjQ0pMGDB4uvFWycKP4dEhJChoaGtH379k+O4UMpHgt5Y/Pff/+lZs2aUZ8+fWjq1KlkZmZG48aNIwcHB5o2bRplZWUpvUdQUBAZGRmVagLlxo0bJAgCLVy4UFz2oYPCqnvDWHF/hg0bRoIgUJMmTcRlb4tf8TtdsWIFCYJA+/fv/3yBFpO/vz+ZmZmRp6dnoaSlYqIjIiKCJk+eTK6urhQQEFBiiYxTp069dx35Mc/JyRGPo7qfJ0Sk9Jv8999/i71damqquJ8lNbW7Jl0HNTXxwxhj7A1OojDG2AdQvIlNT0+n0aNHk7e3NwmCQPPnz6fnz58XuZ1iYy0kJISMjIwoIiLio2OQx+Hv70+9e/cWX9uzZw8ZGBgoNSCIiPbt26fyHhxFCQoKovDwcLGnyeLFi8nLy4uuXbtGO3fupBo1apC+vj4ZGBgoNdLOnTtHlStXps2bN5dqvM+ePaNZs2aRtrY2LV26VFxe3Jl3srOzP2t8n6Jgw+3SpUsUGRlJq1evpubNm5O1tbVY7lJwPwqe3+XLl6cdO3Z8/qCLKSgoiCwtLcnd3V0pkSKTycTv5/Xr15SWlqa03cf0QPlaSjRUXc74JVwHNSnxwxhj7H84icIYYx/Bz8+PPD09xRvyxYsXi4mUFy9eiOtdunRJabtPuWkfNGgQ7dy5k4j+1zAfOXIkjRs3TlwnPz+f9u3bR4aGhuTs7EzXr18nBwcHcnBwELcJCgqiChUqqDyBQkQ0cOBAatGiBf3www8UExND//zzD3Xo0IH27dtHRG+ebk+YMIG6du2q1KC9e/cu/fPPPyqJ+dmzZ+Tn50eCILw3kaLYYNu4cSMFBQWpdWNZfoyXLFlCjo6O4vLDhw+TpaUlWVtbK/Uc2LFjB6Wnp4t/q7pRWpDid7Js2bIiEylERA8ePCBHR0davHjxJ33e11SioapyRk2+Dn4JiR/GGGOcRGGMsffy8PCg69evE9H/GgHOzs60aNEipfX8/f1JIpHQ7Nmz6dKlS9StWzeytbUVt/mUm98HDx6Qk5MTVahQgSIjI8Xl3bt3p6lTpyqtm5+fT0eOHKHKlSuTmZkZNW/eXGz43rhxg/T19Uu9B4c8rqJER0fTiBEjSCqVUmBgIA0aNIi+++47unfvHhG96SEgp4oERGJiIt2+fVtpWVpaGs2bN48EQaAlS5aIy981+K2WlhYdOHDgs8f7odzd3cnX11dp2axZs8jNzU38Oy8vj6Kjo8nKyoosLCzo7Nmz1LFjR2rfvr24z8uWLSv18qrieFsiJTExkYiIHj58SG3atCFTU9OvcmyOD6XKckZNvQ5qcuKHMcZYYZxEYYyxd3j58iXVrFmTGjZsSPHx8WJDoHPnzhQYGEhEyo2KpUuXUoUKFcjc3JysrKzEm/aTJ09SuXLlPunm9+7du+Tu7k6Ghoa0Z88eIiJydHSkWbNmEVHhEov09HQ6ffq0GJ+8gVgwIVAaFI/R7t27adWqVRQYGKhU5rBx40Zq1KgR9enThwRBIA8PD8rIyBBfL8lZjYpr586dpK2tTcbGxjRp0iQKCgqijIwM8VjOnz+fpFIp+fv7i9vk5+cXahgbGBioZcPnyZMn5ObmRubm5kpJwWHDhpG7uzsR/e+7y8vLo5iYGGrVqhXVqFGD2rZtK57ft27dosaNG9PGjRtLfyeKoahEioeHB/3111/UoUOHEpslhujLLtFQh3JGTbsOamrihzHG2NtxEoUxxt5C3mBITU0la2trMjc3F8flsLe3F0s5FMdVIHpTwnPq1KlC4ylcvnz5o+I4ceIELVmyhJYtW0Zr1qyhyZMnk6GhIf355580adIkmjVrFj1+/Jhu3rxJqamp9OrVKzp9+rTSe6jLrDDe3t5UqVIlsra2JgMDA7KwsKDVq1eLyZKrV6+Sn58f6enp0Y8//qiSxAnRm8ZMXl4eTZ06lSpVqkQ1atSg9u3bk4WFBVWvXp3at29P69evp8jISAoICCBBEGj16tVEpPrZg4pLHuetW7do0qRJVK9ePVqwYAEREQ0ZMoQ8PT2JqOgeRFeuXFFKruTk5NDDhw9LJ/CPpLgfgYGBZGVlRXp6etSgQYNPSqB8jSUaqihn1OTroKYlfhhjjL2bFhhjjL2VTCZDxYoVcfDgQXTs2BHdunVDdHQ09PT0IJVKAQBPnz6FIAgoX748kpOT0bRpU3H7/Px8AIBUKoWFhcUHf/7KlSsxefJkVKtWDUlJSahatSqGDBmCYcOGwdHREa9fv0b9+vWxatUqvHjxAmXLlkV+fj4aN26MgwcPQhAE8fNVLSIiAhs3bsThw4dhZmYGiUSCwYMHIywsDHp6eujduzcaN24Mc3Nz9OvXD9WrV4cgCCAicT9Ky4sXL2BoaIgJEyZAEARcvnwZJiYmmD17Nk6cOIHo6GjMmjULWVlZMDIygp6eHlxcXGBsbIwuXboAAMLCwjB27FisXbsWTk5OpRp/cbx8+RI6OjowNTXF2LFjIZPJEBYWBn19fdSpUwd5eXm4ePEiJBIJjIyMkJubi8TERHTu3BlNmjQB8Ob8lkqlkEqlMDY2Vsl+EBHy8/OhpaWltKzgOSORSCCTySCRSDB69Gjk5OQgJiYGW7ZsgZaWFvLy8pTe430GDx4MJycn9OjRAzKZDIIg4ObNmzA1NRXX+fHHH7FhwwYMGjQI/fr1g6+vL8aOHQsA6NKlCwRBwG+//Ybp06dj9erVanmeeHp6YsSIEWjQoIF4XC9fvoxmzZqJx3js2LEQBAHjx49Hbm4uunbtCl9fX6SmpiImJgaCICA0NBQ+Pj4ftZ+aeh08efKk+Btq1qwZypcvjyFDhmDv3r3ivwdPnjwRrze6urq4evUqbG1tYWtrCwBK53aNGjVKNX7GGGNvodocDmOMqaf9+/eTi4sLde3aVRxsMj09nSwsLMjU1JSqV69O33zzDTVu3JgqVqxIFStWpJo1ayqNgfCpwsLCSEdHhyIiIigjI4OOHj1Kbdu2pbZt29KJEyfI09OT9PX1af78+fTq1Sv6999/KTY2li5duqTynierVq2ihIQEpWULFy6kli1bUlZWlvhkNSMjgzp37kx2dnZFvo8q9uPYsWPk4OBA586dIyKiFy9e0OTJk6lZs2Y0bdo0sdfC3bt36fr16+Tt7U3dunWjRo0aifuVlpZGXbp0UasZahRt27aNevbsSY0aNSJ3d3e6ceMGvXz5kiZMmEBmZmYkCAJ99913VK9ePapUqRJVqVKFKleuTJ06dfrgKZ0/N8WBbo8ePao00G1Rihq35kN7oHwtJRrqUM6oqdfBsLAwqlSpkjjAcP369WnevHk0btw40tfXJ4lEQg0aNCATExMyMjKiatWqkbGxMXXq1EllPfAYY4wVDydRGGOsgNDQUDIyMqI+ffqQtbU1CYIgljakpaWRg4MD6ejo0Nq1a+nKlSt05swZiomJobNnz5bYTfuxY8dIEASaOXMmEf2vsTd//nyqWrUqpaWlUWJiIo0cOZKMjIzo0KFDhd5DVQ2IPXv2UNWqVcnLy4tu3bolLvf19aXGjRuLf8uny718+TLp6urSpUuXVN54ePLkCUVERJCtrS05OTnRxYsXiehNImXKlClkbW1NY8eOpaysrELbymOXNxzfNj6EqoWEhFDZsmXJw8ODevfuTVWqVKGOHTvSw4cP6d69ezRp0iSysLCg4cOHk0wmo5cvX1JSUhLdu3dPbDCr+nuSO3jwIDVt2pSI3pSKWVhY0JMnT967XcGkycf8Vr70Eg11KGfU1OugpiZ+GGOMFQ8nURhjTEFYWBiVKVNG7EGQmppKM2fOJEEQ6Pjx40T0pqFtY2NDlpaW4gwfikriJjg+Pp7s7Ozop59+ohMnTojLFyxYQKamppSSkkJEb2aOGT58OAmCQH/99dcnf25JyMjIoKCgILKysiJPT09KSkoiojdP3cuUKUOTJk1SWv/PP/8kc3NzcT1VWbJkCdWuXZuysrJoy5YtZG9vTz/99JOYSHn58iVNmTKFWrRoQePHjxcbyYrft7okF95m3bp1JAgCRUdHi8tWrFhBWlpa4oCmSUlJNGnSJKpbty4FBAQUeg91aeTJZDKKjo6mJk2akImJCRkaGiol7d61ndz69evp7t27H/S5mjw2x4dQTI6kp6fT999/T/Xq1aM7d+5Qt27dKCgoiIjeXA9TU1MpJyeH4uPjld4jLy/vk/ZVE6+Dmpr4YYwxVnycRGGMsf8nb+T379+fiP5383v69GmqWLEinTp1Slw3NTWVbGxsyMjIiO7cufNZ4omPjycHBwf64YcfKD4+no4cOUJlypQpNHtHXFwczZ8/XyXT/xa0ePFiqlOnDuXk5FBAQABZWlqSp6cn3bx5k4je9PL55ptvyMPDg2JjYyk2NpZ+/PFHatu2rUrLREJCQqhMmTJKs8ts2rSJ2rVrVyiRMnXqVGrZsiUNHz5cLY55cSUlJYklOYq9NTIzM6lmzZoUEhIiLrt9+zZNnjyZjIyM1HLGHcVzZdiwYSQIAjVp0kRc9rbvRTGBsmLFChIEgfbv31/sz/1aSjTUoZxRTtOug5qY+GGMMfZhOInCGGP/7969ezRt2jSqUKGC0hP48PBwKl++vNiVXe7x48c0bNiwz/rUMD4+nrp06UJWVlakra1Nf/zxBxG9eVJZVNJBlQ0IeSJiw4YN4jJ/f39q0qQJeXp6ik/8N23aRMbGxlSlShWqU6cOtWzZUiyBUUUiZcWKFaSjo0M7d+4s9Nq+ffuK7JEyevRo+vXXXzWqYUz05vuwtrYmd3d3ccyaP/74g6RSKV25ckVp3cTERPr999/V6ql4weN96dIlioyMpNWrV1Pz5s3J2tpaLBMrWE5TcJrd8uXLf9CYNV9LiYY6lDMWpEnXQSLNS/wwxhj7MJxEYYwxBSkpKTRz5kzS19endevW0cmTJ0lPT09MDLyt0fy5Eyn29vbUqFEjpSeW6tSAf1ciYsWKFWRhYUGenp7i+A+pqal0+vRpOn/+fKExIkpTwa73cgMHDqT58+cTEdHmzZvJ3t6eevToIU7ZmpGRIR5/dfoe3qbg4J+WlpY0efJkWr58Oenr69OaNWuISDXn94eSx7JkyRJydHQUlx8+fJgsLS3J2tpaabDZHTt2KA02+zHT7H4tJRrqUs5YFE24DirStMQPY4yx4uMkCmOMFfDo0SOaMWMGlS9fngRBoIiICCJS7U1uQkICOTg4kIODg1JZkTp4VyJi4cKFRPSmB0TTpk3Jy8ur0Kw9RKprYMq73nfv3l2cjadXr15Uv359pfE1Nm/eTJ06dSI7OzulHknq2oArimLDLSAggBo2bEg6Ojo0e/ZsInqzL+q6P+7u7uTr66u0bNasWeTm5ib+nZeXR9HR0WRlZUUWFhZ09uxZ6tixI7Vv317c92XLlpGRkdEHzxLzNZRoqFs5Y1HU+TpYFE1L/DDGGCseiaqnWGaMMXVTuXJljBgxAhMnToS+vj6ePHkCANDS0oJMJlNJTHXq1EFgYCCkUim8vLxw9epVlcRRlGrVqqF169a4cOECzp8/DwBwcnLChQsX0KdPHwCAt7c3hgwZglOnTmHu3Ll4+PCh0ntIpdJSjxsA6tati1WrViEnJwczZsyAnZ0dkpOTERUVBVNTU/H7dnZ2xoABA2BpaYk6deqI2wuCoJK4P4ZEIhH3Z8yYMRg9ejRq166NtLQ0JCUlqe2+pKamQiaTYevWrVi8eLG4/M6dO5BI3tzGyGQySKVStGvXDkFBQShXrhx69+6N3NxcHDx4EBKJBMnJyVi5ciWWL18OJyenD4pBfp5kZ2dj7ty5SEhIwNGjR+Hr6wt/f3/85z//AQDUqlUL3t7e8PPzw/fff19yB6EU6Ovrw8fHBwcPHsSSJUvE8+Hff/9Fbm4uKlWqJK5bsWJF7NmzB05OTqhatWqpxajO18Gi1K1bF6Ghofjuu+8wY8YMxMTEANCs6wZjjLHCBCIiVQfBGGOlSSaTiY2vd3n06BFWrFiBgIAAzJ49G6NHjy6F6N7txo0bWLlyJRYtWlSsfSgtCQkJ8PDwgFQqxfPnz5GRkYHt27fD1NQU+fn5YpJk9uzZSEpKwqpVq9Qufjc3N5w7dw5hYWFi8ofe9NgsFGtxzyFVeVd8iq8tXboU69evR5s2bTBy5EjUq1evNMN8LyKCIAhITk7GihUrsH37dri4uMDHxwdDhw6FkZERli5dWuT+Xr16FY0aNYJEIkF+fj5kMhmePn0KY2Pjj44nISEBnp6eSElJwbVr1xAeHo6BAwciPz8fgiAUiiEvLw9aWlof/Xml7fHjxwgJCcHixYuxfPlymJqaokuXLlixYgUGDBggfh8FKf7GS4O6XgffJiEhAWPGjEFKSgpWrVqFJk2aqDokxhhjn4CTKIyxr4r8Zr+4jZuUlBSEhYXB19cXERERYuNaHahbQ764iQh5Q0zd4k9MTMSoUaMgkUgwefJktG7dGsCbeAHNeHr8119/wcbGBgDe2uAFlM+dwMBALFy4EOPGjYOXl1dphVosL168gI6ODnR1dfH06VMsWrQI27dvh7e3N1JTU5GXl4effvoJEokERkZGyM3NRWJiIjp37iy+R0k38BMSEuDq6orHjx9j5cqVaNGiBYB3H29NkpKSgpCQEAQEBODly5fYvHkz+vbtq7YJIXW7jryNpiV+GGOMvR0nURhjX42xY8diz549uH79OnR0dIrdKHj48CEOHDiAwYMHq2UjQp0UNxGhrg1OeY8aAJg6dSpatWql4oiKb9asWdi9ezemTJmCXr16ASh+ImXr1q3o1auXysqqirJ9+3Zs2LABCQkJaNeuHUaNGoXvvvsOc+bMwa5duxAfH49q1aqhbNmySE9PF8vtmjRpggMHDnzWhurNmzfFnmmadp4Ux6NHjxAeHo758+dj3rx5GDVqFADNSVioOz6OjDGm2TiJwhj7KshkMkRGRmLatGkoV64cjhw58kGJFLnS7rauiTQ5EQFobtf7y5cvY8KECQCAX3/9Fb179wZQ/EQKAOTm5kJbW/vzB/seoaGh8Pb2xrBhw/DgwQPExMSgYcOGWL9+PfLz87F8+XJERkaiRYsWCAkJwevXr/HkyRPo6OigSpUqkEgknz1Rp6nniSaXMzLGGGPqgJMojLGvBhHh2LFjmDJlCqRSKY4dOwZtbe13JlIUGxwvXrxA+fLlSzNkjaWpDUw5Tet6L09+3Lx5Ex4eHpBIJHBxcUHPnj0BvD2Rorg8IyMDZcuWLdW4i7J+/XoMHToUhw8fRocOHQAAYWFhcHNzQ0REBHr16oVbt24hLCwM27Ztw8iRIzFmzBil9yitZKemnSdfUjkjY4wxpirq/y8+Y4x9IvmMJIIg4OXLl+jUqRNOnz6Nrl27Ijc3F1paWsjLyyu0neI4HitWrMDChQvx+vXrUo1dU9WtWxeLFi1CmzZt0KhRI1WH88HMzc3h7++vNKONupLJZGLvkXv37qFOnTo4c+YM5s+fj7179wJ4c+4XfGaimEBZsmQJrK2tkZWVVbrBF3Dr1i2MHz8eHTt2hIWFhbh88ODBqF69ujhTVs2aNeHq6oo+ffpg9uzZ2LRpk9L7lFZvMU06T8aOHYv69esjJyfnrde8gipXrgwXFxesWrVKTMgxxhhjXztOojDGvnjyRMjYsWMxYcIEZGdnw8HBAZcuXUL79u2LbFQoNjBXrFgBd3d3WFlZQU9PTyX7oIk0qYH5Lurew0Ae34QJE9C/f39UrlwZI0eOxP379xEQEICdO3cCUE6kKJ7foaGhmDt3LiZNmgRdXV3V7MT/q1mzJnx8fPD8+XPMnDkTN2/eBPBmfJQ7d+7A1tZWXLdGjRpwcXHBvHnz0LdvX1WFLFLn80Qmk6F9+/YoV64cOnTo8EGJlCpVquDnn3+GlpYW8vPzSyFaxhhjTL1xOQ9j7Ktw7tw5dO/eHRs3bkT79u0BADt37sS0adNgZGSkNEaKVCpVamD6+PggPDxcHKyTMXXzzz//oEuXLggNDYWDgwOAN1P8jho1Cvn5+Zg8eTK6du0KQHnaXfn5vXr1ajg5OaksfkC5dG7ZsmVYu3YtunTpgmrVqmHixIkICgrC0KFD1WaaXU3D5YyMMcZYyVDfxyaMMfYJCuaHU1NTkZmZiTp16ojLHB0dMW7cOJw5cwY9e/ZEdnY2tLS0lBIoEyZMwOrVqzmBwtRKwZ49+vr6kMlkyM3NFV9v0qQJQkNDERsbC39/f6xfvx4AxAbzihUrxPNb1QkUAEo9ljw9PTF48GDs3r0bY8aMgY+Pj5hAeRtOoBSNyxkZY4yxksVJFMbYF0meCImNjQUANG3aFMbGxjhw4IC4TpkyZdClSxfUqlULUVFRcHd3F18LCQmBj48PVq1apRYNTMYUyRu3ly9fhkwmAxFBW1sbV65cAfCmASyTydCgQQNYWFggLi5O/C0AwMaNG+Hq6qo2CRQ5xUTKmDFjMHr0aNSuXRtpaWlISkpSy2mx1R2XMzLGGGMli5MojLEv1oEDB+Dm5oZ//vkHBgYGaNKkCbZs2YKoqChxHfkT+4MHDyI0NFRcHh8fr3YNTMbkiAgxMTGwsrJCXFwcatSogQkTJmD69OlYs2YNpFIpJBIJsrKyULNmTfz222/w8/MD8KbspUKFCoiMjFRpD6u3jZOjmEgZMWIEhg8fjhMnTiAoKAjx8fGcSPkI586dw8aNG/H7779jwYIFiIyMRGhoKJ49e1ZojJSC4+WMHz8emzdv5t54jDHG2P/jMVEYY18Mxfp9ADhz5gyGDh0KNzc3eHl5ISkpCUOHDoUgCGjatClatmyJ0NBQSKVSHDp0CBKJRJwqljF1U/D8BoAePXrg6dOn2LdvHwwMDDBr1izMmDEDAwcORIUKFXDlyhU8e/YMFy9ehEQiEccNedu4IqXhr7/+go2NDYC3T70MKO9vYGAgFi5ciHHjxsHLy6u0QtVYBY9rVFQU+vfvj2vXrqF69eoAgOzsbGzatAnDhg1D586dsWPHDpQpU0bcRl7OyL3xGGOMMWXcE4Ux9sWQN7ji4uKQm5sLW1tbeHl5wcfHB2fPnkWtWrWwYcMGtG7dGqdPn8aCBQugq6uLqKgo8ek3J1CYupKf32fPnkVGRgYAYNKkSZBIJNi8eTOICL6+vti5cycyMzMRHx+P6tWr49y5c+L5LR83RFUJlFmzZmHUqFHYsWOHGMfbnuUo9kjx8PDAkiVLMHr06FKLVZNxOSNjjDH2+XBPFMbYFyUwMBATJ07Ef//7XyxYsAD6+voYNmwYnjx5guXLl+O7774Tx5BIT09HxYoVIQjCO2eoYExdbN26Fc7Ozvj555/RqVMn9OvXDz4+PoiJiUFUVJQ4e0pOTg50dHTE7dTl/L58+TImTJgAAPj111/Ru3dvAMXvkQKAe4sV04EDBzBv3jyEhITA1NQU//3vf5Geng5vb2906dIFAPDw4UOMHj0aI0aMQIcOHcTj7O3tjVatWnEChTHGGCsC90RhjGm0guMqVK9eHUZGRti/fz++//577Nq1Cw0aNAAA/P333+I2UqkU3377rfgkXB0amIwVVPA5h76+Pr799lu8ePECe/bsweDBgzF27FgkJSVh1qxZ4nqKM9Woy/mdm5uLpk2bYvny5ZBKpVizZg127twJ4N09UhSTKxkZGZxAeYuC10IDAwM8evQIhw4dQtmyZTF//nxkZWXBz88PHh4e2Lx5MwYMGCCOiyIvZwSAgIAATqAwxhhjb8E9URhjGuvRo0cwNjZWWvbgwQP4+vqiVatWePr0Kc6ePYtvvvkGe/bsga2tLfbt21doXAnG1N3NmzfF6bnHjx+PrVu3Yu/evZg4caKYFDxz5gzWr18PR0dHFUdbmGJvkuPHj2PHjh3YsGED6tSpg6lTp6Jbt24ACvdIUfx7yZIlWLVqFc6fPw9dXd3S3wkNERcXh9q1a0NbWxvBwcHw8vLCqVOnYG1tjTt37iAkJASHDh1Cfn4+jI2NsWfPHmhraxc55g5jjDHGCuN/LRljGmnZsmWwtrbGq1evsHr1apiZmeHKlSuoWrUqevfujSlTpqBHjx5YuHAhWrZsCR0dHRw4cABLly5VdeiMvVdOTg5ev34N4E0Jz6BBgzBx4kQAwPz589GmTRtER0dj//79+PHHH6Grq4v09HScOnVKlWG/lbxxPmHCBPTv3x+VK1fGyJEjcf/+fQQEBBTZI6XgLDFz587FpEmTOIHyDoGBgbCysoKnpydevnwJNzc3DBkyBHPnzsW9e/dQo0YNzJkzB3///TcOHz6MyMhIaGtrIy8vjxMojDHGWDHxv5iMMY0jnzVi0aJFKFeuHCwtLVGzZk307NkTEydOhJWVFaZOnYpffvkF+vr6GDFiBA4cOIDRo0fDw8ND1eEz9k7bt29H//79YWdnh4CAANjY2KB3797YunUrWrVqhaNHj8LCwgIJCQm4f/8+3N3dsXTpUqxdu1appEfd/PPPP9i8eTPCw8MxZcoUzJkzB5GRkcjLy8OiRYuwb98+ABDHKFJMoPj4+CA0NBQDBw5U5S6oHS5nZIwxxkofl/MwxjRKWFgY3N3dERERgR49eii9tnr1auzevRuXLl3CkCFDEB8fD0dHRwwePFhpjAh1GWSTsYLkCQMXFxfIZDIEBgZi3bp1GDRoEB49eoShQ4ciJycHhoaGOHfuHFxdXTF16lSl91CX87tgecjdu3fRsmVLBAcHo1u3buLr//zzD2xsbPD999/jl19+weDBg8VtVqxYwbPEvAWXMzLGGGOqwf+SMsY0xvHjxzFixAixVEdu4MCBWLRoEX755RcsWrQIXl5eCAgIwLZt27Bo0SJxOlg5dWhgMlbQypUrMXr0aKxduxYBAQFYunQpnJ2dkZaWJjaYDx48iF9++QUVKlQQG8wnTpxQeh91Ob/ljfXLly+LM2Jpa2vjypUrAN6U68hkMjRo0AAWFhaIi4sTp+QFgI0bN8LV1RWrV6/mBEoBXM7IGGOMqRAxxpiGiI+PJzs7O+revTudO3eOiIh69epF9evXp+TkZKV1L168SN26daM2bdpQfn6+KsJlrNiOHTtGgiDQzJkzlZZbWFhQ48aNSV9fn1q0aEEbNmwgIqK0tDTy9/endu3aUV5enipCfi+ZTEanTp0iQRDo+vXrREQUEhJCEomEwsPDxfUyMzNp8ODBtG3bNvG3mpeXR1FRURQVFaWK0NVaSEgIlSlThjZv3kxEb651nTt3ppo1a9KECRMoJSWFli9fTnZ2dpSamiqu4+HhQbm5uaoMnTHGGPsicDkPY0yjJCQkwMPDA1KpFM+fP0dGRga2b98OU1NTcR36/wEp09LSYGRkBEEQeOYJptYSEhLg4uICIyMjTJs2Dc2aNYOTkxOuXr2KuXPnwsDAAOPGjUNeXh7279+PWrVqKW2fn5+vVLKmKkX9znr06IGnT59i3759MDAwwKxZszBjxgwMHDgQFSpUwJUrV/Ds2TNcvHgREolE3BcqMFMP43JGxhhjTB1wEoUxpnESEhLg5uaGc+fOISwsDH369AFQeHpUOU6gME2gmCB89uwZMjMzlRKEly5dEgcL7d69O4C3n/OqdvbsWTRq1Ahly5bF33//DR8fHwwYMADDhw+HIAjYvXs31q9fj9evX+Pbb7/F6tWreZrd9zh+/Djs7e0xY8YM+Pr6issHDhyIpk2bYvz48YiPj8e+ffswdepUZGVlwdzcHH/99Rf09fVVGDljjDH2ZeE7FcaYxqlbty5CQkJgY2OD8PBwcVpXxelRFXGjjGmCunXrIjAwENnZ2YiNjcXEiRNhamoqjidCRDA3N0fFihXFbdQxgbJ161bY2Nhg9OjR2Lx5M1q0aIEWLVpg3bp1ePnyJQDgp59+wsaNGxEVFYX169fzNLvFUK1aNbRu3RoXLlzA+fPnAQBOTk64ePEi+vbtCwCoV68evL29ERMTg65du+Lbb7+Fnp6eKsNmjDHGvjjcE4UxprHkT+4BYOrUqWjVqpWKI2Ls0yUmJmLUqFGQSCSYNGkS7OzsAADdunXDq1evcOTIEbVKNhTsDXPgwAEMGTIEbdu2hba2NqRSKRYvXoymTZti4MCBWLx4MQDlEiR17VGjbrickTHGGFM9TqIwxjRaQkICxowZg5SUFKxatQpNmjRRdUiMfTJ5Y1meSFmyZAliY2MRGxurtmUvN2/eRJ06dQAA48ePx9atW7F3715MnDgRMpkMUqkUZ86cwfr16+Ho6KjiaDUXlzMyxhhjqsX/qjLGNFrdunWxaNEitGnTBo0aNVJ1OIyVCHlpjyAIsLe3x/Xr18UEirqUveTk5OD169cA3pTwDBo0CBMnTgQAzJ8/H23atEF0dDT279+PH3/8Ebq6ukhPTxfL79jH4XJGxhhjTLW4Jwpj7IvCT13ZlyQuLg7BwcEICAiAlpaW2syssn37dmzcuBG3bt3CoEGD0KdPH0REROD333+HsbExZsyYgatXryIxMRFTpkxBtWrVcO/ePRw7dgz9+/dXi33QdFzOyBhjjKkGJ1EYY4wxDaAuCZTQ0FD4+PjAxcUFMpkMgYGBWLduHQYNGoRHjx5h6NChyMnJgaGhIc6dOwdXV1dMnTpV6T3UZV80HZczMsYYY6WPkyiMMcYYK5aVK1fCzc0NW7ZsQY8ePQAA/fv3h62tLfr27QtjY2MAwPr163H8+HGEh4cDAI4dO4a2bduqKuwv2o0bN7By5UosWrSIe+ExxhhjpYCTKIwxxhh7r+PHj8Pe3h4zZsyAr6+vuLxp06aQyWRITk5GgwYN4OHhgQEDBiA9PR3h4eHYu3cvoqOjxZl42OfD5YyMMcbY58dJFMYYY4y9V0JCAlxcXGBkZIRp06ahWbNmcHJywtWrVzF37lwYGBhg3LhxyMvLw/79+1GrVi2l7RWnNGaMMcYY01ScRGGMMcZYscgHM5VKpXj27BkyMzOxfft2mJqaAgAuXbqE77//Hrt27UL37t0BvH3qXcYYY4wxTcR9PhljjDFWLPKpl7OzsxEbG4uJEyfC1NQUMpkMRAQigrm5OSpWrChuwwkUxhhjjH1JuCcKY4wxxj5IYmIiRo0aBYlEgkmTJsHOzg4A0K1bN7x69QpHjhzhsTkYY4wx9kXiJApjjDHGPpi8tEeeSFmyZAliY2MRGxsLbW1tHuSUMcYYY18kvrthjDHG2AeTl/YIggB7e3tcv35dTKDk5eVxAoUxxhhjXyTuicIYY4yxjxYXF4fg4GAEBARAS0sLeXl50NLSUnVYjDHGGGOfBSdRGGOMMVYiOIHCGGOMsS8dJ1EYY4wxxhhjjDHGioELlhljjDHGGGOMMcaKgZMojDHGGGOMMcYYY8XASRTGGGOMMcYYY4yxYuAkCmOMMcYYY4wxxlgxcBKFMcYYY4wxxhhjrBg4icIYY4wxxhhjjDFWDJxEYYwxxth7/fe//4UgCIX+u3nz5ie/95o1a2BoaPjpQTLGGGOMfWZaqg6AMcYYY5rBwcEB4eHhSssqVaqkomiKlpubC21tbVWHwRhjjLEvFPdEYYwxxlixlClTBsbGxkr/SaVS7N69G1ZWVtDV1UWtWrUwc+ZM5OXlidsFBASgcePG0NPTQ/Xq1eHm5oZXr14BAI4fP46ff/4Zz58/F3u3zJgxAwAgCAJ27dqlFIOhoSHWrFkDAEhOToYgCIiIiEDbtm2hq6uLDRs2AABWrlwJc3Nz6Orqon79+ggODhbfIycnB+7u7qhSpQp0dXVhYmICPz+/z3fgGGOMMfbF4J4ojDHGGPtof/75J4YMGYLAwEDY2dkhMTERw4cPBwBMnz4dACCRSBAYGIiaNWsiKSkJbm5u8PHxQXBwMFq2bImlS5fC19cX//77LwCgXLlyHxTDxIkT4e/vD0tLSzGR4uvri99++w2Wlpa4dOkSfv31V+jp6WHo0KEIDAzEnj17sGXLFtSoUQN3797F3bt3S/bAMMYYY+yLxEkUxhhjjBXLvn37lBIcXbp0QXp6OiZOnIihQ4cCAGrVqoXZs2fDx8dHTKJ4eXmJ25iammLOnDlwdXVFcHAwdHR0YGBgAEEQYGxs/FFxeXl5oVevXuLf06dPh7+/v7isZs2a+OeffxAaGoqhQ4fizp07qFu3Llq3bg1BEGBiYvJRn8sYY4yxrw8nURhjjDFWLO3bt8fvv/8u/q2np4cmTZogJiYGc+fOFZfn5+cjKysLGRkZKFu2LKKjo+Hn54e4uDi8ePECeXl5Sq9/qmbNmon///Xr10hMTISLiwt+/fVXcXleXh4MDAwAvBkkt1OnTjAzM4ODgwO6du2KH3744ZPjYIwxxtiXj5MojDHGGCsWPT091KlTR2nZq1evMHPmTKWeIHK6urpITk5G165dMXLkSMydOxcVKlTAqVOn4OLigpycnHcmUQRBABEpLcvNzS0yLsV4ACAsLAwtWrRQWk8qlQIArKyscOvWLURFRSE6Ohp9+/ZFx44dsW3btvccAcYYY4x97TiJwhhjjLGPZmVlhX///bdQckXuwoULkMlk8Pf3h0TyZjz7LVu2KK2jo6OD/Pz8QttWqlQJDx8+FP9OSEhARkbGO+OpXLkyqlatiqSkJAwcOPCt65UvXx7Ozs5wdnZG79694eDggLS0NFSoUOGd788YY4yxrxsnURhjjDH20Xx9fdG1a1fUqFEDvXv3hkQiwZUrVxAbG4s5c+agTp06yM3NRVBQELp164aYmBiEhIQovYepqSlevXqFI0eOwMLCAmXLlkXZsmVhb2+P3377Dba2tsjPz8eECROKNX3xzJkz4eHhAQMDAzg4OCA7Oxvnz59Heno6vL29ERAQgCpVqsDS0hISiQRbt26FsbExDA0NP9NRYowxxtiXgqc4ZowxxthH69y5M/bt24dDhw6hefPmsLGxwZIlS8TBWi0sLBAQEIAFCxagUaNG2LBhQ6HphFu2bAlXV1c4OzujUqVKWLhwIQDA398f1atXh52dHQYMGIBx48YVawyVYcOGYeXKlQgPD0fjxo3Rtm1brFmzBjVr1gQA6OvrY+HChWjWrBmaN2+O5ORkREZGij1lGGOMMcbeRqCCxcaMMcYYY4wxxhhjrBB+5MIYY4wxxhhjjDFWDJxEYYwxxhhjjDHGGCsGTqIwxhhjjDHGGGOMFQMnURhjjDHGGGOMMcaKgZMojDHGGGOMMcYYY8XASRTGGGOMMcYYY4yxYuAkCmOMMcYYY4wxxlgxcBKFMcYYY4wxxhhjrBg4icIYY4wxxhhjjDFWDJxEYYwxxhhjjDHGGCsGTqIwxhhjjDHGGGOMFQMnURhjjDHGGGOMMcaK4f8APj3c8Exllf8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_weights_per_label(weights, columns, label = 1, large = False, num_weights = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "## convert dataset to spark dataFrame\n",
    "## Transform the dataframe as required (standard scaler, vector assembler, string indexer)\n",
    "## prediction pipeline\n",
    "## display the prediction as we wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## create information bank to store feature description\n",
    "information_bank = dict()\n",
    "\n",
    "data = train.sample(withReplacement = False, seed = 2023, fraction = 0.5).toPandas() ## sample dataset\n",
    "\n",
    "for column in columns:\n",
    "    series = data[column]\n",
    "\n",
    "    #if  the feature is categorical, store the set of values the dataset can samnple from \n",
    "    if (len(series.unique()) <= 30) or (series.dtype == \"object\"):\n",
    "        information_bank[column] = series.unique().tolist()\n",
    "    else:\n",
    "        if series.dtype == float:\n",
    "            dtype = \"float\"\n",
    "        else:\n",
    "            dtype = \"int\" \n",
    "            \n",
    "        information_bank[column] = {\n",
    "            \"min\": series.min(), #.item(),\n",
    "            \"max\": series.max(), #.item(),\n",
    "            \"dtype\": dtype\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(columns, information_bank, sample_size = 1):\n",
    "    data = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for column in columns:\n",
    "        column_info = information_bank[column] # pick out column information\n",
    "    \n",
    "        #categorical features\n",
    "        if isinstance(column_info, list):\n",
    "            results = [np.random.choice(column_info) for _ in range(sample_size)]\n",
    "        else:\n",
    "            low, high = column_info[\"min\"], column_info[\"max\"]\n",
    "\n",
    "            if column_info[\"dtype\"] == \"float\":\n",
    "                results = np.random.randint(low = low, high = high + 1, size = sample_size) + np.random.randn(sample_size)\n",
    "            else:\n",
    "                results = nprandom.randint(low = low, high = high + 1, size = sample_size)\n",
    "        data[column] = results # populate te dataframe with the generated data\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>Fwd_Pkt_Len_Mean</th>\n",
       "      <th>Fwd_Pkt_Len_Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Init_Bwd_Win_Byts</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>-1.035992</td>\n",
       "      <td>29.406305</td>\n",
       "      <td>23.526014</td>\n",
       "      <td>18.671144</td>\n",
       "      <td>3.898141</td>\n",
       "      <td>18.324218</td>\n",
       "      <td>1.353885</td>\n",
       "      <td>-1.446686</td>\n",
       "      <td>-0.822180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.901646</td>\n",
       "      <td>-0.021761</td>\n",
       "      <td>9.922094</td>\n",
       "      <td>14.916235</td>\n",
       "      <td>17.274459</td>\n",
       "      <td>11.778009</td>\n",
       "      <td>-0.839642</td>\n",
       "      <td>3.259826</td>\n",
       "      <td>2.322249</td>\n",
       "      <td>3.790557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.948482</td>\n",
       "      <td>9.709766</td>\n",
       "      <td>10.080729</td>\n",
       "      <td>2.233644</td>\n",
       "      <td>36.209610</td>\n",
       "      <td>9.488018</td>\n",
       "      <td>2.797053</td>\n",
       "      <td>12.970149</td>\n",
       "      <td>14.457043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822590</td>\n",
       "      <td>2.385198</td>\n",
       "      <td>3.279325</td>\n",
       "      <td>17.921215</td>\n",
       "      <td>2.235505</td>\n",
       "      <td>1.235110</td>\n",
       "      <td>3.480208</td>\n",
       "      <td>9.483058</td>\n",
       "      <td>0.498437</td>\n",
       "      <td>4.247020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.216510</td>\n",
       "      <td>27.002194</td>\n",
       "      <td>21.738151</td>\n",
       "      <td>11.801920</td>\n",
       "      <td>44.827850</td>\n",
       "      <td>21.655786</td>\n",
       "      <td>2.363814</td>\n",
       "      <td>28.570874</td>\n",
       "      <td>30.760845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.783079</td>\n",
       "      <td>6.599226</td>\n",
       "      <td>2.133992</td>\n",
       "      <td>24.616504</td>\n",
       "      <td>3.425402</td>\n",
       "      <td>6.799811</td>\n",
       "      <td>1.248199</td>\n",
       "      <td>5.436232</td>\n",
       "      <td>2.027032</td>\n",
       "      <td>3.009898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.135153</td>\n",
       "      <td>25.721492</td>\n",
       "      <td>26.042292</td>\n",
       "      <td>21.307213</td>\n",
       "      <td>36.243483</td>\n",
       "      <td>22.976623</td>\n",
       "      <td>30.646827</td>\n",
       "      <td>18.474843</td>\n",
       "      <td>4.853725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030038</td>\n",
       "      <td>4.528139</td>\n",
       "      <td>9.230015</td>\n",
       "      <td>7.852789</td>\n",
       "      <td>15.543011</td>\n",
       "      <td>14.880402</td>\n",
       "      <td>2.804234</td>\n",
       "      <td>1.622477</td>\n",
       "      <td>1.020999</td>\n",
       "      <td>0.230208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.876096</td>\n",
       "      <td>21.315289</td>\n",
       "      <td>33.294181</td>\n",
       "      <td>0.482261</td>\n",
       "      <td>33.090966</td>\n",
       "      <td>9.291470</td>\n",
       "      <td>35.312650</td>\n",
       "      <td>11.092000</td>\n",
       "      <td>11.721901</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.077232</td>\n",
       "      <td>4.581439</td>\n",
       "      <td>3.654285</td>\n",
       "      <td>0.193529</td>\n",
       "      <td>7.484090</td>\n",
       "      <td>9.671268</td>\n",
       "      <td>-0.594805</td>\n",
       "      <td>7.182273</td>\n",
       "      <td>1.515630</td>\n",
       "      <td>4.255124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol  Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  TotLen_Fwd_Pkts  \\\n",
       "0      17.0      -1.035992     29.406305     23.526014        18.671144   \n",
       "1       6.0       1.948482      9.709766     10.080729         2.233644   \n",
       "2      17.0       0.216510     27.002194     21.738151        11.801920   \n",
       "3       6.0       0.135153     25.721492     26.042292        21.307213   \n",
       "4      17.0       0.876096     21.315289     33.294181         0.482261   \n",
       "\n",
       "   TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  Fwd_Pkt_Len_Mean  \\\n",
       "0         3.898141        18.324218         1.353885         -1.446686   \n",
       "1        36.209610         9.488018         2.797053         12.970149   \n",
       "2        44.827850        21.655786         2.363814         28.570874   \n",
       "3        36.243483        22.976623        30.646827         18.474843   \n",
       "4        33.090966         9.291470        35.312650         11.092000   \n",
       "\n",
       "   Fwd_Pkt_Len_Std  ...  Init_Bwd_Win_Byts  Fwd_Act_Data_Pkts  Active_Mean  \\\n",
       "0        -0.822180  ...          -0.901646          -0.021761     9.922094   \n",
       "1        14.457043  ...           0.822590           2.385198     3.279325   \n",
       "2        30.760845  ...          -0.783079           6.599226     2.133992   \n",
       "3         4.853725  ...           0.030038           4.528139     9.230015   \n",
       "4        11.721901  ...          -1.077232           4.581439     3.654285   \n",
       "\n",
       "   Active_Std  Active_Max  Active_Min  Idle_Mean  Idle_Std  Idle_Max  Idle_Min  \n",
       "0   14.916235   17.274459   11.778009  -0.839642  3.259826  2.322249  3.790557  \n",
       "1   17.921215    2.235505    1.235110   3.480208  9.483058  0.498437  4.247020  \n",
       "2   24.616504    3.425402    6.799811   1.248199  5.436232  2.027032  3.009898  \n",
       "3    7.852789   15.543011   14.880402   2.804234  1.622477  1.020999  0.230208  \n",
       "4    0.193529    7.484090    9.671268  -0.594805  7.182273  1.515630  4.255124  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data(columns, information_bank, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(columns, information_bank, sample_size = 1):\n",
    "    data = generate_data(columns, information_bank, sample_size)\n",
    "    data = spark.createDataFrame(data)\n",
    "    data = assembler.transform(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(columns, information_bank, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_pipeline(data, model):\n",
    "    predictions = model.transform(data) #generate predictions\n",
    "    label_mapper = IndexToString(inputCol = \"prediction\", outputCol = \"Label\", labels = string_encoder.labels)\n",
    "\n",
    "    predictions = label_mapper.transform(predictions).toPandas()\n",
    "    predictions = predictions[\"Label\"].values.tolist()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = prediction_pipeline(data, log_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NaN', 'NaN', 'NaN', 'NaN', 'NaN']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_predictions(predictions):\n",
    "    predictions = [\n",
    "        (f\"Operational Status: {status}\" if status == \"Normal\" \n",
    "        else f\"Operational Status: Under Threat! Threat type: {status}. Take appropriate action now!\")\n",
    "        for status in predictions\n",
    "    ]\n",
    "\n",
    "    predictions = [\n",
    "        \"<h4>\" + prediction + \"<h4>\" for prediction in predictions\n",
    "    ]\n",
    "    return \"\".join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h4>Operational Status: Under Threat! Threat type: NaN. Take appropriate action now!<h4><h4>Operational Status: Under Threat! Threat type: NaN. Take appropriate action now!<h4><h4>Operational Status: Under Threat! Threat type: NaN. Take appropriate action now!<h4><h4>Operational Status: Under Threat! Threat type: NaN. Take appropriate action now!<h4><h4>Operational Status: Under Threat! Threat type: NaN. Take appropriate action now!<h4>'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocess_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def inference():\n",
    "    \n",
    "    n = request.args.get(\"n\", default=1, type=int)\n",
    "    \n",
    "    data = prepare_data(columns, information_bank, n)\n",
    "    predictions = prediction_pipeline(data, log_model)\n",
    "    predictions = postprocess_predictions(predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/xlade/Library/Python/3.9/lib/python/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 898, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9007')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xlade/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/23 00:01:07 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 996781 ms exceeds timeout 120000 ms\n",
      "24/10/23 00:01:07 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/10/23 00:15:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:15:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:15:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:15:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:15:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:15:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:15:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:15:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:15:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:15:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:15:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:15:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:16:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:17:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:18:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:19:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:19:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:19:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:20:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:21:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:22:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:23:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/10/23 00:23:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:23:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.198:60046\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/23 00:24:54 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
